{
  "date": "2026-02-26",
  "fetched_at": "2026-02-27T09:27:20.957639+09:00",
  "papers": [
    {
      "id": "2602.22207",
      "title": "Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets",
      "abstract": "The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks. Existing resources often suffer from semantic drift and context loss, which can lead to misleading performance metrics. In this work, we present a fully automated framework designed to address these challenges by enabling scalable, high-quality translation of datasets and benchmarks. We demonstrate that adapting test-time compute scaling strategies, specifically Universal Self-Improvement (USI) and our proposed multi-round ranking method, T-RANK, allows for significantly higher quality outputs compared to traditional pipelines. Our framework ensures that benchmarks preserve their original task structure and linguistic nuances during localization. We apply this approach to translate popular benchmarks and datasets into eight Eastern and Southern European languages (Ukrainian, Bulgarian, Slovak, Romanian, Lithuanian, Estonian, Turkish, Greek). Evaluations using both reference-based metrics and LLM-as-a-judge show that our translations surpass existing resources, resulting in more accurate downstream model assessment. We release both the framework and the improved benchmarks to facilitate robust and reproducible multilingual AI development.",
      "authors": [
        "Hanna Yukhymenko",
        "Anton Alexandrov",
        "Martin Vechev"
      ],
      "url": "https://arxiv.org/abs/2602.22207",
      "published": "2026-02-25T18:58:25+00:00",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.22200",
      "title": "SumTablets: A Transliteration Dataset of Sumerian Tablets",
      "abstract": "Sumerian transliteration is a conventional system for representing a scholar's interpretation of a tablet in the Latin script. Thanks to visionary digital Assyriology projects such as ETCSL, CDLI, and Oracc, a large number of Sumerian transliterations have been published online, and these data are well-structured for a variety of search and analysis tasks. However, the absence of a comprehensive, accessible dataset pairing transliterations with a digital representation of the tablet's cuneiform glyphs has prevented the application of modern Natural Language Processing (NLP) methods to the task of Sumerian transliteration.   To address this gap, we present SumTablets, a dataset pairing Unicode representations of 91,606 Sumerian cuneiform tablets (totaling 6,970,407 glyphs) with the associated transliterations published by Oracc. We construct SumTablets by first preprocessing and standardizing the Oracc transliterations before mapping each reading back to the Unicode representation of the source glyph. Further, we retain parallel structural information (e.g., surfaces, newlines, broken segments) through the use of special tokens. We release SumTablets as a Hugging Face Dataset (CC BY 4.0) and open source data preparation code via GitHub.   Additionally, we leverage SumTablets to implement and evaluate two transliteration baselines: (1) weighted sampling from a glyph's possible readings, and (2) fine-tuning an autoregressive language model. Our fine-tuned language model achieves an average transliteration character-level F-score (chrF) of 97.55, demonstrating the immediate potential of transformer-based transliteration models in allowing experts to rapidly verify generated transliterations rather than manually transliterating tablets one-by-one.",
      "authors": [
        "Cole Simmons",
        "Richard Diehl Martinez",
        "Dan Jurafsky"
      ],
      "url": "https://arxiv.org/abs/2602.22200",
      "published": "2026-02-25T18:50:42+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.22197",
      "title": "Off-The-Shelf Image-to-Image Models Are All You Need To Defeat Image Protection Schemes",
      "abstract": "Advances in Generative AI (GenAI) have led to the development of various protection strategies to prevent the unauthorized use of images. These methods rely on adding imperceptible protective perturbations to images to thwart misuse such as style mimicry or deepfake manipulations. Although previous attacks on these protections required specialized, purpose-built methods, we demonstrate that this is no longer necessary. We show that off-the-shelf image-to-image GenAI models can be repurposed as generic ``denoisers\" using a simple text prompt, effectively removing a wide range of protective perturbations. Across 8 case studies spanning 6 diverse protection schemes, our general-purpose attack not only circumvents these defenses but also outperforms existing specialized attacks while preserving the image's utility for the adversary. Our findings reveal a critical and widespread vulnerability in the current landscape of image protection, indicating that many schemes provide a false sense of security. We stress the urgent need to develop robust defenses and establish that any future protection mechanism must be benchmarked against attacks from off-the-shelf GenAI models. Code is available in this repository: https://github.com/mlsecviswanath/img2imgdenoiser",
      "authors": [
        "Xavier Pleimling",
        "Sifat Muhammad Abdullah",
        "Gunjan Balde",
        "Peng Gao",
        "Mainack Mondal",
        "Murtuza Jadliwala",
        "Bimal Viswanath"
      ],
      "url": "https://arxiv.org/abs/2602.22197",
      "published": "2026-02-25T18:46:30+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.22193",
      "title": "Improving Parametric Knowledge Access in Reasoning Language Models",
      "abstract": "We study reasoning for accessing world knowledge stored in a language model's parameters. For example, recalling that Canberra is Australia's capital may benefit from thinking through major cities and the concept of purpose-built capitals. While reasoning language models are trained via reinforcement learning to produce reasoning traces on tasks such as mathematics, they may not reason well for accessing their own world knowledge. We first find that models do not generate their best world knowledge reasoning by default: adding a simple \"think step-by-step\" cue demonstrates statistically significant improvement in knowledge recall but not math. Motivated by this, we propose training models to reason over their parametric knowledge using world-knowledge question answering as a verifiable reward. After reinforcement learning on TriviaQA (+9.9%), performance also improves on Natural Questions, HotpotQA, SimpleQA, and StrategyQA by 4.2%, 2.1%, 0.6%, and 3.0%, respectively. Reasoning models are under-optimized for parametric knowledge access, but can be easily trained to reason better.",
      "authors": [
        "Melody Ma",
        "John Hewitt"
      ],
      "url": "https://arxiv.org/abs/2602.22193",
      "published": "2026-02-25T18:43:01+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.22190",
      "title": "GUI-Libra: Training Native GUI Agents to Reason and Act with Action-aware Supervision and Partially Verifiable RL",
      "abstract": "Open-source native GUI agents still lag behind closed-source systems on long-horizon navigation tasks. This gap stems from two limitations: a shortage of high-quality, action-aligned reasoning data, and the direct adoption of generic post-training pipelines that overlook the unique challenges of GUI agents. We identify two fundamental issues in these pipelines: (i) standard SFT with CoT reasoning often hurts grounding, and (ii) step-wise RLVR-tyle training faces partial verifiability, where multiple actions can be correct but only a single demonstrated action is used for verification. This makes offline step-wise metrics weak predictors of online task success. In this work, we present GUI-Libra, a tailored training recipe that addresses these challenges. First, to mitigate the scarcity of action-aligned reasoning data, we introduce a data construction and filtering pipeline and release a curated 81K GUI reasoning dataset. Second, to reconcile reasoning with grounding, we propose action-aware SFT that mixes reasoning-then-action and direct-action data and reweights tokens to emphasize action and grounding. Third, to stabilize RL under partial verifiability, we identify the overlooked importance of KL regularization in RLVR and show that a KL trust region is critical for improving offline-to-online predictability; we further introduce success-adaptive scaling to downweight unreliable negative gradients. Across diverse web and mobile benchmarks, GUI-Libra consistently improves both step-wise accuracy and end-to-end task completion. Our results suggest that carefully designed post-training and data curation can unlock significantly stronger task-solving capabilities without costly online data collection. We release our dataset, code, and models to facilitate further research on data-efficient post-training for reasoning-capable GUI agents.",
      "authors": [
        "Rui Yang",
        "Qianhui Wu",
        "Zhaoyang Wang",
        "Hanyang Chen",
        "Ke Yang",
        "Hao Cheng",
        "Huaxiu Yao",
        "Baoling Peng",
        "Huan Zhang",
        "Jianfeng Gao",
        "Tong Zhang"
      ],
      "url": "https://arxiv.org/abs/2602.22190",
      "published": "2026-02-25T18:34:57+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "id": "2602.22188",
      "title": "Surrogate models for Rock-Fluid Interaction: A Grid-Size-Invariant Approach",
      "abstract": "Modelling rock-fluid interaction requires solving a set of partial differential equations (PDEs) to predict the flow behaviour and the reactions of the fluid with the rock on the interfaces. Conventional high-fidelity numerical models require a high resolution to obtain reliable results, resulting in huge computational expense. This restricts the applicability of these models for multi-query problems, such as uncertainty quantification and optimisation, which require running numerous scenarios. As a cheaper alternative to high-fidelity models, this work develops eight surrogate models for predicting the fluid flow in porous media. Four of these are reduced-order models (ROM) based on one neural network for compression and another for prediction. The other four are single neural networks with the property of grid-size invariance; a term which we use to refer to image-to-image models that are capable of inferring on computational domains that are larger than those used during training. In addition to the novel grid-size-invariant framework for surrogate models, we compare the predictive performance of UNet and UNet++ architectures, and demonstrate that UNet++ outperforms UNet for surrogate models. Furthermore, we show that the grid-size-invariant approach is a reliable way to reduce memory consumption during training, resulting in good correlation between predicted and ground-truth values and outperforming the ROMs analysed. The application analysed is particularly challenging because fluid-induced rock dissolution results in a non-static solid field and, consequently, it cannot be used to help in adjustments of the future prediction.",
      "authors": [
        "Nathalie C. Pinheiro",
        "Donghu Guo",
        "Hannah P. Menke",
        "Aniket C. Joshi",
        "Claire E. Heaney",
        "Ahmed H. ElSheikh",
        "Christopher C. Pain"
      ],
      "url": "https://arxiv.org/abs/2602.22188",
      "published": "2026-02-25T18:34:03+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.flu-dyn"
      ]
    },
    {
      "id": "2602.22182",
      "title": "LiCQA : A Lightweight Complex Question Answering System",
      "abstract": "Over the last twenty years, significant progress has been made in designing and implementing Question Answering (QA) systems. However, addressing complex questions, the answers to which are spread across multiple documents, remains a challenging problem. Recent QA systems that are designed to handle complex questions work either on the basis of knowledge graphs, or utilise contem- porary neural models that are expensive to train, in terms of both computational resources and the volume of training data required. In this paper, we present LiCQA, an unsupervised question answer- ing model that works primarily on the basis of corpus evidence. We empirically compare the effectiveness and efficiency of LiCQA with two recently presented QA systems, which are based on different underlying principles. The results of our experiments show that LiCQA significantly outperforms these two state-of-the-art systems on benchmark data with noteworthy reduction in latency.",
      "authors": [
        "Sourav Saha",
        "Dwaipayan Roy",
        "Mandar Mitra"
      ],
      "url": "https://arxiv.org/abs/2602.22182",
      "published": "2026-02-25T18:28:38+00:00",
      "categories": [
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "id": "2602.22179",
      "title": "Learning and Naming Subgroups with Exceptional Survival Characteristics",
      "abstract": "In many applications, it is important to identify subpopulations that survive longer or shorter than the rest of the population. In medicine, for example, it allows determining which patients benefit from treatment, and in predictive maintenance, which components are more likely to fail. Existing methods for discovering subgroups with exceptional survival characteristics require restrictive assumptions about the survival model (e.g. proportional hazards), pre-discretized features, and, as they compare average statistics, tend to overlook individual deviations. In this paper, we propose Sysurv, a fully differentiable, non-parametric method that leverages random survival forests to learn individual survival curves, automatically learns conditions and how to combine these into inherently interpretable rules, so as to select subgroups with exceptional survival characteristics. Empirical evaluation on a wide range of datasets and settings, including a case study on cancer data, shows that Sysurv reveals insightful and actionable survival subgroups.",
      "authors": [
        "Mhd Jawad Al Rahwanji",
        "Sascha Xu",
        "Nils Philipp Walter",
        "Jilles Vreeken"
      ],
      "url": "https://arxiv.org/abs/2602.22179",
      "published": "2026-02-25T18:25:47+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.22175",
      "title": "DySCO: Dynamic Attention-Scaling Decoding for Long-Context LMs",
      "abstract": "Understanding and reasoning over long contexts is a crucial capability for language models (LMs). Although recent models support increasingly long context windows, their accuracy often deteriorates as input length grows. In practice, models often struggle to keep attention aligned with the most relevant context throughout decoding. In this work, we propose DySCO, a novel decoding algorithm for improving long-context reasoning. DySCO leverages retrieval heads--a subset of attention heads specialized for long-context retrieval--to identify task-relevant tokens at each decoding step and explicitly up-weight them. By doing so, DySCO dynamically adjusts attention during generation to better utilize relevant context. The method is training-free and can be applied directly to any off-the-shelf LMs. Across multiple instruction-tuned and reasoning models, DySCO consistently improves performance on challenging long-context reasoning benchmarks, yielding relative gains of up to 25% on MRCR and LongBenchV2 at 128K context length with modest additional compute. Further analysis highlights the importance of both dynamic attention rescaling and retrieval-head-guided selection for the effectiveness of the method, while providing interpretability insights into decoding-time attention behavior. Our code is available at https://github.com/princeton-pli/DySCO.",
      "authors": [
        "Xi Ye",
        "Wuwei Zhang",
        "Fangcong Yin",
        "Howard Yen",
        "Danqi Chen"
      ],
      "url": "https://arxiv.org/abs/2602.22175",
      "published": "2026-02-25T18:21:35+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.22157",
      "title": "Dynamic Personality Adaptation in Large Language Models via State Machines",
      "abstract": "The inability of Large Language Models (LLMs) to modulate their personality expression in response to evolving dialogue dynamics hinders their performance in complex, interactive contexts. We propose a model-agnostic framework for dynamic personality simulation that employs state machines to represent latent personality states, where transition probabilities are dynamically adapted to the conversational context. Part of our architecture is a modular pipeline for continuous personality scoring that evaluates dialogues along latent axes while remaining agnostic to the specific personality models, their dimensions, transition mechanisms, or LLMs used. These scores function as dynamic state variables that systematically reconfigure the system prompt, steering behavioral alignment throughout the interaction.We evaluate this framework by operationalizing the Interpersonal Circumplex (IPC) in a medical education setting. Results demonstrate that the system successfully adapts its personality state to user inputs, but also influences user behavior, thereby facilitating de-escalation training. Notably, the scoring pipeline maintains comparable precision even when utilizing lightweight, fine-tuned classifiers instead of large-scale LLMs. This work demonstrates the feasibility of modular, personality-adaptive architectures for education, customer support, and broader human-computer interaction.",
      "authors": [
        "Leon Pielage",
        "Ole Hätscher",
        "Mitja Back",
        "Bernhard Marschall",
        "Benjamin Risse"
      ],
      "url": "https://arxiv.org/abs/2602.22157",
      "published": "2026-02-25T18:05:11+00:00",
      "categories": [
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "id": "2602.22149",
      "title": "Enhancing Framingham Cardiovascular Risk Score Transparency through Logic-Based XAI",
      "abstract": "Cardiovascular disease (CVD) remains one of the leading global health challenges, accounting for more than 19 million deaths worldwide. To address this, several tools that aim to predict CVD risk and support clinical decision making have been developed. In particular, the Framingham Risk Score (FRS) is one of the most widely used and recommended worldwide. However, it does not explain why a patient was assigned to a particular risk category nor how it can be reduced. Due to this lack of transparency, we present a logical explainer for the FRS. Based on first-order logic and explainable artificial intelligence (XAI) fundaments, the explainer is capable of identifying a minimal set of patient attributes that are sufficient to explain a given risk classification. Our explainer also produces actionable scenarios that illustrate which modifiable variables would reduce a patient's risk category. We evaluated all possible input combinations of the FRS (over 22,000 samples) and tested them with our explainer, successfully identifying important risk factors and suggesting focused interventions for each case. The results may improve clinician trust and facilitate a wider implementation of CVD risk assessment by converting opaque scores into transparent and prescriptive insights, particularly in areas with restricted access to specialists.",
      "authors": [
        "Emannuel L. de A. Bezerra",
        "Luiz H. T. Viana",
        "Vinícius P. Chagas",
        "Diogo E. Rolim",
        "Thiago Alves Rocha",
        "Carlos H. L. Cavalcante"
      ],
      "url": "https://arxiv.org/abs/2602.22149",
      "published": "2026-02-25T17:58:11+00:00",
      "categories": [
        "cs.LO",
        "cs.AI"
      ]
    },
    {
      "id": "2602.22146",
      "title": "Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual",
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) plays a significant role in aligning Large Language Models (LLMs) with human preferences. While RLHF with expected reward constraints can be formulated as a primal-dual optimization problem, standard primal-dual methods only guarantee convergence with a distributional policy where the saddle-point problem is in convex-concave form. Moreover, standard primal-dual methods may exhibit instability or divergence in the last iterate under policy parameterization in practical applications. In this work, we propose a universal primal-dual framework for safe RLHF that unifies a broad class of existing alignment algorithms, including safe-RLHF, one-shot, and multi-shot based methods. Building on this framework, we introduce an optimistic primal-dual (OPD) algorithm that incorporates predictive updates for both primal and dual variables to stabilize saddle-point dynamics. We establish last-iterate convergence guarantees for the proposed method, covering both exact policy optimization in the distributional space and convergence to a neighborhood of the optimal solution whose gap is related to approximation error and bias under parameterized policies. Our analysis reveals that optimism plays a crucial role in mitigating oscillations inherent to constrained alignment objectives, thereby closing a key theoretical gap between constrained RL and practical RLHF.",
      "authors": [
        "Yining Li",
        "Peizhong Ju",
        "Ness Shroff"
      ],
      "url": "https://arxiv.org/abs/2602.22146",
      "published": "2026-02-25T17:54:52+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.22145",
      "title": "When AI Writes, Whose Voice Remains? Quantifying Cultural Marker Erasure Across World English Varieties in Large Language Models",
      "abstract": "Large Language Models (LLMs) are increasingly used to ``professionalize'' workplace communication, often at the cost of linguistic identity. We introduce \"Cultural Ghosting\", the systematic erasure of linguistic markers unique to non-native English varieties during text processing. Through analysis of 22,350 LLM outputs generated from 1,490 culturally marked texts (Indian, Singaporean,& Nigerian English) processed by five models under three prompt conditions, we quantify this phenomenon using two novel metrics: Identity Erasure Rate (IER) & Semantic Preservation Score (SPS). Across all prompts, we find an overall IER of 10.26%, with model-level variation from 3.5% to 20.5% (5.9x range). Crucially, we identify a Semantic Preservation Paradox: models maintain high semantic similarity (mean SPS = 0.748) while systematically erasing cultural markers. Pragmatic markers (politeness conventions) are 1.9x more vulnerable than lexical markers (71.5% vs. 37.1% erasure). Our experiments demonstrate that explicit cultural-preservation prompts reduce erasure by 29% without sacrificing semantic quality.",
      "authors": [
        "Satyam Kumar Navneet",
        "Joydeep Chandra",
        "Yong Zhang"
      ],
      "url": "https://arxiv.org/abs/2602.22145",
      "published": "2026-02-25T17:54:42+00:00",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "id": "2602.22144",
      "title": "NoLan: Mitigating Object Hallucinations in Large Vision-Language Models via Dynamic Suppression of Language Priors",
      "abstract": "Object hallucination is a critical issue in Large Vision-Language Models (LVLMs), where outputs include objects that do not appear in the input image. A natural question arises from this phenomenon: Which component of the LVLM pipeline primarily contributes to object hallucinations? The vision encoder to perceive visual information, or the language decoder to generate text responses? In this work, we strive to answer this question through designing a systematic experiment to analyze the roles of the vision encoder and the language decoder in hallucination generation. Our observations reveal that object hallucinations are predominantly associated with the strong priors from the language decoder. Based on this finding, we propose a simple and training-free framework, No-Language-Hallucination Decoding, NoLan, which refines the output distribution by dynamically suppressing language priors, modulated based on the output distribution difference between multimodal and text-only inputs. Experimental results demonstrate that NoLan effectively reduces object hallucinations across various LVLMs on different tasks. For instance, NoLan achieves substantial improvements on POPE, enhancing the accuracy of LLaVA-1.5 7B and Qwen-VL 7B by up to 6.45 and 7.21, respectively. The code is publicly available at: https://github.com/lingfengren/NoLan.",
      "authors": [
        "Lingfeng Ren",
        "Weihao Yu",
        "Runpeng Yu",
        "Xinchao Wang"
      ],
      "url": "https://arxiv.org/abs/2602.22144",
      "published": "2026-02-25T17:50:41+00:00",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "id": "2602.22136",
      "title": "SigmaQuant: Hardware-Aware Heterogeneous Quantization Method for Edge DNN Inference",
      "abstract": "Deep neural networks (DNNs) are essential for performing advanced tasks on edge or mobile devices, yet their deployment is often hindered by severe resource constraints, including limited memory, energy, and computational power. While uniform quantization provides a straightforward approach to compress model and reduce hardware requirement, it fails to fully leverage the varying robustness across layers, and often lead to accuracy degradation or suboptimal resource usage, particularly at low bitwidths. In contrast, heterogeneous quantization, which allocates different bitwidths to individual layers, can mitigate these drawbacks. Nonetheless, current heterogeneous quantization methods either needs huge brute-force design space search or lacks the adaptability to meet different hardware conditions, such as memory size, energy budget, and latency requirement. Filling these gaps, this work introduces \\textbf{\\textit{SigmaQuant}}, an adaptive layer-wise heterogeneous quantization framework designed to efficiently balance accuracy and resource usage for varied edge environments without exhaustive search.",
      "authors": [
        "Qunyou Liu",
        "Pengbo Yu",
        "Marina Zapater",
        "David Atienza"
      ],
      "url": "https://arxiv.org/abs/2602.22136",
      "published": "2026-02-25T17:34:14+00:00",
      "categories": [
        "cs.LG",
        "cs.AR"
      ]
    },
    {
      "id": "2602.22130",
      "title": "Sample Complexity Bounds for Robust Mean Estimation with Mean-Shift Contamination",
      "abstract": "We study the basic task of mean estimation in the presence of mean-shift contamination. In the mean-shift contamination model, an adversary is allowed to replace a small constant fraction of the clean samples by samples drawn from arbitrarily shifted versions of the base distribution. Prior work characterized the sample complexity of this task for the special cases of the Gaussian and Laplace distributions. Specifically, it was shown that consistent estimation is possible in these cases, a property that is provably impossible in Huber's contamination model. An open question posed in earlier work was to determine the sample complexity of mean estimation in the mean-shift contamination model for general base distributions. In this work, we study and essentially resolve this open question. Specifically, we show that, under mild spectral conditions on the characteristic function of the (potentially multivariate) base distribution, there exists a sample-efficient algorithm that estimates the target mean to any desired accuracy. We complement our upper bound with a qualitatively matching sample complexity lower bound. Our techniques make critical use of Fourier analysis, and in particular introduce the notion of a Fourier witness as an essential ingredient of our upper and lower bounds.",
      "authors": [
        "Ilias Diakonikolas",
        "Giannis Iakovidis",
        "Daniel M. Kane",
        "Sihan Liu"
      ],
      "url": "https://arxiv.org/abs/2602.22130",
      "published": "2026-02-25T17:21:23+00:00",
      "categories": [
        "cs.LG",
        "cs.DS"
      ]
    },
    {
      "id": "2602.22125",
      "title": "IndicIFEval: A Benchmark for Verifiable Instruction-Following Evaluation in 14 Indic Languages",
      "abstract": "Instruction-following benchmarks remain predominantly English-centric, leaving a critical evaluation gap for the hundreds of millions of Indic language speakers. We introduce IndicIFEval, a benchmark evaluating constrained generation of LLMs across 14 Indic languages using automatically verifiable, rule-based instructions. It comprises around 800 human-verified examples per language spread across two complementary subsets: IndicIFEval-Ground, translated prompts from IFEval (Zhou et al., 2023) carefully localized for Indic contexts, and IndicIFEval-Ground, synthetically generated instructions grounded in native Indic content. We conduct a comprehensive evaluation of major open-weight and proprietary models spanning both reasoning and non-reasoning models. While models maintain strong adherence to formatting constraints, they struggle significantly with lexical and cross-lingual tasks -- and despite progress in high-resource languages, instruction-following across the broader Indic family lags significantly behind English. We release IndicIFEval and its evaluation scripts to support progress on multilingual constrained generation (http://github.com/ai4bharat/IndicIFEval).",
      "authors": [
        "Thanmay Jayakumar",
        "Mohammed Safi Ur Rahman Khan",
        "Raj Dabre",
        "Ratish Puduppully",
        "Anoop Kunchukuttan"
      ],
      "url": "https://arxiv.org/abs/2602.22125",
      "published": "2026-02-25T17:12:37+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.22124",
      "title": "SWE-Protégé: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents",
      "abstract": "Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We introduce SWE-Protégé, a post-training framework that reframes software repair as an expert-protégé collaboration problem. In SWE-Protégé, an SLM remains the sole decision-maker while learning to selectively seek guidance from a strong expert model, recognize stalled states, and follow through on expert feedback. Our approach combines supervised fine-tuning on expert-augmented trajectories with agentic reinforcement learning that explicitly discourages degenerative looping and unproductive expert collaboration. We lightly post-train Qwen2.5-Coder-7B-Instruct to achieve 42.4% Pass@1 on SWE-bench Verified, a +25.4% improvement over the prior SLM state of the art, while using expert assistance sparsely (~4 calls per task and 11% of total tokens).",
      "authors": [
        "Patrick Tser Jern Kon",
        "Archana Pradeep",
        "Ang Chen",
        "Alexander P. Ellis",
        "Warren Hunt",
        "Zijian Wang",
        "John Yang",
        "Samuel Thompson"
      ],
      "url": "https://arxiv.org/abs/2602.22124",
      "published": "2026-02-25T17:11:49+00:00",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "id": "2602.22122",
      "title": "Probing the Geometry of Diffusion Models with the String Method",
      "abstract": "Understanding the geometry of learned distributions is fundamental to improving and interpreting diffusion models, yet systematic tools for exploring their landscape remain limited. Standard latent-space interpolations fail to respect the structure of the learned distribution, often traversing low-density regions. We introduce a framework based on the string method that computes continuous paths between samples by evolving curves under the learned score function. Operating on pretrained models without retraining, our approach interpolates between three regimes: pure generative transport, which yields continuous sample paths; gradient-dominated dynamics, which recover minimum energy paths (MEPs); and finite-temperature string dynamics, which compute principal curves -- self-consistent paths that balance energy and entropy. We demonstrate that the choice of regime matters in practice. For image diffusion models, MEPs contain high-likelihood but unrealistic ''cartoon'' images, confirming prior observations that likelihood maxima appear unrealistic; principal curves instead yield realistic morphing sequences despite lower likelihood. For protein structure prediction, our method computes transition pathways between metastable conformers directly from models trained on static structures, yielding paths with physically plausible intermediates. Together, these results establish the string method as a principled tool for probing the modal structure of diffusion models -- identifying modes, characterizing barriers, and mapping connectivity in complex learned distributions.",
      "authors": [
        "Elio Moreau",
        "Florentin Coeurdoux",
        "Grégoire Ferre",
        "Eric Vanden-Eijnden"
      ],
      "url": "https://arxiv.org/abs/2602.22122",
      "published": "2026-02-25T17:10:59+00:00",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "id": "2602.22115",
      "title": "Slice and Explain: Logic-Based Explanations for Neural Networks through Domain Slicing",
      "abstract": "Neural networks (NNs) are pervasive across various domains but often lack interpretability. To address the growing need for explanations, logic-based approaches have been proposed to explain predictions made by NNs, offering correctness guarantees. However, scalability remains a concern in these methods. This paper proposes an approach leveraging domain slicing to facilitate explanation generation for NNs. By reducing the complexity of logical constraints through slicing, we decrease explanation time by up to 40\\% less time, as indicated through comparative experiments. Our findings highlight the efficacy of domain slicing in enhancing explanation efficiency for NNs.",
      "authors": [
        "Luiz Fernando Paulino Queiroz",
        "Carlos Henrique Leitão Cavalcante",
        "Thiago Alves Rocha"
      ],
      "url": "https://arxiv.org/abs/2602.22115",
      "published": "2026-02-25T17:01:52+00:00",
      "categories": [
        "cs.LO",
        "cs.LG"
      ]
    },
    {
      "id": "2602.22107",
      "title": "Don't stop me now: Rethinking Validation Criteria for Model Parameter Selection",
      "abstract": "Despite the extensive literature on training loss functions, the evaluation of generalization on the validation set remains underexplored. In this work, we conduct a systematic empirical and statistical study of how the validation criterion used for model selection affects test performance in neural classifiers, with attention to early stopping. Using fully connected networks on standard benchmarks under $k$-fold evaluation, we compare: (i) early stopping with patience and (ii) post-hoc selection over all epochs (i.e. no early stopping). Models are trained with cross-entropy, C-Loss, or PolyLoss; the model parameter selection on the validation set is made using accuracy or one of the three loss functions, each considered independently. Three main findings emerge. (1) Early stopping based on validation accuracy performs worst, consistently selecting checkpoints with lower test accuracy than both loss-based early stopping and post-hoc selection. (2) Loss-based validation criteria yield comparable and more stable test accuracy. (3) Across datasets and folds, any single validation rule often underperforms the test-optimal checkpoint. Overall, the selected model typically achieves test-set performance statistically lower than the best performance across all epochs, regardless of the validation criterion. Our results suggest avoiding validation accuracy (in particular with early stopping) for parameter selection, favoring loss-based validation criteria.",
      "authors": [
        "Andrea Apicella",
        "Francesco Isgrò",
        "Andrea Pollastro",
        "Roberto Prevete"
      ],
      "url": "https://arxiv.org/abs/2602.22107",
      "published": "2026-02-25T16:56:14+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.22101",
      "title": "On Imbalanced Regression with Hoeffding Trees",
      "abstract": "Many real-world applications provide a continuous stream of data that is subsequently used by machine learning models to solve regression tasks of interest. Hoeffding trees and their variants have a long-standing tradition due to their effectiveness, either alone or as base models in broader ensembles. At the same time a recent line of work in batch learning has shown that kernel density estimation (KDE) is an effective approach for smoothed predictions in imbalanced regression tasks [Yang et al., 2021]. Moreover, another recent line of work for batch learning, called hierarchical shrinkage (HS) [Agarwal et al., 2022], has introduced a post-hoc regularization method for decision trees that does not alter the structure of the learned tree. Using a telescoping argument we cast KDE to streaming environments and extend the implementation of HS to incremental decision tree models. Armed with these extensions we investigate the performance of decision trees that may enjoy such options in datasets commonly used for regression in online settings. We conclude that KDE is beneficial in the early parts of the stream, while HS hardly, if ever, offers performance benefits. Our code is publicly available at: https://github.com/marinaAlchirch/DSFA_2026.",
      "authors": [
        "Pantia-Marina Alchirch",
        "Dimitrios I. Diochnos"
      ],
      "url": "https://arxiv.org/abs/2602.22101",
      "published": "2026-02-25T16:48:07+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.22094",
      "title": "Petri Net Relaxation for Infeasibility Explanation and Sequential Task Planning",
      "abstract": "Plans often change due to changes in the situation or our understanding of the situation. Sometimes, a feasible plan may not even exist, and identifying such infeasibilities is useful to determine when requirements need adjustment. Common planning approaches focus on efficient one-shot planning in feasible cases rather than updating domains or detecting infeasibility. We propose a Petri net reachability relaxation to enable robust invariant synthesis, efficient goal-unreachability detection, and helpful infeasibility explanations. We further leverage incremental constraint solvers to support goal and constraint updates. Empirically, compared to baselines, our system produces a comparable number of invariants, detects up to 2 times more infeasibilities, performs competitively in one-shot planning, and outperforms in sequential plan updates in the tested domains.",
      "authors": [
        "Nguyen Cong Nhat Le",
        "John G. Rogers",
        "Claire N. Bonial",
        "Neil T. Dantam"
      ],
      "url": "https://arxiv.org/abs/2602.22094",
      "published": "2026-02-25T16:39:50+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.22090",
      "title": "Confidence-Driven Multi-Scale Model Selection for Cost-Efficient Inference",
      "abstract": "Large Language Models (LLMs) have revolutionized inference across diverse natural language tasks, with larger models performing better but at higher computational costs. We propose a confidence-driven strategy that dynamically selects the most suitable model based on confidence estimates. By assessing a model's confidence in handling the task and response accuracy, tasks that are likely to be solved correctly are retained, while more uncertain or complex cases are delegated to a larger model, ensuring reliability while minimizing computation. Specifically, we evaluate a model's likelihood of knowing the correct answer and the probability that its response is accurate. Experiments on the Massive Multitask Language Understanding (MMLU) benchmark show that our approach achieves accuracy comparable to the largest model while reducing computational costs by 20\\% to 40\\%. When applied to GPT-4o API calls, it reduces token usage by approximately 60\\%, further improving cost efficiency. These findings indicate the potential of confidence-based model selection to enhance real-world LLM deployment, particularly in resource-constrained settings such as edge devices and commercial API applications.",
      "authors": [
        "Bo-Wei Chen",
        "Chung-Chi Chen",
        "An-Zi Yen"
      ],
      "url": "https://arxiv.org/abs/2602.22090",
      "published": "2026-02-25T16:38:03+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.22086",
      "title": "MBD-ML: Many-body dispersion from machine learning for molecules and materials",
      "abstract": "Van der Waals (vdW) interactions are essential for describing molecules and materials, from drug design and catalysis to battery applications. These omnipresent interactions must also be accurately included in machine-learned force fields. The many-body dispersion (MBD) method stands out as one of the most accurate and transferable approaches to capture vdW interactions, requiring only atomic $C_6$ coefficients and polarizabilities as input. We present MBD-ML, a pretrained message passing neural network that predicts these atomic properties directly from atomic structures. Through seamless integration with libMBD, our method enables the immediate calculation of MBD-inclusive total energies, forces, and stress tensors. By eliminating the need for intermediate electronic structure calculations, MBD-ML offers a practical and streamlined tool that simplifies the incorporation of state-of-the-art vdW interactions into any electronic structure code, as well as empirical and machine-learned force fields.",
      "authors": [
        "Evgeny Moerman",
        "Adil Kabylda",
        "Almaz Khabibrakhmanov",
        "Alexandre Tkatchenko"
      ],
      "url": "https://arxiv.org/abs/2602.22086",
      "published": "2026-02-25T16:34:53+00:00",
      "categories": [
        "physics.chem-ph",
        "cond-mat.mtrl-sci",
        "cs.LG",
        "physics.comp-ph"
      ]
    },
    {
      "id": "2602.22083",
      "title": "Coarsening Bias from Variable Discretization in Causal Functionals",
      "abstract": "A class of causal effect functionals requires integration over conditional densities of continuous variables, as in mediation effects and nonparametric identification in causal graphical models. Estimating such densities and evaluating the resulting integrals can be statistically and computationally demanding. A common workaround is to discretize the variable and replace integrals with finite sums. Although convenient, discretization alters the population-level functional and can induce non-negligible approximation bias, even under correct identification. Under smoothness conditions, we show that this coarsening bias is first order in the bin width and arises at the level of the target functional, distinct from statistical estimation error. We propose a simple bias-reduced functional that evaluates the outcome regression at within-bin conditional means, eliminating the leading term and yielding a second-order approximation error. We derive plug-in and one-step estimators for the bias-reduced functional. Simulations demonstrate substantial bias reduction and near-nominal confidence interval coverage, even under coarse binning. Our results provide a simple framework for controlling the impact of variable discretization on parameter approximation and estimation.",
      "authors": [
        "Xiaxian Ou",
        "Razieh Nabi"
      ],
      "url": "https://arxiv.org/abs/2602.22083",
      "published": "2026-02-25T16:32:04+00:00",
      "categories": [
        "stat.ME",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "id": "2602.22072",
      "title": "Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models",
      "abstract": "Theory of Mind (ToM) refers to an agent's ability to model the internal states of others. Contributing to the debate whether large language models (LLMs) exhibit genuine ToM capabilities, our study investigates their ToM robustness using perturbations on false-belief tasks and examines the potential of Chain-of-Thought prompting (CoT) to enhance performance and explain the LLM's decision. We introduce a handcrafted, richly annotated ToM dataset, including classic and perturbed false belief tasks, the corresponding spaces of valid reasoning chains for correct task completion, subsequent reasoning faithfulness, task solutions, and propose metrics to evaluate reasoning chain correctness and to what extent final answers are faithful to reasoning traces of the generated CoT. We show a steep drop in ToM capabilities under task perturbation for all evaluated LLMs, questioning the notion of any robust form of ToM being present. While CoT prompting improves the ToM performance overall in a faithful manner, it surprisingly degrades accuracy for some perturbation classes, indicating that selective application is necessary.",
      "authors": [
        "Christian Nickel",
        "Laura Schrewe",
        "Florian Mai",
        "Lucie Flek"
      ],
      "url": "https://arxiv.org/abs/2602.22072",
      "published": "2026-02-25T16:24:35+00:00",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "id": "2602.22070",
      "title": "Language Models Exhibit Inconsistent Biases Towards Algorithmic Agents and Human Experts",
      "abstract": "Large language models are increasingly used in decision-making tasks that require them to process information from a variety of sources, including both human experts and other algorithmic agents. How do LLMs weigh the information provided by these different sources? We consider the well-studied phenomenon of algorithm aversion, in which human decision-makers exhibit bias against predictions from algorithms. Drawing upon experimental paradigms from behavioural economics, we evaluate how eightdifferent LLMs delegate decision-making tasks when the delegatee is framed as a human expert or an algorithmic agent. To be inclusive of different evaluation formats, we conduct our study with two task presentations: stated preferences, modeled through direct queries about trust towards either agent, and revealed preferences, modeled through providing in-context examples of the performance of both agents. When prompted to rate the trustworthiness of human experts and algorithms across diverse tasks, LLMs give higher ratings to the human expert, which correlates with prior results from human respondents. However, when shown the performance of a human expert and an algorithm and asked to place an incentivized bet between the two, LLMs disproportionately choose the algorithm, even when it performs demonstrably worse. These discrepant results suggest that LLMs may encode inconsistent biases towards humans and algorithms, which need to be carefully considered when they are deployed in high-stakes scenarios. Furthermore, we discuss the sensitivity of LLMs to task presentation formats that should be broadly scrutinized in evaluation robustness for AI safety.",
      "authors": [
        "Jessica Y. Bo",
        "Lillio Mok",
        "Ashton Anderson"
      ],
      "url": "https://arxiv.org/abs/2602.22070",
      "published": "2026-02-25T16:18:28+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.22067",
      "title": "Semantic Partial Grounding via LLMs",
      "abstract": "Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases. Recent advances in partial grounding have addressed this challenge by incrementally grounding only the most promising operators, guided by predictive models. However, these approaches primarily rely on relational features or learned embeddings and do not leverage the textual and structural cues present in PDDL descriptions. We propose SPG-LLM, which uses LLMs to analyze the domain and problem files to heuristically identify potentially irrelevant objects, actions, and predicates prior to grounding, significantly reducing the size of the grounded task. Across seven hard-to-ground benchmarks, SPG-LLM achieves faster grounding-often by orders of magnitude-while delivering comparable or better plan costs in some domains.",
      "authors": [
        "Giuseppe Canonaco",
        "Alberto Pozanco",
        "Daniel Borrajo"
      ],
      "url": "https://arxiv.org/abs/2602.22067",
      "published": "2026-02-25T16:13:26+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.22066",
      "title": "DualWeaver: Synergistic Feature Weaving Surrogates for Multivariate Forecasting with Univariate Time Series Foundation Models",
      "abstract": "Time-series foundation models (TSFMs) have achieved strong univariate forecasting through large-scale pre-training, yet effectively extending this success to multivariate forecasting remains challenging. To address this, we propose DualWeaver, a novel framework that adapts univariate TSFMs (Uni-TSFMs) for multivariate forecasting by using a pair of learnable, structurally symmetric surrogate series. Generated by a shared auxiliary feature-fusion module that captures cross-variable dependencies, these surrogates are mapped to TSFM-compatible series via the forecasting objective. The symmetric structure enables parameter-free reconstruction of final predictions directly from the surrogates, without additional parametric decoding. A theoretically grounded regularization term is further introduced to enhance robustness against adaptation collapse. Extensive experiments on diverse real-world datasets show that DualWeaver outperforms state-of-the-art multivariate forecasters in both accuracy and stability. We release the code at https://github.com/li-jinpeng/DualWeaver.",
      "authors": [
        "Jinpeng Li",
        "Zhongyi Pei",
        "Huaze Xue",
        "Bojian Zheng",
        "Chen Wang",
        "Jianmin Wang"
      ],
      "url": "https://arxiv.org/abs/2602.22066",
      "published": "2026-02-25T16:13:12+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.22061",
      "title": "Learning Quantum Data Distribution via Chaotic Quantum Diffusion Model",
      "abstract": "Generative models for quantum data pose significant challenges but hold immense potential in fields such as chemoinformatics and quantum physics. Quantum denoising diffusion probabilistic models (QuDDPMs) enable efficient learning of quantum data distributions by progressively scrambling and denoising quantum states; however, existing implementations typically rely on circuit-based random unitary dynamics that can be costly to realize and sensitive to control imperfections, particularly on analog quantum hardware. We propose the chaotic quantum diffusion model, a framework that generates projected ensembles via chaotic Hamiltonian time evolution, providing a flexible and hardware-compatible diffusion mechanism. Requiring only global, time-independent control, our approach substantially reduces implementation overhead across diverse analog quantum platforms while achieving accuracy comparable to QuDDPMs. This method improves trainability and robustness, broadening the applicability of quantum generative modeling.",
      "authors": [
        "Quoc Hoan Tran",
        "Koki Chinzei",
        "Yasuhiro Endo",
        "Hirotaka Oshima"
      ],
      "url": "https://arxiv.org/abs/2602.22061",
      "published": "2026-02-25T16:09:50+00:00",
      "categories": [
        "quant-ph",
        "cs.LG",
        "nlin.CD"
      ]
    },
    {
      "id": "2602.22059",
      "title": "NESTOR: A Nested MOE-based Neural Operator for Large-Scale PDE Pre-Training",
      "abstract": "Neural operators have emerged as an efficient paradigm for solving PDEs, overcoming the limitations of traditional numerical methods and significantly improving computational efficiency. However, due to the diversity and complexity of PDE systems, existing neural operators typically rely on a single network architecture, which limits their capacity to fully capture heterogeneous features and complex system dependencies. This constraint poses a bottleneck for large-scale PDE pre-training based on neural operators. To address these challenges, we propose a large-scale PDE pre-trained neural operator based on a nested Mixture-of-Experts (MoE) framework. In particular, the image-level MoE is designed to capture global dependencies, while the token-level Sub-MoE focuses on local dependencies. Our model can selectively activate the most suitable expert networks for a given input, thereby enhancing generalization and transferability. We conduct large-scale pre-training on twelve PDE datasets from diverse sources and successfully transfer the model to downstream tasks. Extensive experiments demonstrate the effectiveness of our approach.",
      "authors": [
        "Dengdi Sun",
        "Xiaoya Zhou",
        "Xiao Wang",
        "Hao Si",
        "Wanli Lyu",
        "Jin Tang",
        "Bin Luo"
      ],
      "url": "https://arxiv.org/abs/2602.22059",
      "published": "2026-02-25T16:08:46+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.22056",
      "title": "FlowCorrect: Efficient Interactive Correction of Generative Flow Policies for Robotic Manipulation",
      "abstract": "Generative manipulation policies can fail catastrophically under deployment-time distribution shift, yet many failures are near-misses: the robot reaches almost-correct poses and would succeed with a small corrective motion. We present FlowCorrect, a deployment-time correction framework that converts near-miss failures into successes using sparse human nudges, without full policy retraining. During execution, a human provides brief corrective pose nudges via a lightweight VR interface. FlowCorrect uses these sparse corrections to locally adapt the policy, improving actions without retraining the backbone while preserving the model performance on previously learned scenarios. We evaluate on a real-world robot across three tabletop tasks: pick-and-place, pouring, and cup uprighting. With a low correction budget, FlowCorrect improves success on hard cases by 85\\% while preserving performance on previously solved scenarios. The results demonstrate clearly that FlowCorrect learns only with very few demonstrations and enables fast and sample-efficient incremental, human-in-the-loop corrections of generative visuomotor policies at deployment time in real-world robotics.",
      "authors": [
        "Edgar Welte",
        "Yitian Shi",
        "Rosa Wolf",
        "Maximillian Gilles",
        "Rania Rayyes"
      ],
      "url": "https://arxiv.org/abs/2602.22056",
      "published": "2026-02-25T16:06:49+00:00",
      "categories": [
        "cs.RO",
        "cs.LG"
      ]
    },
    {
      "id": "2602.22055",
      "title": "Physics-Informed Machine Learning for Vessel Shaft Power and Fuel Consumption Prediction: Interpretable KAN-based Approach",
      "abstract": "Accurate prediction of shaft rotational speed, shaft power, and fuel consumption is crucial for enhancing operational efficiency and sustainability in maritime transportation. Conventional physics-based models provide interpretability but struggle with real-world variability, while purely data-driven approaches achieve accuracy at the expense of physical plausibility. This paper introduces a Physics-Informed Kolmogorov-Arnold Network (PI-KAN), a hybrid method that integrates interpretable univariate feature transformations with a physics-informed loss function and a leakage-free chained prediction pipeline. Using operational and environmental data from five cargo vessels, PI-KAN consistently outperforms the traditional polynomial method and neural network baselines. The model achieves the lowest mean absolute error (MAE) and root mean squared error (RMSE), and the highest coefficient of determination (R^2) for shaft power and fuel consumption across all vessels, while maintaining physically consistent behavior. Interpretability analysis reveals rediscovery of domain-consistent dependencies, such as cubic-like speed-power relationships and cosine-like wave and wind effects. These results demonstrate that PI-KAN achieves both predictive accuracy and interpretability, offering a robust tool for vessel performance monitoring and decision support in operational settings.",
      "authors": [
        "Hamza Haruna Mohammed",
        "Dusica Marijan",
        "Arnbjørn Maressa"
      ],
      "url": "https://arxiv.org/abs/2602.22055",
      "published": "2026-02-25T16:06:28+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.22045",
      "title": "DLT-Corpus: A Large-Scale Text Collection for the Distributed Ledger Technology Domain",
      "abstract": "We introduce DLT-Corpus, the largest domain-specific text collection for Distributed Ledger Technology (DLT) research to date: 2.98 billion tokens from 22.12 million documents spanning scientific literature (37,440 publications), United States Patent and Trademark Office (USPTO) patents (49,023 filings), and social media (22 million posts). Existing Natural Language Processing (NLP) resources for DLT focus narrowly on cryptocurrencies price prediction and smart contracts, leaving domain-specific language under explored despite the sector's ~$3 trillion market capitalization and rapid technological evolution.   We demonstrate DLT-Corpus' utility by analyzing technology emergence patterns and market-innovation correlations. Findings reveal that technologies originate in scientific literature before reaching patents and social media, following traditional technology transfer patterns. While social media sentiment remains overwhelmingly bullish even during crypto winters, scientific and patent activity grow independently of market fluctuations, tracking overall market expansion in a virtuous cycle where research precedes and enables economic growth that funds further innovation.   We publicly release the full DLT-Corpus; LedgerBERT, a domain-adapted model achieving 23% improvement over BERT-base on a DLT-specific Named Entity Recognition (NER) task; and all associated tools and code.",
      "authors": [
        "Walter Hernandez Cruz",
        "Peter Devine",
        "Nikhil Vadgama",
        "Paolo Tasca",
        "Jiahua Xu"
      ],
      "url": "https://arxiv.org/abs/2602.22045",
      "published": "2026-02-25T15:53:41+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.22039",
      "title": "TG-ASR: Translation-Guided Learning with Parallel Gated Cross Attention for Low-Resource Automatic Speech Recognition",
      "abstract": "Low-resource automatic speech recognition (ASR) continues to pose significant challenges, primarily due to the limited availability of transcribed data for numerous languages. While a wealth of spoken content is accessible in television dramas and online videos, Taiwanese Hokkien exemplifies this issue, with transcriptions often being scarce and the majority of available subtitles provided only in Mandarin. To address this deficiency, we introduce TG-ASR for Taiwanese Hokkien drama speech recognition, a translation-guided ASR framework that utilizes multilingual translation embeddings to enhance recognition performance in low-resource environments. The framework is centered around the parallel gated cross-attention (PGCA) mechanism, which adaptively integrates embeddings from various auxiliary languages into the ASR decoder. This mechanism facilitates robust cross-linguistic semantic guidance while ensuring stable optimization and minimizing interference between languages. To support ongoing research initiatives, we present YT-THDC, a 30-hour corpus of Taiwanese Hokkien drama speech with aligned Mandarin subtitles and manually verified Taiwanese Hokkien transcriptions. Comprehensive experiments and analyses identify the auxiliary languages that most effectively enhance ASR performance, achieving a 14.77% relative reduction in character error rate and demonstrating the efficacy of translation-guided learning for underrepresented languages in practical applications.",
      "authors": [
        "Cheng-Yeh Yang",
        "Chien-Chun Wang",
        "Li-Wei Chen",
        "Hung-Shin Lee",
        "Hsin-Min Wang",
        "Berlin Chen"
      ],
      "url": "https://arxiv.org/abs/2602.22039",
      "published": "2026-02-25T15:47:34+00:00",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ]
    },
    {
      "id": "2602.22026",
      "title": "RGB-Event HyperGraph Prompt for Kilometer Marker Recognition based on Pre-trained Foundation Models",
      "abstract": "Metro trains often operate in highly complex environments, characterized by illumination variations, high-speed motion, and adverse weather conditions. These factors pose significant challenges for visual perception systems, especially those relying solely on conventional RGB cameras. To tackle these difficulties, we explore the integration of event cameras into the perception system, leveraging their advantages in low-light conditions, high-speed scenarios, and low power consumption. Specifically, we focus on Kilometer Marker Recognition (KMR), a critical task for autonomous metro localization under GNSS-denied conditions. In this context, we propose a robust baseline method based on a pre-trained RGB OCR foundation model, enhanced through multi-modal adaptation. Furthermore, we construct the first large-scale RGB-Event dataset, EvMetro5K, containing 5,599 pairs of synchronized RGB-Event samples, split into 4,479 training and 1,120 testing samples. Extensive experiments on EvMetro5K and other widely used benchmarks demonstrate the effectiveness of our approach for KMR. Both the dataset and source code will be released on https://github.com/Event-AHU/EvMetro5K_benchmark",
      "authors": [
        "Xiaoyu Xian",
        "Shiao Wang",
        "Xiao Wang",
        "Daxin Tian",
        "Yan Tian"
      ],
      "url": "https://arxiv.org/abs/2602.22026",
      "published": "2026-02-25T15:34:15+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.22018",
      "title": "Disease Progression and Subtype Modeling for Combined Discrete and Continuous Input Data",
      "abstract": "Disease progression modeling provides a robust framework to identify long-term disease trajectories from short-term biomarker data. It is a valuable tool to gain a deeper understanding of diseases with a long disease trajectory, such as Alzheimer's disease. A key limitation of most disease progression models is that they are specific to a single data type (e.g., continuous data), thereby limiting their applicability to heterogeneous, real-world datasets. To address this limitation, we propose the Mixed Events model, a novel disease progression model that handles both discrete and continuous data types. This model is implemented within the Subtype and Stage Inference (SuStaIn) framework, resulting in Mixed-SuStaIn, enabling subtype and progression modeling. We demonstrate the effectiveness of Mixed-SuStaIn through simulation experiments and real-world data from the Alzheimer's Disease Neuroimaging Initiative, showing that it performs well on mixed datasets. The code is available at: https://github.com/ucl-pond/pySuStaIn.",
      "authors": [
        "Sterre de Jonge",
        "Elisabeth J. Vinke",
        "Meike W. Vernooij",
        "Daniel C. Alexander",
        "Alexandra L. Young",
        "Esther E. Bron"
      ],
      "url": "https://arxiv.org/abs/2602.22018",
      "published": "2026-02-25T15:31:30+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.22015",
      "title": "Function-Space Empirical Bayes Regularisation with Student's t Priors",
      "abstract": "Bayesian deep learning (BDL) has emerged as a principled approach to produce reliable uncertainty estimates by integrating deep neural networks with Bayesian inference, and the selection of informative prior distributions remains a significant challenge. Various function-space variational inference (FSVI) regularisation methods have been presented, assigning meaningful priors over model predictions. However, these methods typically rely on a Gaussian prior, which fails to capture the heavy-tailed statistical characteristics inherent in neural network outputs. By contrast, this work proposes a novel function-space empirical Bayes regularisation framework -- termed ST-FS-EB -- which employs heavy-tailed Student's $t$ priors in both parameter and function spaces. Also, we approximate the posterior distribution through variational inference (VI), inducing an evidence lower bound (ELBO) objective based on Monte Carlo (MC) dropout. Furthermore, the proposed method is evaluated against various VI-based BDL baselines, and the results demonstrate its robust performance in in-distribution prediction, out-of-distribution (OOD) detection and handling distribution shifts.",
      "authors": [
        "Pengcheng Hao",
        "Ercan Engin Kuruoglu"
      ],
      "url": "https://arxiv.org/abs/2602.22015",
      "published": "2026-02-25T15:29:44+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.22014",
      "title": "A Diversity Diet for a Healthier Model: A Case Study of French ModernBERT",
      "abstract": "Diversity has been gaining interest in the NLP community in recent years. At the same time, state-of-the-art transformer models such as ModernBERT use very large pre-training datasets, which are driven by size rather than by diversity. This summons for an investigation of the impact of diversity on the ModernBERT pre-training. We do so in this study, with the express intent of reducing pre-training dataset size, while retaining at least comparable performance. We compare diversity-driven sampling algorithms, so as to pick the best one. We find that diversity-driven sampling allows in some tasks to gain 10 points relative to randomly-sampled pre-training data of commensurate size. We also see that a model pre-trained for 483h on a diversity-driven dataset of 150M tokens can yield a commensurate performance to a model pre-trained for 1,775h on a randomly-driven dataset of 2.4B tokens.",
      "authors": [
        "Louis Estève",
        "Christophe Servan",
        "Thomas Lavergne",
        "Agata Savary"
      ],
      "url": "https://arxiv.org/abs/2602.22014",
      "published": "2026-02-25T15:29:30+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.22003",
      "title": "Neural solver for Wasserstein Geodesics and optimal transport dynamics",
      "abstract": "In recent years, the machine learning community has increasingly embraced the optimal transport (OT) framework for modeling distributional relationships. In this work, we introduce a sample-based neural solver for computing the Wasserstein geodesic between a source and target distribution, along with the associated velocity field. Building on the dynamical formulation of the optimal transport (OT) problem, we recast the constrained optimization as a minimax problem, using deep neural networks to approximate the relevant functions. This approach not only provides the Wasserstein geodesic but also recovers the OT map, enabling direct sampling from the target distribution. By estimating the OT map, we obtain velocity estimates along particle trajectories, which in turn allow us to learn the full velocity field. The framework is flexible and readily extends to general cost functions, including the commonly used quadratic cost. We demonstrate the effectiveness of our method through experiments on both synthetic and real datasets.",
      "authors": [
        "Hailiang Liu",
        "Yan-Han Chen"
      ],
      "url": "https://arxiv.org/abs/2602.22003",
      "published": "2026-02-25T15:21:24+00:00",
      "categories": [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ]
    },
    {
      "id": "2602.21997",
      "title": "Enhancing LLM-Based Test Generation by Eliminating Covered Code",
      "abstract": "Automated test generation is essential for software quality assurance, with coverage rate serving as a key metric to ensure thorough testing. Recent advancements in Large Language Models (LLMs) have shown promise in improving test generation, particularly in achieving higher coverage. However, while existing LLM-based test generation solutions perform well on small, isolated code snippets, they struggle when applied to complex methods under test. To address these issues, we propose a scalable LLM-based unit test generation method. Our approach consists of two key steps. The first step is context information retrieval, which uses both LLMs and static analysis to gather relevant contextual information associated with the complex methods under test. The second step, iterative test generation with code elimination, repeatedly generates unit tests for the code slice, tracks the achieved coverage, and selectively removes code segments that have already been covered. This process simplifies the testing task and mitigates issues arising from token limits or reduced reasoning effectiveness associated with excessively long contexts. Through comprehensive evaluations on open-source projects, our approach outperforms state-of-the-art LLM-based and search-based methods, demonstrating its effectiveness in achieving high coverage on complex methods.",
      "authors": [
        "WeiZhe Xu",
        "Mengyu Liu",
        "Fanxin Kong"
      ],
      "url": "https://arxiv.org/abs/2602.21997",
      "published": "2026-02-25T15:16:43+00:00",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.21995",
      "title": "Outpatient Appointment Scheduling Optimization with a Genetic Algorithm Approach",
      "abstract": "The optimization of complex medical appointment scheduling remains a significant operational challenge in multi-center healthcare environments, where clinical safety protocols and patient logistics must be reconciled. This study proposes and evaluates a Genetic Algorithm (GA) framework designed to automate the scheduling of multiple medical acts while adhering to rigorous inter-procedural incompatibility rules. Using a synthetic dataset encompassing 50 medical acts across four healthcare facilities, we compared two GA variants, Pre-Ordered and Unordered, against deterministic First-Come, First-Served (FCFS) and Random Choice baselines. Our results demonstrate that the GA framework achieved a 100% constraint fulfillment rate, effectively resolving temporal overlaps and clinical incompatibilities that the FCFS baseline failed to address in 60% and 40% of cases, respectively. Furthermore, the GA variants demonstrated statistically significant improvements (p < 0.001) in patient-centric metrics, achieving an Idle Time Ratio (ITR) frequently below 0.4 and reducing inter-healthcenter trips. While the GA (Ordered) variant provided a superior initial search locus, both evolutionary models converged to comparable global optima by the 100th generation. These findings suggest that transitioning from manual, human-mediated scheduling to an automated metaheuristic approach enhances clinical integrity, reduces administrative overhead, and significantly improves the patient experience by minimizing wait times and logistical burdens.",
      "authors": [
        "Ana Rodrigues",
        "Rui Rego"
      ],
      "url": "https://arxiv.org/abs/2602.21995",
      "published": "2026-02-25T15:15:57+00:00",
      "categories": [
        "cs.NE",
        "cs.LG"
      ]
    },
    {
      "id": "2602.21987",
      "title": "PatchDenoiser: Parameter-efficient multi-scale patch learning and fusion denoiser for medical images",
      "abstract": "Medical images are essential for diagnosis, treatment planning, and research, but their quality is often degraded by noise from low-dose acquisition, patient motion, or scanner limitations, affecting both clinical interpretation and downstream analysis. Traditional filtering approaches often over-smooth and lose fine anatomical details, while deep learning methods, including CNNs, GANs, and transformers, may struggle to preserve such details or require large, computationally expensive models, limiting clinical practicality.   We propose PatchDenoiser, a lightweight, energy-efficient multi-scale patch-based denoising framework. It decomposes denoising into local texture extraction and global context aggregation, fused via a spatially aware patch fusion strategy. This design enables effective noise suppression while preserving fine structural and anatomical details. PatchDenoiser is ultra-lightweight, with far fewer parameters and lower computational complexity than CNN-, GAN-, and transformer-based denoisers.   On the 2016 Mayo Low-Dose CT dataset, PatchDenoiser consistently outperforms state-of-the-art CNN- and GAN-based methods in PSNR and SSIM. It is robust to variations in slice thickness, reconstruction kernels, and HU windows, generalizes across scanners without fine-tuning, and reduces parameters by ~9x and energy consumption per inference by ~27x compared with conventional CNN denoisers.   PatchDenoiser thus provides a practical, scalable, and computationally efficient solution for medical image denoising, balancing performance, robustness, and clinical deployability.",
      "authors": [
        "Jitindra Fartiyal",
        "Pedro Freire",
        "Sergei K. Turitsyn",
        "Sergei G. Solovski"
      ],
      "url": "https://arxiv.org/abs/2602.21987",
      "published": "2026-02-25T15:08:43+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    }
  ]
}
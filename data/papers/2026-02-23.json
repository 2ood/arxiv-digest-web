{
  "date": "2026-02-23",
  "fetched_at": "2026-02-27T09:27:20.974615+09:00",
  "papers": [
    {
      "id": "2602.19919",
      "title": "Janus-Q: End-to-End Event-Driven Trading via Hierarchical-Gated Reward Modeling",
      "abstract": "Financial market movements are often driven by discrete financial events conveyed through news, whose impacts are heterogeneous, abrupt, and difficult to capture under purely numerical prediction objectives. These limitations have motivated growing interest in using textual information as the primary source of trading signals in learning-based systems. Two key challenges hinder existing approaches: (1) the absence of large-scale, event-centric datasets that jointly model news semantics and statistically grounded market reactions, and (2) the misalignment between language model reasoning and financially valid trading behavior under dynamic market conditions. To address these challenges, we propose Janus-Q, an end-to-end event-driven trading framework that elevates financial news events from auxiliary signals to primary decision units. Janus-Q unifies event-centric data construction and model optimization under a two-stage paradigm. Stage I focuses on event-centric data construction, building a large-scale financial news event dataset comprising 62,400 articles annotated with 10 fine-grained event types, associated stocks, sentiment labels, and event-driven cumulative abnormal return (CAR). Stage II performs decision-oriented fine-tuning, combining supervised learning with reinforcement learning guided by a Hierarchical Gated Reward Model (HGRM), which explicitly captures trade-offs among multiple trading objectives. Extensive experiments demonstrate that Janus-Q achieves more consistent, interpretable, and profitable trading decisions than market indices and LLM baselines, improving the Sharpe Ratio by up to 102.0% while increasing direction accuracy by over 17.5% compared to the strongest competing strategies.",
      "authors": [
        "Xiang Li",
        "Zikai Wei",
        "Yiyan Qi",
        "Wanyun Zhou",
        "Xiang Liu",
        "Penglei Sun",
        "Yongqi Zhang",
        "Xiaowen Chu"
      ],
      "url": "https://arxiv.org/abs/2602.19919",
      "published": "2026-02-23T14:58:51+00:00",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19918",
      "title": "RobPI: Robust Private Inference against Malicious Client",
      "abstract": "The increased deployment of machine learning inference in various applications has sparked privacy concerns. In response, private inference (PI) protocols have been created to allow parties to perform inference without revealing their sensitive data. Despite recent advances in the efficiency of PI, most current methods assume a semi-honest threat model where the data owner is honest and adheres to the protocol. However, in reality, data owners can have different motivations and act in unpredictable ways, making this assumption unrealistic. To demonstrate how a malicious client can compromise the semi-honest model, we first designed an inference manipulation attack against a range of state-of-the-art private inference protocols. This attack allows a malicious client to modify the model output with 3x to 8x fewer queries than current black-box attacks. Motivated by the attacks, we proposed and implemented RobPI, a robust and resilient private inference protocol that withstands malicious clients. RobPI integrates a distinctive cryptographic protocol that bolsters security by weaving encryption-compatible noise into the logits and features of private inference, thereby efficiently warding off malicious-client attacks. Our extensive experiments on various neural networks and datasets show that RobPI achieves ~91.9% attack success rate reduction and increases more than 10x the number of queries required by malicious-client attacks.",
      "authors": [
        "Jiaqi Xue",
        "Mengxin Zheng",
        "Qian Lou"
      ],
      "url": "https://arxiv.org/abs/2602.19918",
      "published": "2026-02-23T14:58:08+00:00",
      "categories": [
        "cs.CR",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19917",
      "title": "Uncertainty-Aware Rank-One MIMO Q Network Framework for Accelerated Offline Reinforcement Learning",
      "abstract": "Offline reinforcement learning (RL) has garnered significant interest due to its safe and easily scalable paradigm. However, training under this paradigm presents its own challenge: the extrapolation error stemming from out-of-distribution (OOD) data. Existing methodologies have endeavored to address this issue through means like penalizing OOD Q-values or imposing similarity constraints on the learned policy and the behavior policy. Nonetheless, these approaches are often beset by limitations such as being overly conservative in utilizing OOD data, imprecise OOD data characterization, and significant computational overhead. To address these challenges, this paper introduces an Uncertainty-Aware Rank-One Multi-Input Multi-Output (MIMO) Q Network framework. The framework aims to enhance Offline Reinforcement Learning by fully leveraging the potential of OOD data while still ensuring efficiency in the learning process. Specifically, the framework quantifies data uncertainty and harnesses it in the training losses, aiming to train a policy that maximizes the lower confidence bound of the corresponding Q-function. Furthermore, a Rank-One MIMO architecture is introduced to model the uncertainty-aware Q-function, \\TP{offering the same ability for uncertainty quantification as an ensemble of networks but with a cost nearly equivalent to that of a single network}. Consequently, this framework strikes a harmonious balance between precision, speed, and memory efficiency, culminating in improved overall performance. Extensive experimentation on the D4RL benchmark demonstrates that the framework attains state-of-the-art performance while remaining computationally efficient. By incorporating the concept of uncertainty quantification, our framework offers a promising avenue to alleviate extrapolation errors and enhance the efficiency of offline RL.",
      "authors": [
        "Thanh Nguyen",
        "Tung Luu",
        "Tri Ton",
        "Sungwoong Kim",
        "Chang D. Yoo"
      ],
      "url": "https://arxiv.org/abs/2602.19917",
      "published": "2026-02-23T14:57:52+00:00",
      "categories": [
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "id": "2602.19915",
      "title": "Fully Convolutional Spatiotemporal Learning for Microstructure Evolution Prediction",
      "abstract": "Understanding and predicting microstructure evolution is fundamental to materials science, as it governs the resulting properties and performance of materials. Traditional simulation methods, such as phase-field models, offer high-fidelity results but are computationally expensive due to the need to solve complex partial differential equations at fine spatiotemporal resolutions. To address this challenge, we propose a deep learning-based framework that accelerates microstructure evolution predictions while maintaining high accuracy. Our approach utilizes a fully convolutional spatiotemporal model trained in a self-supervised manner using sequential images generated from simulations of microstructural processes, including grain growth and spinodal decomposition. The trained neural network effectively learns the underlying physical dynamics and can accurately capture both short-term local behaviors and long-term statistical properties of evolving microstructures, while also demonstrating generalization to unseen spatiotemporal domains and variations in configuration and material parameters. Compared to recurrent neural architectures, our model achieves state-of-the-art predictive performance with significantly reduced computational cost in both training and inference. This work establishes a robust baseline for spatiotemporal learning in materials science and offers a scalable, data-driven alternative for fast and reliable microstructure simulations.",
      "authors": [
        "Michael Trimboli",
        "Mohammed Alsubaie",
        "Sirani M. Perera",
        "Ke-Gang Wang",
        "Xianqi Li"
      ],
      "url": "https://arxiv.org/abs/2602.19915",
      "published": "2026-02-23T14:55:28+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19914",
      "title": "Watson & Holmes: A Naturalistic Benchmark for Comparing Human and LLM Reasoning",
      "abstract": "Existing benchmarks for AI reasoning provide limited insight into how closely these capabilities resemble human reasoning in naturalistic contexts. We present an adaptation of the Watson & Holmes detective tabletop game as a new benchmark designed to evaluate reasoning performance using incrementally presented narrative evidence, open-ended questions and unconstrained language responses. An automated grading system was developed and validated against human assessors to enable scalable and replicable performance evaluation. Results show a clear improvement in AI model performance over time. Over nine months of 2025, model performance rose from the lower quartile of the human comparison group to approximately the top 5%. Around half of this improvement reflects steady advancement across successive model releases, while the remainder corresponds to a marked step change associated with reasoning-oriented model architectures. Systematic differences in the performance of AI models compared to humans, dependent on features of the specific detection puzzle, were mostly absent with the exception of a fall in performance for models when solving longer cases (case lengths being in the range of 1900-4000 words), and an advantage at inductive reasoning for reasoning models at early stages of case solving when evidence was scant.",
      "authors": [
        "Thatchawin Leelawat",
        "Lewis D Griffin"
      ],
      "url": "https://arxiv.org/abs/2602.19914",
      "published": "2026-02-23T14:54:38+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.19912",
      "title": "De novo molecular structure elucidation from mass spectra via flow matching",
      "abstract": "Mass spectrometry is a powerful and widely used tool for identifying molecular structures due to its sensitivity and ability to profile complex samples. However, translating spectra into full molecular structures is a difficult, under-defined inverse problem. Overcoming this problem is crucial for enabling biological insight, discovering new metabolites, and advancing chemical research across multiple fields. To this end, we develop MSFlow, a two-stage encoder-decoder flow-matching generative model that achieves state-of-the-art performance on the structure elucidation task for small molecules. In the first stage, we adopt a formula-restricted transformer model for encoding mass spectra into a continuous and chemically informative embedding space, while in the second stage, we train a decoder flow matching model to reconstruct molecules from latent embeddings of mass spectra. We present ablation studies demonstrating the importance of using information-preserving molecular descriptors for encoding mass spectra and motivate the use of our discrete flow-based decoder. Our rigorous evaluation demonstrates that MSFlow can accurately translate up to 45 percent of molecular mass spectra into their corresponding molecular representations - an improvement of up to fourteen-fold over the current state-of-the-art. A trained version of MSFlow is made publicly available on GitHub for non-commercial users.",
      "authors": [
        "Ghaith Mqawass",
        "Tuan Le",
        "Fabian Theis",
        "Djork-Arné Clevert"
      ],
      "url": "https://arxiv.org/abs/2602.19912",
      "published": "2026-02-23T14:52:53+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19907",
      "title": "Gradient based Severity Labeling for Biomarker Classification in OCT",
      "abstract": "In this paper, we propose a novel selection strategy for contrastive learning for medical images. On natural images, contrastive learning uses augmentations to select positive and negative pairs for the contrastive loss. However, in the medical domain, arbitrary augmentations have the potential to distort small localized regions that contain the biomarkers we are interested in detecting. A more intuitive approach is to select samples with similar disease severity characteristics, since these samples are more likely to have similar structures related to the progression of a disease. To enable this, we introduce a method that generates disease severity labels for unlabeled OCT scans on the basis of gradient responses from an anomaly detection algorithm. These labels are used to train a supervised contrastive learning setup to improve biomarker classification accuracy by as much as 6% above self-supervised baselines for key indicators of Diabetic Retinopathy.",
      "authors": [
        "Kiran Kokilepersaud",
        "Mohit Prabhushankar",
        "Ghassan AlRegib",
        "Stephanie Trejo Corona",
        "Charles Wykoff"
      ],
      "url": "https://arxiv.org/abs/2602.19907",
      "published": "2026-02-23T14:46:08+00:00",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19903",
      "title": "Rethinking Chronological Causal Discovery with Signal Processing",
      "abstract": "Causal discovery problems use a set of observations to deduce causality between variables in the real world, typically to answer questions about biological or physical systems. These observations are often recorded at regular time intervals, determined by a user or a machine, depending on the experiment design. There is generally no guarantee that the timing of these recordings matches the timing of the underlying biological or physical events. In this paper, we examine the sensitivity of causal discovery methods to this potential mismatch. We consider empirical and theoretical evidence to understand how causal discovery performance is impacted by changes of sampling rate and window length. We demonstrate that both classical and recent causal discovery methods exhibit sensitivity to these hyperparameters, and we discuss how ideas from signal processing may help us understand these phenomena.",
      "authors": [
        "Kurt Butler",
        "Damian Machlanski",
        "Panagiotis Dimitrakopoulos",
        "Sotirios A. Tsaftaris"
      ],
      "url": "https://arxiv.org/abs/2602.19903",
      "published": "2026-02-23T14:43:15+00:00",
      "categories": [
        "eess.SP",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19895",
      "title": "DSDR: Dual-Scale Diversity Regularization for Exploration in LLM Reasoning",
      "abstract": "Reinforcement learning with verifiers (RLVR) is a central paradigm for improving large language model (LLM) reasoning, yet existing methods often suffer from limited exploration. Policies tend to collapse onto a few reasoning patterns and prematurely stop deep exploration, while conventional entropy regularization introduces only local stochasticity and fails to induce meaningful path-level diversity, leading to weak and unstable learning signals in group-based policy optimization. We propose DSDR, a Dual-Scale Diversity Regularization reinforcement learning framework that decomposes diversity in LLM reasoning into global and coupling components. Globally, DSDR promotes diversity among correct reasoning trajectories to explore distinct solution modes. Locally, it applies a length-invariant, token-level entropy regularization restricted to correct trajectories, preventing entropy collapse within each mode while preserving correctness. The two scales are coupled through a global-to-local allocation mechanism that emphasizes local regularization for more distinctive correct trajectories. We provide theoretical support showing that DSDR preserves optimal correctness under bounded regularization, sustains informative learning signals in group-based optimization, and yields a principled global-to-local coupling rule. Experiments on multiple reasoning benchmarks demonstrate consistent improvements in accuracy and pass@k, highlighting the importance of dual-scale diversity for deep exploration in RLVR. Code is available at https://github.com/SUSTechBruce/DSDR.",
      "authors": [
        "Zhongwei Wan",
        "Yun Shen",
        "Zhihao Dou",
        "Donghao Zhou",
        "Yu Zhang",
        "Xin Wang",
        "Hui Shen",
        "Jing Xiong",
        "Chaofan Tao",
        "Zixuan Zhong",
        "Peizhou Huang",
        "Mi Zhang"
      ],
      "url": "https://arxiv.org/abs/2602.19895",
      "published": "2026-02-23T14:37:01+00:00",
      "categories": [
        "cs.LG",
        "cs.CL"
      ]
    },
    {
      "id": "2602.19893",
      "title": "Generalized Random Direction Newton Algorithms for Stochastic Optimization",
      "abstract": "We present a family of generalized Hessian estimators of the objective using random direction stochastic approximation (RDSA) by utilizing only noisy function measurements. The form of each estimator and the order of the bias depend on the number of function measurements. In particular, we demonstrate that estimators with more function measurements exhibit lower-order estimation bias. We show the asymptotic unbiasedness of the estimators. We also perform asymptotic and non-asymptotic convergence analyses for stochastic Newton methods that incorporate our generalized Hessian estimators. Finally, we perform numerical experiments to validate our theoretical findings.",
      "authors": [
        "Soumen Pachal",
        "Prashanth L. A.",
        "Shalabh Bhatnagar",
        "Avinash Achar"
      ],
      "url": "https://arxiv.org/abs/2602.19893",
      "published": "2026-02-23T14:33:39+00:00",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19883",
      "title": "Denotational Semantics for ODRL: Knowledge-Based Constraint Conflict Detection",
      "abstract": "ODRL's six set-based operators -- isA, isPartOf, hasPart, isAnyOf, isAllOf, isNoneOf -- depend on external domain knowledge that the W3C specification leaves unspecified. Without it, every cross-dataspace policy comparison defaults to Unknown. We present a denotational semantics that maps each ODRL constraint to the set of knowledge-base concepts satisfying it. Conflict detection reduces to denotation intersection under a three-valued verdict -- Conflict, Compatible, or Unknown -- that is sound under incomplete knowledge. The framework covers all three ODRL composition modes (and, or, xone) and all three semantic domains arising in practice: taxonomic (class subsumption), mereological (part-whole containment), and nominal (identity). For cross-dataspace interoperability, we define order-preserving alignments between knowledge bases and prove two guarantees: conflicts are preserved across different KB standards, and unmapped concepts degrade gracefully to Unknown -- never to false conflicts. A runtime soundness theorem ensures that design-time verdicts hold for all execution contexts. The encoding stays within the decidable EPR fragment of first-order logic. We validate it with 154 benchmarks across six knowledge base families (GeoNames, ISO 3166, W3C DPV, a GDPR-derived taxonomy, BCP 47, and ISO 639-3) and four structural KBs targeting adversarial edge cases. Both the Vampire theorem prover and the Z3 SMT solver agree on all 154 verdicts. A key finding is that exclusive composition (xone) requires strictly stronger KB axioms than conjunction or disjunction: open-world semantics blocks exclusivity even when positive evidence appears to satisfy exactly one branch.",
      "authors": [
        "Daham Mustafa",
        "Diego Collarana",
        "Yixin Peng",
        "Rafiqul Haque",
        "Christoph Lange-Bever",
        "Christoph Quix",
        "Stephan Decker"
      ],
      "url": "https://arxiv.org/abs/2602.19883",
      "published": "2026-02-23T14:28:13+00:00",
      "categories": [
        "cs.CL",
        "cs.LO"
      ]
    },
    {
      "id": "2602.19881",
      "title": "Make Some Noise: Unsupervised Remote Sensing Change Detection Using Latent Space Perturbations",
      "abstract": "Unsupervised change detection (UCD) in remote sensing aims to localise semantic changes between two images of the same region without relying on labelled data during training. Most recent approaches rely either on frozen foundation models in a training-free manner or on training with synthetic changes generated in pixel space. Both strategies inherently rely on predefined assumptions about change types, typically introduced through handcrafted rules, external datasets, or auxiliary generative models. Due to these assumptions, such methods fail to generalise beyond a few change types, limiting their real-world usage, especially in rare or complex scenarios. To address this, we propose MaSoN (Make Some Noise), an end-to-end UCD framework that synthesises diverse changes directly in the latent feature space during training. It generates changes that are dynamically estimated using feature statistics of target data, enabling diverse yet data-driven variation aligned with the target domain. It also easily extends to new modalities, such as SAR. MaSoN generalises strongly across diverse change types and achieves state-of-the-art performance on five benchmarks, improving the average F1 score by 14.1 percentage points. Project page: https://blaz-r.github.io/mason_ucd",
      "authors": [
        "Blaž Rolih",
        "Matic Fučka",
        "Filip Wolf",
        "Luka Čehovin Zajc"
      ],
      "url": "https://arxiv.org/abs/2602.19881",
      "published": "2026-02-23T14:27:36+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19878",
      "title": "Axis Decomposition for ODRL: Resolving Dimensional Ambiguity in Policy Constraints through Interval Semantics",
      "abstract": "Every ODRL 2.2 constraint compares a single scalar value: (leftOperand, operator, rightOperand). Five of ODRL's left operands, however, denote multi-dimensional quantities--image dimensions, canvas positions, geographic coordinates--whose specification text explicitly references multiple axes. For these operands, a single scalar constraint admits one interpretation per axis, making policy evaluation non-deterministic.   We classify ODRL's left operands by value-domain structure (scalar, dimensional, concept-valued), grounded in the ODRL 2.2 specification text, and show that dimensional ambiguity is intrinsic to the constraint syntax. We present an axis-decomposition framework that refines each dimensional operand into axis-specific scalar operands and prove four properties: deterministic interpretation, AABB completeness, projection soundness, and conservative extension.   Conflict detection operates in two layers: per-axis verdicts are always decidable; box-level verdicts compose through Strong Kleene conjunction into a three-valued logic (Conflict, Compatible, Unknown). For ODRL's disjunctive (odrl:or) and exclusive-or (odrl:xone) logical constraints, where per-axis decomposition does not apply, the framework encodes coupled multi-axis conjectures directly.   We instantiate the framework as the ODRL Spatial Axis Profile--15 axis-specific left operands for the five affected base terms--and evaluate it on 117 benchmark problems spanning nine categories across both TPTP FOF (Vampire) and SMT-LIB (Z3) encodings, achieving full concordance between provers. Benchmark scenarios are inspired by constraints arising in cultural heritage dataspaces such as Datenraum Kultur. All meta-theorems are mechanically verified in Isabelle/HOL.",
      "authors": [
        "Daham Mustafa",
        "Diego Collarana",
        "Yixin Peng",
        "Rafiqul Haque",
        "Christoph Lange-Bever",
        "Christoph Quix",
        "Stephan Decker"
      ],
      "url": "https://arxiv.org/abs/2602.19878",
      "published": "2026-02-23T14:24:46+00:00",
      "categories": [
        "cs.CL",
        "cs.LO"
      ]
    },
    {
      "id": "2602.19872",
      "title": "GOAL: Geometrically Optimal Alignment for Continual Generalized Category Discovery",
      "abstract": "Continual Generalized Category Discovery (C-GCD) requires identifying novel classes from unlabeled data while retaining knowledge of known classes over time. Existing methods typically update classifier weights dynamically, resulting in forgetting and inconsistent feature alignment. We propose GOAL, a unified framework that introduces a fixed Equiangular Tight Frame (ETF) classifier to impose a consistent geometric structure throughout learning. GOAL conducts supervised alignment for labeled samples and confidence-guided alignment for novel samples, enabling stable integration of new classes without disrupting old ones. Experiments on four benchmarks show that GOAL outperforms the prior method Happy, reducing forgetting by 16.1% and boosting novel class discovery by 3.2%, establishing a strong solution for long-horizon continual discovery.",
      "authors": [
        "Jizhou Han",
        "Chenhao Ding",
        "SongLin Dong",
        "Yuhang He",
        "Shaokun Wang",
        "Qiang Wang",
        "Yihong Gong"
      ],
      "url": "https://arxiv.org/abs/2602.19872",
      "published": "2026-02-23T14:15:56+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19859",
      "title": "Dirichlet Scale Mixture Priors for Bayesian Neural Networks",
      "abstract": "Neural networks are the cornerstone of modern machine learning, yet can be difficult to interpret, give overconfident predictions and are vulnerable to adversarial attacks. Bayesian neural networks (BNNs) provide some alleviation of these limitations, but have problems of their own. The key step of specifying prior distributions in BNNs is no trivial task, yet is often skipped out of convenience. In this work, we propose a new class of prior distributions for BNNs, the Dirichlet scale mixture (DSM) prior, that addresses current limitations in Bayesian neural networks through structured, sparsity-inducing shrinkage. Theoretically, we derive general dependence structures and shrinkage results for DSM priors and show how they manifest under the geometry induced by neural networks. In experiments on simulated and real world data we find that the DSM priors encourages sparse networks through implicit feature selection, show robustness under adversarial attacks and deliver competitive predictive performance with substantially fewer effective parameters. In particular, their advantages appear most pronounced in correlated, moderately small data regimes, and are more amenable to weight pruning. Moreover, by adopting heavy-tailed shrinkage mechanisms, our approach aligns with recent findings that such priors can mitigate the cold posterior effect, offering a principled alternative to the commonly used Gaussian priors.",
      "authors": [
        "August Arnstad",
        "Leiv Rønneberg",
        "Geir Storvik"
      ],
      "url": "https://arxiv.org/abs/2602.19859",
      "published": "2026-02-23T13:58:16+00:00",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19855",
      "title": "SHIELD: Semantic Heterogeneity Integrated Embedding for Latent Discovery in Clinical Trial Safety Signals",
      "abstract": "We present SHIELD, a novel methodology for automated and integrated safety signal detection in clinical trials. SHIELD combines disproportionality analysis with semantic clustering of adverse event (AE) terms applied to MedDRA term embeddings. For each AE, the pipeline computes an information-theoretic disproportionality measure (Information Component) with effect size derived via empirical Bayesian shrinkage. A utility matrix is constructed by weighting semantic term-term similarities by signal magnitude, followed by spectral embedding and clustering to identify groups of related AEs. Resulting clusters are annotated with syndrome-level summary labels using large language models, yielding a coherent, data-driven representation of treatment-associated safety profiles in the form of a network graph and hierarchical tree. We implement the SHIELD framework in the context of a single-arm incidence summary, to compare two treatment arms or for the detection of any treatment effect in a multi-arm trial. We illustrate its ability to recover known safety signals and generate interpretable, cluster-based summaries in a real clinical trial example. This work bridges statistical signal detection with modern natural language processing to enhance safety assessment and causal interpretation in clinical trials.",
      "authors": [
        "Francois Vandenhende",
        "Anna Georgiou",
        "Theodoros Psaras",
        "Ellie Karekla"
      ],
      "url": "https://arxiv.org/abs/2602.19855",
      "published": "2026-02-23T13:55:36+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.19851",
      "title": "Orthogonal Uplift Learning with Permutation-Invariant Representations for Combinatorial Treatments",
      "abstract": "We study uplift estimation for combinatorial treatments. Uplift measures the pure incremental causal effect of an intervention (e.g., sending a coupon or a marketing message) on user behavior, modeled as a conditional individual treatment effect. Many real-world interventions are combinatorial: a treatment is a policy that specifies context-dependent action distributions rather than a single atomic label. Although recent work considers structured treatments, most methods rely on categorical or opaque encodings, limiting robustness and generalization to rare or newly deployed policies. We propose an uplift estimation framework that aligns treatment representation with causal semantics. Each policy is represented by the mixture it induces over contextaction components and embedded via a permutation-invariant aggregation. This representation is integrated into an orthogonalized low-rank uplift model, extending Robinson-style decompositions to learned, vector-valued treatments. We show that the resulting estimator is expressive for policy-induced causal effects, orthogonally robust to nuisance estimation errors, and stable under small policy perturbations. Experiments on large-scale randomized platform data demonstrate improved uplift accuracy and stability in long-tailed policy regimes",
      "authors": [
        "Xinyan Su",
        "Jiacan Gao",
        "Mingyuan Ma",
        "Xiao Xu",
        "Xinrui Wan",
        "Tianqi Gu",
        "Enyun Yu",
        "Jiecheng Guo",
        "Zhiheng Zhang"
      ],
      "url": "https://arxiv.org/abs/2602.19851",
      "published": "2026-02-23T13:54:12+00:00",
      "categories": [
        "stat.ME",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19845",
      "title": "I Dropped a Neural Net",
      "abstract": "A recent Dwarkesh Patel podcast with John Collison and Elon Musk featured an interesting puzzle from Jane Street: they trained a neural net, shuffled all 96 layers, and asked to put them back in order.   Given unlabelled layers of a Residual Network and its training dataset, we recover the exact ordering of the layers. The problem decomposes into pairing each block's input and output projections ($48!$ possibilities) and ordering the reassembled blocks ($48!$ possibilities), for a combined search space of $(48!)^2 \\approx 10^{122}$, which is more than the atoms in the observable universe. We show that stability conditions during training like dynamic isometry leave the product $W_{\\text{out}} W_{\\text{in}}$ for correctly paired layers with a negative diagonal structure, allowing us to use diagonal dominance ratio as a signal for pairing. For ordering, we seed-initialize with a rough proxy such as delta-norm or $\\|W_{\\text{out}}\\|_F$ then hill-climb to zero mean squared error.",
      "authors": [
        "Hyunwoo Park"
      ],
      "url": "https://arxiv.org/abs/2602.19845",
      "published": "2026-02-23T13:49:05+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19844",
      "title": "LLM-enabled Applications Require System-Level Threat Monitoring",
      "abstract": "LLM-enabled applications are rapidly reshaping the software ecosystem by using large language models as core reasoning components for complex task execution. This paradigm shift, however, introduces fundamentally new reliability challenges and significantly expands the security attack surface, due to the non-deterministic, learning-driven, and difficult-to-verify nature of LLM behavior. In light of these emerging and unavoidable safety challenges, we argue that such risks should be treated as expected operational conditions rather than exceptional events, necessitating a dedicated incident-response perspective. Consequently, the primary barrier to trustworthy deployment is not further improving model capability but establishing system-level threat monitoring mechanisms that can detect and contextualize security-relevant anomalies after deployment -- an aspect largely underexplored beyond testing or guardrail-based defenses. Accordingly, this position paper advocates systematic and comprehensive monitoring of security threats in LLM-enabled applications as a prerequisite for reliable operation and a foundation for dedicated incident-response frameworks.",
      "authors": [
        "Yedi Zhang",
        "Haoyu Wang",
        "Xianglin Yang",
        "Jin Song Dong",
        "Jun Sun"
      ],
      "url": "https://arxiv.org/abs/2602.19844",
      "published": "2026-02-23T13:48:36+00:00",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "id": "2602.19843",
      "title": "MAS-FIRE: Fault Injection and Reliability Evaluation for LLM-Based Multi-Agent Systems",
      "abstract": "As LLM-based Multi-Agent Systems (MAS) are increasingly deployed for complex tasks, ensuring their reliability has become a pressing challenge. Since MAS coordinate through unstructured natural language rather than rigid protocols, they are prone to semantic failures (e.g., hallucinations, misinterpreted instructions, and reasoning drift) that propagate silently without raising runtime exceptions. Prevailing evaluation approaches, which measure only end-to-end task success, offer limited insight into how these failures arise or how effectively agents recover from them. To bridge this gap, we propose MAS-FIRE, a systematic framework for fault injection and reliability evaluation of MAS. We define a taxonomy of 15 fault types covering intra-agent cognitive errors and inter-agent coordination failures, and inject them via three non-invasive mechanisms: prompt modification, response rewriting, and message routing manipulation. Applying MAS-FIRE to three representative MAS architectures, we uncover a rich set of fault-tolerant behaviors that we organize into four tiers: mechanism, rule, prompt, and reasoning. This tiered view enables fine-grained diagnosis of where and why systems succeed or fail. Our findings reveal that stronger foundation models do not uniformly improve robustness. We further show that architectural topology plays an equally decisive role, with iterative, closed-loop designs neutralizing over 40% of faults that cause catastrophic collapse in linear workflows. MAS-FIRE provides the process-level observability and actionable guidance needed to systematically improve multi-agent systems.",
      "authors": [
        "Jin Jia",
        "Zhiling Deng",
        "Zhuangbin Chen",
        "Yingqi Wang",
        "Zibin Zheng"
      ],
      "url": "https://arxiv.org/abs/2602.19843",
      "published": "2026-02-23T13:47:43+00:00",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19840",
      "title": "SAMAS: A Spectrum-Guided Multi-Agent System for Achieving Style Fidelity in Literary Translation",
      "abstract": "Modern large language models (LLMs) excel at generating fluent and faithful translations. However, they struggle to preserve an author's unique literary style, often producing semantically correct but generic outputs. This limitation stems from the inability of current single-model and static multi-agent systems to perceive and adapt to stylistic variations. To address this, we introduce the Style-Adaptive Multi-Agent System (SAMAS), a novel framework that treats style preservation as a signal processing task. Specifically, our method quantifies literary style into a Stylistic Feature Spectrum (SFS) using the wavelet packet transform. This SFS serves as a control signal to dynamically assemble a tailored workflow of specialized translation agents based on the source text's structural patterns. Extensive experiments on translation benchmarks show that SAMAS achieves competitive semantic accuracy against strong baselines, primarily by leveraging its statistically significant advantage in style fidelity.",
      "authors": [
        "Jingzhuo Wu",
        "Jiajun Zhang",
        "Keyan Jin",
        "Dehua Ma",
        "Junbo Wang"
      ],
      "url": "https://arxiv.org/abs/2602.19840",
      "published": "2026-02-23T13:40:44+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.19837",
      "title": "Meta-Learning and Meta-Reinforcement Learning - Tracing the Path towards DeepMind's Adaptive Agent",
      "abstract": "Humans are highly effective at utilizing prior knowledge to adapt to novel tasks, a capability that standard machine learning models struggle to replicate due to their reliance on task-specific training. Meta-learning overcomes this limitation by allowing models to acquire transferable knowledge from various tasks, enabling rapid adaptation to new challenges with minimal data. This survey provides a rigorous, task-based formalization of meta-learning and meta-reinforcement learning and uses that paradigm to chronicle the landmark algorithms that paved the way for DeepMind's Adaptive Agent, consolidating the essential concepts needed to understand the Adaptive Agent and other generalist approaches.",
      "authors": [
        "Björn Hoppmann",
        "Christoph Scholz"
      ],
      "url": "https://arxiv.org/abs/2602.19837",
      "published": "2026-02-23T13:39:58+00:00",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.20223",
      "title": "MultiModalPFN: Extending Prior-Data Fitted Networks for Multimodal Tabular Learning",
      "abstract": "Recently, TabPFN has gained attention as a foundation model for tabular data. However, it struggles to integrate heterogeneous modalities such as images and text, which are common in domains like healthcare and marketing, thereby limiting its applicability. To address this, we present the Multi-Modal Prior-data Fitted Network (MMPFN), which extends TabPFN to handle tabular and non-tabular modalities in a unified manner. MMPFN comprises per-modality encoders, modality projectors, and pre-trained foundation models. The modality projectors serve as the critical bridge, transforming non-tabular embeddings into tabular-compatible tokens for unified processing. To this end, we introduce a multi-head gated MLP and a cross-attention pooler that extract richer context from non-tabular inputs while mitigates attention imbalance issue in multimodal learning. Extensive experiments on medical and general-purpose multimodal datasets demonstrate that MMPFN consistently outperforms competitive state-of-the-art methods and effectively exploits non-tabular modalities alongside tabular features. These results highlight the promise of extending prior-data fitted networks to the multimodal setting, offering a scalable and effective framework for heterogeneous data learning. The source code is available at https://github.com/too-z/MultiModalPFN.",
      "authors": [
        "Wall Kim",
        "Chaeyoung Song",
        "Hanul Kim"
      ],
      "url": "https://arxiv.org/abs/2602.20223",
      "published": "2026-02-23T13:37:44+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19822",
      "title": "Efficient endometrial carcinoma screening via cross-modal synthesis and gradient distillation",
      "abstract": "Early detection of myometrial invasion is critical for the staging and life-saving management of endometrial carcinoma (EC), a prevalent global malignancy. Transvaginal ultrasound serves as the primary, accessible screening modality in resource-constrained primary care settings; however, its diagnostic reliability is severely hindered by low tissue contrast, high operator dependence, and a pronounced scarcity of positive pathological samples. Existing artificial intelligence solutions struggle to overcome this severe class imbalance and the subtle imaging features of invasion, particularly under the strict computational limits of primary care clinics. Here we present an automated, highly efficient two-stage deep learning framework that resolves both data and computational bottlenecks in EC screening. To mitigate pathological data scarcity, we develop a structure-guided cross-modal generation network that synthesizes diverse, high-fidelity ultrasound images from unpaired magnetic resonance imaging (MRI) data, strictly preserving clinically essential anatomical junctions. Furthermore, we introduce a lightweight screening network utilizing gradient distillation, which transfers discriminative knowledge from a high-capacity teacher model to dynamically guide sparse attention towards task-critical regions. Evaluated on a large, multicenter cohort of 7,951 participants, our model achieves a sensitivity of 99.5\\%, a specificity of 97.2\\%, and an area under the curve of 0.987 at a minimal computational cost (0.289 GFLOPs), substantially outperforming the average diagnostic accuracy of expert sonographers. Our approach demonstrates that combining cross-modal synthetic augmentation with knowledge-driven efficient modeling can democratize expert-level, real-time cancer screening for resource-constrained primary care settings.",
      "authors": [
        "Dongjing Shan",
        "Yamei Luo",
        "Jiqing Xuan",
        "Lu Huang",
        "Jin Li",
        "Mengchu Yang",
        "Zeyu Chen",
        "Fajin Lv",
        "Yong Tang",
        "Chunxiang Zhang"
      ],
      "url": "https://arxiv.org/abs/2602.19822",
      "published": "2026-02-23T13:22:25+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.21255",
      "title": "A General Equilibrium Theory of Orchestrated AI Agent Systems",
      "abstract": "We establish a general equilibrium theory for systems of large language model (LLM) agents operating under centralized orchestration. The framework is a production economy in the sense of Arrow-Debreu (1954), extended to infinite-dimensional commodity spaces following Bewley (1972). Each LLM agent is modeled as a firm whose production set Y a $\\subset$ H = L 2 ([0, T ], R R ) represents the feasible metric trajectories determined by its frozen model weights. The orchestrator is the consumer, choosing a routing policy over the agent DAG to maximize system welfare subject to a budget constraint evaluated at functional prices p $\\in$ H A . These prices-elements of the Hilbert dual of the commodity space-assign a shadow value to each metric of each agent at each instant. We prove, via Brouwer's theorem applied to a finitedimensional approximation V K $\\subset$ H, that every such economy admits at least one general equilibrium (p * , y * , $π$ * ). A functional Walras' law  holds as a theorem: the value of functional excess demand is zero for all prices, as a consequence of the consumer's budget constraint-not by construction. We further establish Pareto optimality (First Welfare Theorem), decentralizability of Pareto optima (Second Welfare Theorem), and uniqueness with geometric convergence under a contraction condition (Banach). The orchestration dynamics constitute a Walrasian t{â}tonnement that converges globally under the contraction condition, unlike classical t{â}tonnement (Scarf, 1960). The framework admits a DSGE interpretation with SLO parameters as policy rates.",
      "authors": [
        "Jean-Philippe Garnier"
      ],
      "url": "https://arxiv.org/abs/2602.21255",
      "published": "2026-02-23T13:21:32+00:00",
      "categories": [
        "cs.GT",
        "cs.AI",
        "math.OC"
      ]
    },
    {
      "id": "2602.19818",
      "title": "SafePickle: Robust and Generic ML Detection of Malicious Pickle-based ML Models",
      "abstract": "Model repositories such as Hugging Face increasingly distribute machine learning artifacts serialized with Python's pickle format, exposing users to remote code execution (RCE) risks during model loading. Recent defenses, such as PickleBall, rely on per-library policy synthesis that requires complex system setups and verified benign models, which limits scalability and generalization. In this work, we propose a lightweight, machine-learning-based scanner that detects malicious Pickle-based files without policy generation or code instrumentation. Our approach statically extracts structural and semantic features from Pickle bytecode and applies supervised and unsupervised models to classify files as benign or malicious. We construct and release a labeled dataset of 727 Pickle-based files from Hugging Face and evaluate our models on four datasets: our own, PickleBall (out-of-distribution), Hide-and-Seek (9 advanced evasive malicious models), and synthetic joblib files. Our method achieves 90.01% F1-score compared with 7.23%-62.75% achieved by the SOTA scanners (Modelscan, Fickling, ClamAV, VirusTotal) on our dataset. Furthermore, on the PickleBall data (OOD), it achieves 81.22% F1-score compared with 76.09% achieved by the PickleBall method, while remaining fully library-agnostic. Finally, we show that our method is the only one to correctly parse and classify 9/9 evasive Hide-and-Seek malicious models specially crafted to evade scanners. This demonstrates that data-driven detection can effectively and generically mitigate Pickle-based model file attacks.",
      "authors": [
        "Hillel Ohayon",
        "Daniel Gilkarov",
        "Ran Dubin"
      ],
      "url": "https://arxiv.org/abs/2602.19818",
      "published": "2026-02-23T13:19:43+00:00",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19816",
      "title": "Depth-Structured Music Recurrence: Budgeted Recurrent Attention for Full-Piece Symbolic Music Modeling",
      "abstract": "Long-context modeling is essential for symbolic music generation, since motif repetition and developmental variation can span thousands of musical events. However, practical composition and performance workflows frequently rely on resource-limited devices (e.g., electronic instruments and portable computers), making heavy memory and attention computation difficult to deploy. We introduce Depth-Structured Music Recurrence (DSMR), a recurrent long-context Transformer for full-piece symbolic music modeling that extends context beyond fixed-length excerpts via segment-level recurrence with detached cross-segment states, featuring a layer-wise memory-horizon schedule that budgets recurrent KV states across depth. DSMR is trained in a single left-to-right pass over each complete composition, akin to how a musician experiences it from beginning to end, while carrying recurrent cross-segment states forward. Within this recurrent framework, we systematically study how depth-wise horizon allocations affect optimization, best-checkpoint perplexity, and efficiency. By allocating different history-window lengths across layers while keeping the total recurrent-state budget fixed, DSMR creates depth-dependent temporal receptive fields within a recurrent attention stack without reducing compute depth. Our main instantiation is a two-scale DSMR schedule that allocates long history windows to lower layers and a uniform short window to the remaining layers. Experiments on the piano performance dataset MAESTRO demonstrate that two-scale DSMR provides a practical quality--efficiency recipe for full-length long-context symbolic music modeling with recurrent attention under limited computational resources.",
      "authors": [
        "Yungang Yi"
      ],
      "url": "https://arxiv.org/abs/2602.19816",
      "published": "2026-02-23T13:13:41+00:00",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19815",
      "title": "Keyboards for the Endangered Idu Mishmi Language",
      "abstract": "We present a mobile and desktop keyboard suite for Idu Mishmi, an endangered Trans-Himalayan language spoken by approximately 11,000 people in Arunachal Pradesh, India. Although a Latin-based orthography was developed in 2018, no digital input tools existed to use it, forcing speakers into ad-hoc romanizations that cannot represent the full writing system. Our keyboards comprise two tools: (1) an Android mobile keyboard, published on the Google Play Store and actively used in teacher training programs, and (2) a Windows desktop keyboard currently undergoing community testing. Both tools support the complete Idu Mishmi character inventory, including schwa, retracted schwa, nasalized vowels, and accented forms. Both operate fully offline with zero network permissions, addressing connectivity constraints and data sovereignty concerns. We describe the design, implementation, and deployment as a replicable model for other endangered language communities.",
      "authors": [
        "Akhilesh Kakolu Ramarao"
      ],
      "url": "https://arxiv.org/abs/2602.19815",
      "published": "2026-02-23T13:13:40+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.19810",
      "title": "OpenClaw, Moltbook, and ClawdLab: From Agent-Only Social Networks to Autonomous Scientific Research",
      "abstract": "In January 2026, the open-source agent framework OpenClaw and the agent-only social network Moltbook produced a large-scale dataset of autonomous AI-to-AI interaction, attracting six academic publications within fourteen days. This study conducts a multivocal literature review of that ecosystem and presents ClawdLab, an open-source platform for autonomous scientific research, as a design science response to the architectural failure modes identified. The literature documents emergent collective phenomena, security vulnerabilities spanning 131 agent skills and over 15,200 exposed control panels, and five recurring architectural patterns. ClawdLab addresses these failure modes through hard role restrictions, structured adversarial critique, PI-led governance, multi-model orchestration, and domain-specific evidence requirements encoded as protocol constraints that ground validation in computational tool outputs rather than social consensus; the architecture provides emergent Sybil resistance as a structural consequence. A three-tier taxonomy distinguishes single-agent pipelines, predetermined multi-agent workflows, and fully decentralised systems, analysing why leading AI co-scientist platforms remain confined to the first two tiers. ClawdLab's composable third-tier architecture, in which foundation models, capabilities, governance, and evidence requirements are independently modifiable, enables compounding improvement as the broader AI ecosystem advances.",
      "authors": [
        "Lukas Weidener",
        "Marko Brkić",
        "Mihailo Jovanović",
        "Ritvik Singh",
        "Emre Ulgac",
        "Aakaash Meduri"
      ],
      "url": "https://arxiv.org/abs/2602.19810",
      "published": "2026-02-23T13:10:01+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.19805",
      "title": "Decision MetaMamba: Enhancing Selective SSM in Offline RL with Heterogeneous Sequence Mixing",
      "abstract": "Mamba-based models have drawn much attention in offline RL. However, their selective mechanism often detrimental when key steps in RL sequences are omitted. To address these issues, we propose a simple yet effective structure, called Decision MetaMamba (DMM), which replaces Mamba's token mixer with a dense layer-based sequence mixer and modifies positional structure to preserve local information. By performing sequence mixing that considers all channels simultaneously before Mamba, DMM prevents information loss due to selective scanning and residual gating. Extensive experiments demonstrate that our DMM delivers the state-of-the-art performance across diverse RL tasks. Furthermore, DMM achieves these results with a compact parameter footprint, demonstrating strong potential for real-world applications.",
      "authors": [
        "Wall Kim",
        "Chaeyoung Song",
        "Hanul Kim"
      ],
      "url": "https://arxiv.org/abs/2602.19805",
      "published": "2026-02-23T13:03:48+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19799",
      "title": "Path-conditioned training: a principled way to rescale ReLU neural networks",
      "abstract": "Despite recent algorithmic advances, we still lack principled ways to leverage the well-documented rescaling symmetries in ReLU neural network parameters. While two properly rescaled weights implement the same function, the training dynamics can be dramatically different. To offer a fresh perspective on exploiting this phenomenon, we build on the recent path-lifting framework, which provides a compact factorization of ReLU networks. We introduce a geometrically motivated criterion to rescale neural network parameters which minimization leads to a conditioning strategy that aligns a kernel in the path-lifting space with a chosen reference. We derive an efficient algorithm to perform this alignment. In the context of random network initialization, we analyze how the architecture and the initialization scale jointly impact the output of the proposed method. Numerical experiments illustrate its potential to speed up training.",
      "authors": [
        "Arthur Lebeurrier",
        "Titouan Vayer",
        "Rémi Gribonval"
      ],
      "url": "https://arxiv.org/abs/2602.19799",
      "published": "2026-02-23T12:55:48+00:00",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.OC"
      ]
    },
    {
      "id": "2602.19790",
      "title": "Drift Localization using Conformal Predictions",
      "abstract": "Concept drift -- the change of the distribution over time -- poses significant challenges for learning systems and is of central interest for monitoring. Understanding drift is thus paramount, and drift localization -- determining which samples are affected by the drift -- is essential. While several approaches exist, most rely on local testing schemes, which tend to fail in high-dimensional, low-signal settings. In this work, we consider a fundamentally different approach based on conformal predictions. We discuss and show the shortcomings of common approaches and demonstrate the performance of our approach on state-of-the-art image datasets.",
      "authors": [
        "Fabian Hinder",
        "Valerie Vaquet",
        "Johannes Brinkrolf",
        "Barbara Hammer"
      ],
      "url": "https://arxiv.org/abs/2602.19790",
      "published": "2026-02-23T12:46:50+00:00",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19789",
      "title": "Stop Preaching and Start Practising Data Frugality for Responsible Development of AI",
      "abstract": "This position paper argues that the machine learning community must move from preaching to practising data frugality for responsible artificial intelligence (AI) development. For long, progress has been equated with ever-larger datasets, driving remarkable advances but now yielding increasingly diminishing performance gains alongside rising energy use and carbon emissions. While awareness of data frugal approaches has grown, their adoption has remained rhetorical, and data scaling continues to dominate development practice. We argue that this gap between preach and practice must be closed, as continued data scaling entails substantial and under-accounted environmental impacts. To ground our position, we provide indicative estimates of the energy use and carbon emissions associated with the downstream use of ImageNet-1K. We then present empirical evidence that data frugality is both practical and beneficial, demonstrating that coreset-based subset selection can substantially reduce training energy consumption with little loss in accuracy, while also mitigating dataset bias. Finally, we outline actionable recommendations for moving data frugality from rhetorical preach to concrete practice for responsible development of AI.",
      "authors": [
        "Sophia N. Wilson",
        "Guðrún Fjóla Guðmundsdóttir",
        "Andrew Millard",
        "Raghavendra Selvan",
        "Sebastian Mair"
      ],
      "url": "https://arxiv.org/abs/2602.19789",
      "published": "2026-02-23T12:46:23+00:00",
      "categories": [
        "cs.LG",
        "cs.CY"
      ]
    },
    {
      "id": "2602.19788",
      "title": "Bayesian Meta-Learning with Expert Feedback for Task-Shift Adaptation through Causal Embeddings",
      "abstract": "Meta-learning methods perform well on new within-distribution tasks but often fail when adapting to out-of-distribution target tasks, where transfer from source tasks can induce negative transfer. We propose a causally-aware Bayesian meta-learning method, by conditioning task-specific priors on precomputed latent causal task embeddings, enabling transfer based on mechanistic similarity rather than spurious correlations. Our approach explicitly considers realistic deployment settings where access to target-task data is limited, and adaptation relies on noisy (expert-provided) pairwise judgments of causal similarity between source and target tasks. We provide a theoretical analysis showing that conditioning on causal embeddings controls prior mismatch and mitigates negative transfer under task shift. Empirically, we demonstrate reductions in negative transfer and improved out-of-distribution adaptation in both controlled simulations and a large-scale real-world clinical prediction setting for cross-disease transfer, where causal embeddings align with underlying clinical mechanisms.",
      "authors": [
        "Lotta Mäkinen",
        "Jorge Loría",
        "Samuel Kaski"
      ],
      "url": "https://arxiv.org/abs/2602.19788",
      "published": "2026-02-23T12:44:22+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19786",
      "title": "The Climate Change Knowledge Graph: Supporting Climate Services",
      "abstract": "Climate change impacts a broad spectrum of human resources and activities, necessitating the use of climate models to project long-term effects and inform mitigation and adaptation strategies. These models generate multiple datasets by running simulations across various scenarios and configurations, thereby covering a range of potential future outcomes. Currently, researchers rely on traditional search interfaces and APIs to retrieve such datasets, often piecing together information from metadata and community vocabularies. The Climate Change Knowledge Graph is designed to address these challenges by integrating diverse data sources related to climate simulations into a coherent and interoperable knowledge graph. This innovative resource allows for executing complex queries involving climate models, simulations, variables, spatio-temporal domains, and granularities. Developed with input from domain experts, the knowledge graph and its underlying ontology are published with open access license and provide a comprehensive framework that enhances the exploration of climate data, facilitating more informed decision-making in addressing climate change issues.",
      "authors": [
        "Miguel Ceriani",
        "Fiorela Ciroku",
        "Alessandro Russo",
        "Massimiliano Schembri",
        "Fai Fung",
        "Neha Mittal",
        "Vito Trianni",
        "Andrea Giovanni Nuzzolese"
      ],
      "url": "https://arxiv.org/abs/2602.19786",
      "published": "2026-02-23T12:42:05+00:00",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "id": "2602.19785",
      "title": "Unsupervised Anomaly Detection in NSL-KDD Using $β$-VAE: A Latent Space and Reconstruction Error Approach",
      "abstract": "As Operational Technology increasingly integrates with Information Technology, the need for Intrusion Detection Systems becomes more important. This paper explores an unsupervised approach to anomaly detection in network traffic using $β$-Variational Autoencoders on the NSL-KDD dataset. We investigate two methods: leveraging the latent space structure by measuring distances from test samples to the training data projections, and using the reconstruction error as a conventional anomaly detection metric. By comparing these approaches, we provide insights into their respective advantages and limitations in an unsupervised setting. Experimental results highlight the effectiveness of latent space exploitation for classification tasks.",
      "authors": [
        "Dylan Baptiste",
        "Ramla Saddem",
        "Alexandre Philippot",
        "François Foyer"
      ],
      "url": "https://arxiv.org/abs/2602.19785",
      "published": "2026-02-23T12:42:00+00:00",
      "categories": [
        "cs.LG",
        "cs.NE",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19782",
      "title": "Addressing Instrument-Outcome Confounding in Mendelian Randomization through Representation Learning",
      "abstract": "Mendelian Randomization (MR) is a prominent observational epidemiological research method designed to address unobserved confounding when estimating causal effects. However, core assumptions -- particularly the independence between instruments and unobserved confounders -- are often violated due to population stratification or assortative mating. Leveraging the increasing availability of multi-environment data, we propose a representation learning framework that exploits cross-environment invariance to recover latent exogenous components of genetic instruments. We provide theoretical guarantees for identifying these latent instruments under various mixing mechanisms and demonstrate the effectiveness of our approach through simulations and semi-synthetic experiments using data from the All of Us Research Hub.",
      "authors": [
        "Shimeng Huang",
        "Matthew Robinson",
        "Francesco Locatello"
      ],
      "url": "https://arxiv.org/abs/2602.19782",
      "published": "2026-02-23T12:38:26+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19778",
      "title": "Enhancing Automatic Chord Recognition via Pseudo-Labeling and Knowledge Distillation",
      "abstract": "Automatic Chord Recognition (ACR) is constrained by the scarcity of aligned chord labels, as well-aligned annotations are costly to acquire. At the same time, open-weight pre-trained models are currently more accessible than their proprietary training data. In this work, we present a two-stage training pipeline that leverages pre-trained models together with unlabeled audio. The proposed method decouples training into two stages. In the first stage, we use a pre-trained BTC model as a teacher to generate pseudo-labels for over 1,000 hours of diverse unlabeled audio and train a student model solely on these pseudo-labels. In the second stage, the student is continually trained on ground-truth labels as they become available, with selective knowledge distillation (KD) from the teacher applied as a regularizer to prevent catastrophic forgetting of the representations learned in the first stage. In our experiments, two models (BTC, 2E1D) were used as students. In stage 1, using only pseudo-labels, the BTC student achieves over 98% of the teacher's performance, while the 2E1D model achieves about 96% across seven standard mir_eval metrics. After a single training run for both students in stage 2, the resulting BTC student model surpasses the traditional supervised learning baseline by 2.5% and the original pre-trained teacher model by 1.55% on average across all metrics. And the resulting 2E1D student model improves from the traditional supervised learning baseline by 3.79% on average and achieves almost the same performance as the teacher. Both cases show the large gains on rare chord qualities.",
      "authors": [
        "Nghia Phan",
        "Rong Jin",
        "Gang Liu",
        "Xiao Dong"
      ],
      "url": "https://arxiv.org/abs/2602.19778",
      "published": "2026-02-23T12:32:53+00:00",
      "categories": [
        "cs.SD",
        "cs.IR",
        "cs.LG",
        "cs.MM"
      ]
    },
    {
      "id": "2602.19775",
      "title": "Exact Discrete Stochastic Simulation with Deep-Learning-Scale Gradient Optimization",
      "abstract": "Exact stochastic simulation of continuous-time Markov chains (CTMCs) is essential when discreteness and noise drive system behavior, but the hard categorical event selection in Gillespie-type algorithms blocks gradient-based learning. We eliminate this constraint by decoupling forward simulation from backward differentiation, with hard categorical sampling generating exact trajectories and gradients propagating through a continuous massively-parallel Gumbel-Softmax straight-through surrogate. Our approach enables accurate optimization at parameter scales over four orders of magnitude beyond existing simulators. We validate for accuracy, scalability, and reliability on a reversible dimerization model (0.09% error), a genetic oscillator (1.2% error), a 203,796-parameter gene regulatory network achieving 98.4% MNIST accuracy (a prototypical deep-learning multilayer perceptron benchmark), and experimental patch-clamp recordings of ion channel gating (R^2 = 0.987) in the single-channel regime. Our GPU implementation delivers 1.9 billion steps per second, matching the scale of non-differentiable simulators. By making exact stochastic simulation massively parallel and autodiff-compatible, our results enable high-dimensional parameter inference and inverse design across systems biology, chemical kinetics, physics, and related CTMC-governed domains.",
      "authors": [
        "Jose M. G. Vilar",
        "Leonor Saiz"
      ],
      "url": "https://arxiv.org/abs/2602.19775",
      "published": "2026-02-23T12:29:43+00:00",
      "categories": [
        "q-bio.QM",
        "cond-mat.stat-mech",
        "cs.LG",
        "physics.comp-ph",
        "q-bio.MN"
      ]
    },
    {
      "id": "2602.19770",
      "title": "The Confusion is Real: GRAPHIC - A Network Science Approach to Confusion Matrices in Deep Learning",
      "abstract": "Explainable artificial intelligence has emerged as a promising field of research to address reliability concerns in artificial intelligence. Despite significant progress in explainable artificial intelligence, few methods provide a systematic way to visualize and understand how classes are confused and how their relationships evolve as training progresses. In this work, we present GRAPHIC, an architecture-agnostic approach that analyzes neural networks on a class level. It leverages confusion matrices derived from intermediate layers using linear classifiers. We interpret these as adjacency matrices of directed graphs, allowing tools from network science to visualize and quantify learning dynamics across training epochs and intermediate layers. GRAPHIC provides insights into linear class separability, dataset issues, and architectural behavior, revealing, for example, similarities between flatfish and man and labeling ambiguities validated in a human study. In summary, by uncovering real confusions, GRAPHIC offers new perspectives on how neural networks learn. The code is available at https://github.com/Johanna-S-Froehlich/GRAPHIC.",
      "authors": [
        "Johanna S. Fröhlich",
        "Bastian Heinlein",
        "Jan U. Claar",
        "Hans Rosenberger",
        "Vasileios Belagiannis",
        "Ralf R. Müller"
      ],
      "url": "https://arxiv.org/abs/2602.19770",
      "published": "2026-02-23T12:20:37+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19762",
      "title": "Hexagon-MLIR: An AI Compilation Stack For Qualcomm's Neural Processing Units (NPUs)",
      "abstract": "In this paper, we present Hexagon-MLIR,an open-source compilation stack that targets Qualcomm Hexagon Neural Processing Unit (NPU) and provides unified support for lowering Triton kernels and PyTorch models . Built using the MLIR framework, our compiler applies a structured sequence of passes to exploit NPU architectural features to accelerate AI workloads. It enables faster deployment of new Triton kernels (hand-written or subgraphs from PyTorch 2.0), for our target by providing automated compilation from kernel to binary. By ingesting Triton kernels, we generate mega-kernels that maximize data locality in the NPU's Tightly Coupled Memory (TCM), reducing the bandwidth bottlenecks inherent in library-based approaches. This initiative complements our commercial toolchains by providing developers with an open-source MLIR-based compilation stack that gives them a path to advance AI compilation capabilities through a more flexible approach. Hexagon-MLIR is a work-in-progress, and we are continuing to add many more optimizations and capabilities in this effort.",
      "authors": [
        "Mohammed Javed Absar",
        "Muthu Baskaran",
        "Abhikrant Sharma",
        "Abhilash Bhandari",
        "Ankit Aggarwal",
        "Arun Rangasamy",
        "Dibyendu Das",
        "Fateme Hosseini",
        "Franck Slama",
        "Iulian Brumar",
        "Jyotsna Verma",
        "Krishnaprasad Bindumadhavan",
        "Mitesh Kothari",
        "Mohit Gupta",
        "Ravishankar Kolachana",
        "Richard Lethin",
        "Samarth Narang",
        "Sanjay Motilal Ladwa",
        "Shalini Jain",
        "Snigdha Suresh Dalvi",
        "Tasmia Rahman",
        "Venkat Rasagna Reddy Komatireddy",
        "Vivek Vasudevbhai Pandya",
        "Xiyue Shi",
        "Zachary Zipper"
      ],
      "url": "https://arxiv.org/abs/2602.19762",
      "published": "2026-02-23T12:12:39+00:00",
      "categories": [
        "cs.PL",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19761",
      "title": "Ensemble Machine Learning and Statistical Procedures for Dynamic Predictions of Time-to-Event Outcomes",
      "abstract": "Dynamic predictions for longitudinal and time-to-event outcomes have become a versatile tool in precision medicine. Our work is motivated by the application of dynamic predictions in the decision-making process for primary biliary cholangitis patients. For these patients, serial biomarker measurements (e.g., bilirubin and alkaline phosphatase levels) are routinely collected to inform treating physicians of the risk of liver failure and guide clinical decision-making. Two popular statistical approaches to derive dynamic predictions are joint modelling and landmarking. However, recently, machine learning techniques have also been proposed. Each approach has its merits, and no single method exists to outperform all others. Consequently, obtaining the best possible survival estimates is challenging. Therefore, we extend the Super Learner framework to combine dynamic predictions from different models and procedures. Super Learner is an ensemble learning technique that allows users to combine different prediction algorithms to improve predictive accuracy and flexibility. It uses cross-validation and different objective functions of performance (e.g., squared loss) that suit specific applications to build the optimally weighted combination of predictions from a library of candidate algorithms. In our work, we pay special attention to appropriate objective functions for Super Learner to obtain the most optimal weighted combination of dynamic predictions. In our primary biliary cholangitis application, Super Learner presented unique benefits due to its ability to flexibly combine outputs from a diverse set of models with varying assumptions for equal or better predictive performance than any model fit separately.",
      "authors": [
        "Nina van Gerwen",
        "Sten Willemsen",
        "Bettina E. Hansen",
        "Christophe Corpechot",
        "Marco Carbone",
        "Cynthia Levy",
        "Maria-Carlota Londõno",
        "Atsushi Tanaka",
        "Palak Trivedi",
        "Alejandra Villamil",
        "Gideon Hirschfield",
        "Dimitris Rizopoulos"
      ],
      "url": "https://arxiv.org/abs/2602.19761",
      "published": "2026-02-23T12:12:13+00:00",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.AP"
      ]
    },
    {
      "id": "2602.19743",
      "title": "NILE: Formalizing Natural-Language Descriptions of Formal Languages",
      "abstract": "This paper explores how natural-language descriptions of formal languages can be compared to their formal representations and how semantic differences can be explained. This is motivated from educational scenarios where learners describe a formal language (presented, e.g., by a finite state automaton, regular expression, pushdown automaton, context-free grammar or in set notation) in natural language, and an educational support system has to (1) judge whether the natural-language description accurately describes the formal language, and to (2) provide explanations why descriptions are not accurate.   To address this question, we introduce a representation language for formal languages, Nile, which is designed so that Nile expressions can mirror the syntactic structure of natural-language descriptions of formal languages. Nile is sufficiently expressive to cover a broad variety of formal languages, including all regular languages and fragments of context-free languages typically used in educational contexts. Generating Nile expressions that are syntactically close to natural-language descriptions then allows to provide explanations for inaccuracies in the descriptions algorithmically.   In experiments on an educational data set, we show that LLMs can translate natural-language descriptions into equivalent, syntactically close Nile expressions with high accuracy - allowing to algorithmically provide explanations for incorrect natural-language descriptions. Our experiments also show that while natural-language descriptions can also be translated into regular expressions (but not context-free grammars), the expressions are often not syntactically close and thus not suitable for providing explanations.",
      "authors": [
        "Tristan Kneisel",
        "Marko Schmellenkamp",
        "Fabian Vehlken",
        "Thomas Zeume"
      ],
      "url": "https://arxiv.org/abs/2602.19743",
      "published": "2026-02-23T11:42:56+00:00",
      "categories": [
        "cs.FL",
        "cs.CL",
        "cs.LO"
      ]
    },
    {
      "id": "2602.19733",
      "title": "Understanding the Curse of Unrolling",
      "abstract": "Algorithm unrolling is ubiquitous in machine learning, particularly in hyperparameter optimization and meta-learning, where Jacobians of solution mappings are computed by differentiating through iterative algorithms. Although unrolling is known to yield asymptotically correct Jacobians under suitable conditions, recent work has shown that the derivative iterates may initially diverge from the true Jacobian, a phenomenon known as the curse of unrolling. In this work, we provide a non-asymptotic analysis that explains the origin of this behavior and identifies the algorithmic factors that govern it. We show that truncating early iterations of the derivative computation mitigates the curse while simultaneously reducing memory requirements. Finally, we demonstrate that warm-starting in bilevel optimization naturally induces an implicit form of truncation, providing a practical remedy. Our theoretical findings are supported by numerical experiments on representative examples.",
      "authors": [
        "Sheheryar Mehmood",
        "Florian Knoll",
        "Peter Ochs"
      ],
      "url": "https://arxiv.org/abs/2602.19733",
      "published": "2026-02-23T11:32:39+00:00",
      "categories": [
        "cs.LG",
        "math.OC"
      ]
    },
    {
      "id": "2602.19718",
      "title": "Carbon-Aware Governance Gates: An Architecture for Sustainable GenAI Development",
      "abstract": "The rapid adoption of Generative AI (GenAI) in the software development life cycle (SDLC) increases computational demand, which can raise the carbon footprint of development activities. At the same time, organizations are increasingly embedding governance mechanisms into GenAI-assisted development to support trust, transparency, and accountability. However, these governance mechanisms introduce additional computational workloads, including repeated inference, regeneration cycles, and expanded validation pipelines, increasing energy use and the carbon footprint of GenAI-assisted development. This paper proposes Carbon-Aware Governance Gates (CAGG), an architectural extension that embeds carbon budgets, energy provenance, and sustainability-aware validation orchestration into human-AI governance layers. CAGG comprises three components: (i) an Energy and Carbon Provenance Ledger, (ii) a Carbon Budget Manager, and (iii) a Green Validation Orchestrator, operationalized through governance policies and reusable design patterns.",
      "authors": [
        "Mateen A. Abbasi",
        "Tommi J. Mikkonen",
        "Petri J. Ihantola",
        "Muhammad Waseem",
        "Pekka Abrahamsson",
        "Niko K. Mäkitalo"
      ],
      "url": "https://arxiv.org/abs/2602.19718",
      "published": "2026-02-23T11:11:56+00:00",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19710",
      "title": "Universal Pose Pretraining for Generalizable Vision-Language-Action Policies",
      "abstract": "Existing Vision-Language-Action (VLA) models often suffer from feature collapse and low training efficiency because they entangle high-level perception with sparse, embodiment-specific action supervision. Since these models typically rely on VLM backbones optimized for Visual Question Answering (VQA), they excel at semantic identification but often overlook subtle 3D state variations that dictate distinct action patterns.   To resolve these misalignments, we propose Pose-VLA, a decoupled paradigm that separates VLA training into a pre-training phase for extracting universal 3D spatial priors in a unified camera-centric space, and a post-training phase for efficient embodiment alignment within robot-specific action space. By introducing discrete pose tokens as a universal representation, Pose-VLA seamlessly integrates spatial grounding from diverse 3D datasets with geometry-level trajectories from robotic demonstrations. Our framework follows a two-stage pre-training pipeline, establishing fundamental spatial grounding via poses followed by motion alignment through trajectory supervision.   Extensive evaluations demonstrate that Pose-VLA achieves state-of-the-art results on RoboTwin 2.0 with a 79.5% average success rate and competitive performance on LIBERO at 96.0%. Real-world experiments further showcase robust generalization across diverse objects using only 100 demonstrations per task, validating the efficiency of our pre-training paradigm.",
      "authors": [
        "Haitao Lin",
        "Hanyang Yu",
        "Jingshun Huang",
        "He Zhang",
        "Yonggen Ling",
        "Ping Tan",
        "Xiangyang Xue",
        "Yanwei Fu"
      ],
      "url": "https://arxiv.org/abs/2602.19710",
      "published": "2026-02-23T11:00:08+00:00",
      "categories": [
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "id": "2602.19702",
      "title": "DReX: An Explainable Deep Learning-based Multimodal Recommendation Framework",
      "abstract": "Multimodal recommender systems leverage diverse data sources, such as user interactions, content features, and contextual information, to address challenges like cold-start and data sparsity. However, existing methods often suffer from one or more key limitations: processing different modalities in isolation, requiring complete multimodal data for each interaction during training, or independent learning of user and item representations. These factors contribute to increased complexity and potential misalignment between user and item embeddings. To address these challenges, we propose DReX, a unified multimodal recommendation framework that incrementally refines user and item representations by leveraging interaction-level features from multimodal feedback. Our model employs gated recurrent units to selectively integrate these fine-grained features into global representations. This incremental update mechanism provides three key advantages: (1) simultaneous modeling of both nuanced interaction details and broader preference patterns, (2) eliminates the need for separate user and item feature extraction processes, leading to enhanced alignment in their learned representation, and (3) inherent robustness to varying or missing modalities. We evaluate the performance of the proposed approach on three real-world datasets containing reviews and ratings as interaction modalities. By considering review text as a modality, our approach automatically generates interpretable keyword profiles for both users and items, which supplement the recommendation process with interpretable preference indicators. Experiment results demonstrate that our approach outperforms state-of-the-art methods across all evaluated datasets.",
      "authors": [
        "Adamya Shyam",
        "Venkateswara Rao Kagita",
        "Bharti Rana",
        "Vikas Kumar"
      ],
      "url": "https://arxiv.org/abs/2602.19702",
      "published": "2026-02-23T10:52:20+00:00",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19698",
      "title": "Iconographic Classification and Content-Based Recommendation for Digitized Artworks",
      "abstract": "We present a proof-of-concept system that automates iconographic classification and content-based recommendation of digitized artworks using the Iconclass vocabulary and selected artificial intelligence methods. The prototype implements a four-stage workflow for classification and recommendation, which integrates YOLOv8 object detection with algorithmic mappings to Iconclass codes, rule-based inference for abstract meanings, and three complementary recommenders (hierarchical proximity, IDF-weighted overlap, and Jaccard similarity). Although more engineering is still needed, the evaluation demonstrates the potential of this solution: Iconclass-aware computer vision and recommendation methods can accelerate cataloging and enhance navigation in large heritage repositories. The key insight is to let computer vision propose visible elements and to use symbolic structures (Iconclass hierarchy) to reach meaning.",
      "authors": [
        "Krzysztof Kutt",
        "Maciej Baczyński"
      ],
      "url": "https://arxiv.org/abs/2602.19698",
      "published": "2026-02-23T10:44:27+00:00",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ]
    },
    {
      "id": "2602.19691",
      "title": "Smoothness Adaptivity in Constant-Depth Neural Networks: Optimal Rates via Smooth Activations",
      "abstract": "Smooth activation functions are ubiquitous in modern deep learning, yet their theoretical advantages over non-smooth counterparts remain poorly understood. In this work, we characterize both approximation and statistical properties of neural networks with smooth activations over the Sobolev space $W^{s,\\infty}([0,1]^d)$ for arbitrary smoothness $s>0$. We prove that constant-depth networks equipped with smooth activations automatically exploit arbitrarily high orders of target function smoothness, achieving the minimax-optimal approximation and estimation error rates (up to logarithmic factors). In sharp contrast, networks with non-smooth activations, such as ReLU, lack this adaptivity: their attainable approximation order is strictly limited by depth, and capturing higher-order smoothness requires proportional depth growth. These results identify activation smoothness as a fundamental mechanism, alternative to depth, for attaining statistical optimality. Technically, our results are established via a constructive approximation framework that produces explicit neural network approximators with carefully controlled parameter norms and model size. This complexity control ensures statistical learnability under empirical risk minimization (ERM) and removes the impractical sparsity constraints commonly required in prior analyses.",
      "authors": [
        "Yuhao Liu",
        "Zilin Wang",
        "Lei Wu",
        "Shaobo Zhang"
      ],
      "url": "https://arxiv.org/abs/2602.19691",
      "published": "2026-02-23T10:38:12+00:00",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.NA"
      ]
    },
    {
      "id": "2602.20220",
      "title": "What Matters for Simulation to Online Reinforcement Learning on Real Robots",
      "abstract": "We investigate what specific design choices enable successful online reinforcement learning (RL) on physical robots. Across 100 real-world training runs on three distinct robotic platforms, we systematically ablate algorithmic, systems, and experimental decisions that are typically left implicit in prior work. We find that some widely used defaults can be harmful, while a set of robust, readily adopted design choices within standard RL practice yield stable learning across tasks and hardware. These results provide the first large-sample empirical study of such design choices, enabling practitioners to deploy online RL with lower engineering effort.",
      "authors": [
        "Yarden As",
        "Dhruva Tirumala",
        "René Zurbrügg",
        "Chenhao Li",
        "Stelian Coros",
        "Andreas Krause",
        "Markus Wulfmeier"
      ],
      "url": "https://arxiv.org/abs/2602.20220",
      "published": "2026-02-23T10:34:15+00:00",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19685",
      "title": "PerturbDiff: Functional Diffusion for Single-Cell Perturbation Modeling",
      "abstract": "Building Virtual Cells that can accurately simulate cellular responses to perturbations is a long-standing goal in systems biology. A fundamental challenge is that high-throughput single-cell sequencing is destructive: the same cell cannot be observed both before and after a perturbation. Thus, perturbation prediction requires mapping unpaired control and perturbed populations. Existing models address this by learning maps between distributions, but typically assume a single fixed response distribution when conditioned on observed cellular context (e.g., cell type) and the perturbation type. In reality, responses vary systematically due to unobservable latent factors such as microenvironmental fluctuations and complex batch effects, forming a manifold of possible distributions for the same observed conditions. To account for this variability, we introduce PerturbDiff, which shifts modeling from individual cells to entire distributions. By embedding distributions as points in a Hilbert space, we define a diffusion-based generative process operating directly over probability distributions. This allows PerturbDiff to capture population-level response shifts across hidden factors. Benchmarks on established datasets show that PerturbDiff achieves state-of-the-art performance in single-cell response prediction and generalizes substantially better to unseen perturbations. See our project page (https://katarinayuan.github.io/PerturbDiff-ProjectPage/), where code and data will be made publicly available (https://github.com/DeepGraphLearning/PerturbDiff).",
      "authors": [
        "Xinyu Yuan",
        "Xixian Liu",
        "Ya Shi Zhang",
        "Zuobai Zhang",
        "Hongyu Guo",
        "Jian Tang"
      ],
      "url": "https://arxiv.org/abs/2602.19685",
      "published": "2026-02-23T10:28:56+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19679",
      "title": "TeHOR: Text-Guided 3D Human and Object Reconstruction with Textures",
      "abstract": "Joint reconstruction of 3D human and object from a single image is an active research area, with pivotal applications in robotics and digital content creation. Despite recent advances, existing approaches suffer from two fundamental limitations. First, their reconstructions rely heavily on physical contact information, which inherently cannot capture non-contact human-object interactions, such as gazing at or pointing toward an object. Second, the reconstruction process is primarily driven by local geometric proximity, neglecting the human and object appearances that provide global context crucial for understanding holistic interactions. To address these issues, we introduce TeHOR, a framework built upon two core designs. First, beyond contact information, our framework leverages text descriptions of human-object interactions to enforce semantic alignment between the 3D reconstruction and its textual cues, enabling reasoning over a wider spectrum of interactions, including non-contact cases. Second, we incorporate appearance cues of the 3D human and object into the alignment process to capture holistic contextual information, thereby ensuring visually plausible reconstructions. As a result, our framework produces accurate and semantically coherent reconstructions, achieving state-of-the-art performance.",
      "authors": [
        "Hyeongjin Nam",
        "Daniel Sungho Jung",
        "Kyoung Mu Lee"
      ],
      "url": "https://arxiv.org/abs/2602.19679",
      "published": "2026-02-23T10:22:52+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19674",
      "title": "Continuous Telemonitoring of Heart Failure using Personalised Speech Dynamics",
      "abstract": "Remote monitoring of heart failure (HF) via speech signals provides a non-invasive and cost-effective solution for long-term patient management. However, substantial inter-individual heterogeneity in vocal characteristics often limits the accuracy of traditional cross-sectional classification models. To address this, we propose a Longitudinal Intra-Patient Tracking (LIPT) scheme designed to capture the trajectory of relative symptomatic changes within individuals. Central to this framework is a Personalised Sequential Encoder (PSE), which transforms longitudinal speech recordings into context-aware latent representations. By incorporating historical data at each timestamp, the PSE facilitates a holistic assessment of the clinical trajectory rather than modelling discrete visits independently. Experimental results from a cohort of 225 patients demonstrate that the LIPT paradigm significantly outperforms the classic cross-sectional approaches, achieving a recognition accuracy of 99.7% for clinical status transitions. The model's high sensitivity was further corroborated by additional follow-up data, confirming its efficacy in predicting HF deterioration and its potential to secure patient safety in remote, home-based settings. Furthermore, this work addresses the gap in existing literature by providing a comprehensive analysis of different speech task designs and acoustic features. Taken together, the superior performance of the LIPT framework and PSE architecture validates their readiness for integration into long-term telemonitoring systems, offering a scalable solution for remote heart failure management.",
      "authors": [
        "Yue Pan",
        "Xingyao Wang",
        "Hanyue Zhang",
        "Liwei Liu",
        "Changxin Li",
        "Gang Yang",
        "Rong Sheng",
        "Yili Xia",
        "Ming Chu"
      ],
      "url": "https://arxiv.org/abs/2602.19674",
      "published": "2026-02-23T10:19:17+00:00",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19672",
      "title": "SkillOrchestra: Learning to Route Agents via Skill Transfer",
      "abstract": "Compound AI systems promise capabilities beyond those of individual models, yet their success depends critically on effective orchestration. Existing routing approaches face two limitations: (1) input-level routers make coarse query-level decisions that ignore evolving task requirements; (2) RL-trained orchestrators are expensive to adapt and often suffer from routing collapse, repeatedly invoking one strong but costly option in multi-turn scenarios. We introduce SkillOrchestra, a framework for skill-aware orchestration. Instead of directly learning a routing policy end-to-end, SkillOrchestra learns fine-grained skills from execution experience and models agent-specific competence and cost under those skills. At deployment, the orchestrator infers the skill demands of the current interaction and selects agents that best satisfy them under an explicit performance-cost trade-off. Extensive experiments across ten benchmarks demonstrate that SkillOrchestra outperforms SoTA RL-based orchestrators by up to 22.5% with 700x and 300x learning cost reduction compared to Router-R1 and ToolOrchestra, respectively. These results show that explicit skill modeling enables scalable, interpretable, and sample-efficient orchestration, offering a principled alternative to data-intensive RL-based approaches. The code is available at: https://github.com/jiayuww/SkillOrchestra.",
      "authors": [
        "Jiayu Wang",
        "Yifei Ming",
        "Zixuan Ke",
        "Shafiq Joty",
        "Aws Albarghouthi",
        "Frederic Sala"
      ],
      "url": "https://arxiv.org/abs/2602.19672",
      "published": "2026-02-23T10:17:25+00:00",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19668",
      "title": "Personalized Longitudinal Medical Report Generation via Temporally-Aware Federated Adaptation",
      "abstract": "Longitudinal medical report generation is clinically important yet remains challenging due to strict privacy constraints and the evolving nature of disease progression. Although federated learning (FL) enables collaborative training without data sharing, existing FL methods largely overlook longitudinal dynamics by assuming stationary client distributions, making them unable to model temporal shifts across visits or patient-specific heterogeneity-ultimately leading to unstable optimization and suboptimal report generation.   We introduce Federated Temporal Adaptation (FTA), a federated setting that explicitly accounts for the temporal evolution of client data. Building upon this setting, we propose FedTAR, a framework that integrates demographic-driven personalization with time-aware global aggregation. FedTAR generates lightweight LoRA adapters from demographic embeddings and performs temporal residual aggregation, where updates from different visits are weighted by a meta-learned temporal policy optimized via first-order MAML.   Experiments on J-MID (1M exams) and MIMIC-CXR demonstrate consistent improvements in linguistic accuracy, temporal coherence, and cross-site generalization, establishing FedTAR as a robust and privacy-preserving paradigm for federated longitudinal modeling.",
      "authors": [
        "He Zhu",
        "Ren Togo",
        "Takahiro Ogawa",
        "Kenji Hirata",
        "Minghui Tang",
        "Takaaki Yoshimura",
        "Hiroyuki Sugimori",
        "Noriko Nishioka",
        "Yukie Shimizu",
        "Kohsuke Kudo",
        "Miki Haseyama"
      ],
      "url": "https://arxiv.org/abs/2602.19668",
      "published": "2026-02-23T10:14:36+00:00",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19661",
      "title": "PaReGTA: An LLM-based EHR Data Encoding Approach to Capture Temporal Information",
      "abstract": "Temporal information in structured electronic health records (EHRs) is often lost in sparse one-hot or count-based representations, while sequence models can be costly and data-hungry. We propose PaReGTA, an LLM-based encoding framework that (i) converts longitudinal EHR events into visit-level templated text with explicit temporal cues, (ii) learns domain-adapted visit embeddings via lightweight contrastive fine-tuning of a sentence-embedding model, and (iii) aggregates visit embeddings into a fixed-dimensional patient representation using hybrid temporal pooling that captures both recency and globally informative visits. Because PaReGTA does not require training from scratch but instead utilizes a pre-trained LLM, it can perform well even in data-limited cohorts. Furthermore, PaReGTA is model-agnostic and can benefit from future EHR-specialized sentence-embedding models. For interpretability, we introduce PaReGTA-RSS (Representation Shift Score), which quantifies clinically defined factor importance by recomputing representations after targeted factor removal and projecting representation shifts through a machine learning model. On 39,088 migraine patients from the All of Us Research Program, PaReGTA outperforms sparse baselines for migraine type classification while deep sequential models were unstable in our cohort.",
      "authors": [
        "Kihyuk Yoon",
        "Lingchao Mao",
        "Catherine Chong",
        "Todd J. Schwedt",
        "Chia-Chun Chiang",
        "Jing Li"
      ],
      "url": "https://arxiv.org/abs/2602.19661",
      "published": "2026-02-23T10:09:50+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19655",
      "title": "Representation Stability in a Minimal Continual Learning Agent",
      "abstract": "Continual learning systems are increasingly deployed in environments where retraining or reset is infeasible, yet many approaches emphasize task performance rather than the evolution of internal representations over time. In this work, we study a minimal continual learning agent designed to isolate representational dynamics from architectural complexity and optimization objectives. The agent maintains a persistent state vector across executions and incrementally updates it as new textual data is introduced. We quantify representational change using cosine similarity between successive normalized state vectors and define a stability metric over time intervals. Longitudinal experiments across eight executions reveal a transition from an initial plastic regime to a stable representational regime under consistent input. A deliberately introduced semantic perturbation produces a bounded decrease in similarity, followed by recovery and restabilization under subsequent coherent input. These results demonstrate that meaningful stability plasticity tradeoffs can emerge in a minimal, stateful learning system without explicit regularization, replay, or architectural complexity. The work establishes a transparent empirical baseline for studying representational accumulation and adaptation in continual learning systems.",
      "authors": [
        "Vishnu Subramanian"
      ],
      "url": "https://arxiv.org/abs/2602.19655",
      "published": "2026-02-23T09:59:03+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19654",
      "title": "NEXUS: A compact neural architecture for high-resolution spatiotemporal air quality forecasting in Delhi National Capital Region",
      "abstract": "Urban air pollution in megacities poses critical public health challenges, particularly in Delhi National Capital Region (NCR) where severe degradation affects millions. We present NEXUS (Neural Extraction and Unified Spatiotemporal) architecture for forecasting carbon monoxide, nitrogen oxide, and sulfur dioxide. Working with four years (2018--2021) of atmospheric data across sixteen spatial grids, NEXUS achieves R$^2$ exceeding 0.94 for CO, 0.91 for NO, and 0.95 for SO$_2$ using merely 18,748 parameters -- substantially fewer than SCINet (35,552), Autoformer (68,704), and FEDformer (298,080). The architecture integrates patch embedding, low-rank projections, and adaptive fusion mechanisms to decode complex atmospheric chemistry patterns. Our investigation uncovers distinct diurnal rhythms and pronounced seasonal variations, with winter months experiencing severe pollution episodes driven by temperature inversions and agricultural biomass burning. Analysis identifies critical meteorological thresholds, quantifies wind field impacts on pollutant dispersion, and maps spatial heterogeneity across the region. Extensive ablation experiments demonstrate each architectural component's role. NEXUS delivers superior predictive performance with remarkable computational efficiency, enabling real-time deployment for air quality monitoring systems.",
      "authors": [
        "Rampunit Kumar",
        "Aditya Maheshwari"
      ],
      "url": "https://arxiv.org/abs/2602.19654",
      "published": "2026-02-23T09:56:22+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19651",
      "title": "Denoising Particle Filters: Learning State Estimation with Single-Step Objectives",
      "abstract": "Learning-based methods commonly treat state estimation in robotics as a sequence modeling problem. While this paradigm can be effective at maximizing end-to-end performance, models are often difficult to interpret and expensive to train, since training requires unrolling sequences of predictions in time. As an alternative to end-to-end trained state estimation, we propose a novel particle filtering algorithm in which models are trained from individual state transitions, fully exploiting the Markov property in robotic systems. In this framework, measurement models are learned implicitly by minimizing a denoising score matching objective. At inference, the learned denoiser is used alongside a (learned) dynamics model to approximately solve the Bayesian filtering equation at each time step, effectively guiding predicted states toward the data manifold informed by measurements. We evaluate the proposed method on challenging robotic state estimation tasks in simulation, demonstrating competitive performance compared to tuned end-to-end trained baselines. Importantly, our method offers the desirable composability of classical filtering algorithms, allowing prior information and external sensor models to be incorporated without retraining.",
      "authors": [
        "Lennart Röstel",
        "Berthold Bäuml"
      ],
      "url": "https://arxiv.org/abs/2602.19651",
      "published": "2026-02-23T09:53:23+00:00",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19644",
      "title": "Spectral Phase Encoding for Quantum Kernel Methods",
      "abstract": "Quantum kernel methods are promising for near-term quantum ma- chine learning, yet their behavior under data corruption remains insuf- ficiently understood. We analyze how quantum feature constructions degrade under controlled additive noise. We introduce Spectral Phase Encoding (SPE), a hybrid construc- tion combining a discrete Fourier transform (DFT) front-end with a diagonal phase-only embedding aligned with the geometry of diagonal quantum maps. Within a unified framework, we compare QK-DFT against alternative quantum variants (QK-PCA, QK-RP) and classi- cal SVM baselines under identical clean-data hyperparameter selection, quantifying robustness via dataset fixed-effects regression with wild cluster bootstrap inference across heterogeneous real-world datasets. Across the quantum family, DFT-based preprocessing yields the smallest degradation rate as noise increases, with statistically sup- ported slope differences relative to PCA and RP. Compared to classical baselines, QK-DFT shows degradation comparable to linear SVM and more stable than RBF SVM under matched tuning. Hardware exper- iments confirm that SPE remains executable and numerically stable for overlap estimation. These results indicate that robustness in quan- tum kernels depends critically on structure-aligned preprocessing and its interaction with diagonal embeddings, supporting a robustness-first perspective for NISQ-era quantum machine learning.",
      "authors": [
        "Pablo Herrero Gómez",
        "Antonio Jimeno Morenilla",
        "David Muñoz-Hernández",
        "Higinio Mora Mora"
      ],
      "url": "https://arxiv.org/abs/2602.19644",
      "published": "2026-02-23T09:42:42+00:00",
      "categories": [
        "cs.LG",
        "quant-ph"
      ]
    },
    {
      "id": "2602.19643",
      "title": "KGHaluBench: A Knowledge Graph-Based Hallucination Benchmark for Evaluating the Breadth and Depth of LLM Knowledge",
      "abstract": "Large Language Models (LLMs) possess a remarkable capacity to generate persuasive and intelligible language. However, coherence does not equate to truthfulness, as the responses often contain subtle hallucinations. Existing benchmarks are limited by static and narrow questions, leading to limited coverage and misleading evaluations. We present KGHaluBench, a Knowledge Graph-based hallucination benchmark that assesses LLMs across the breadth and depth of their knowledge, providing a fairer and more comprehensive insight into LLM truthfulness. Our framework utilises the KG to dynamically construct challenging, multifaceted questions, whose difficulty is then statistically estimated to address popularity bias. Our automated verification pipeline detects abstentions and verifies the LLM's response at both conceptual and correctness levels to identify different types of hallucinations. We evaluate 25 frontier models, using novel accuracy and hallucination metrics. The results provide a more interpretable insight into the knowledge factors that cause hallucinations across different model sizes. KGHaluBench is publicly available to support future developments in hallucination mitigation.",
      "authors": [
        "Alex Robertson",
        "Huizhi Liang",
        "Mahbub Gani",
        "Rohit Kumar",
        "Srijith Rajamohan"
      ],
      "url": "https://arxiv.org/abs/2602.19643",
      "published": "2026-02-23T09:41:46+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.19641",
      "title": "Evaluating the Impact of Data Anonymization on Image Retrieval",
      "abstract": "With the growing importance of privacy regulations such as the General Data Protection Regulation, anonymizing visual data is becoming increasingly relevant across institutions. However, anonymization can negatively affect the performance of Computer Vision systems that rely on visual features, such as Content-Based Image Retrieval (CBIR). Despite this, the impact of anonymization on CBIR has not been systematically studied. This work addresses this gap, motivated by the DOKIQ project, an artificial intelligence-based system for document verification actively used by the State Criminal Police Office Baden-Württemberg. We propose a simple evaluation framework: retrieval results after anonymization should match those obtained before anonymization as closely as possible. To this end, we systematically assess the impact of anonymization using two public datasets and the internal DOKIQ dataset. Our experiments span three anonymization methods, four anonymization degrees, and four training strategies, all based on the state of the art backbone Self-Distillation with No Labels (DINO)v2. Our results reveal a pronounced retrieval bias in favor of models trained on original data, which produce the most similar retrievals after anonymization. The findings of this paper offer practical insights for developing privacy-compliant CBIR systems while preserving performance.",
      "authors": [
        "Marvin Chen",
        "Manuel Eberhardinger",
        "Johannes Maucher"
      ],
      "url": "https://arxiv.org/abs/2602.19641",
      "published": "2026-02-23T09:39:06+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19634",
      "title": "Compositional Planning with Jumpy World Models",
      "abstract": "The ability to plan with temporal abstractions is central to intelligent decision-making. Rather than reasoning over primitive actions, we study agents that compose pre-trained policies as temporally extended actions, enabling solutions to complex tasks that no constituent alone can solve. Such compositional planning remains elusive as compounding errors in long-horizon predictions make it challenging to estimate the visitation distribution induced by sequencing policies. Motivated by the geometric policy composition framework introduced in arXiv:2206.08736, we address these challenges by learning predictive models of multi-step dynamics -- so-called jumpy world models -- that capture state occupancies induced by pre-trained policies across multiple timescales in an off-policy manner. Building on Temporal Difference Flows (arXiv:2503.09817), we enhance these models with a novel consistency objective that aligns predictions across timescales, improving long-horizon predictive accuracy. We further demonstrate how to combine these generative predictions to estimate the value of executing arbitrary sequences of policies over varying timescales. Empirically, we find that compositional planning with jumpy world models significantly improves zero-shot performance across a wide range of base policies on challenging manipulation and navigation tasks, yielding, on average, a 200% relative improvement over planning with primitive actions on long-horizon tasks.",
      "authors": [
        "Jesse Farebrother",
        "Matteo Pirotta",
        "Andrea Tirinzoni",
        "Marc G. Bellemare",
        "Alessandro Lazaric",
        "Ahmed Touati"
      ],
      "url": "https://arxiv.org/abs/2602.19634",
      "published": "2026-02-23T09:22:21+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19633",
      "title": "TAPE: Tool-Guided Adaptive Planning and Constrained Execution in Language Model Agents",
      "abstract": "Language Model (LM) agents have demonstrated remarkable capabilities in solving tasks that require multiple interactions with the environment. However, they remain vulnerable in environments where a single error often leads to irrecoverable failure, particularly under strict feasibility constraints. We systematically analyze existing agent frameworks, identifying imperfect planning and stochastic execution as the primary causes. To address these challenges, we propose Tool-guided Adaptive Planning with constrained Execution (TAPE). TAPE enhances planning capability by aggregating multiple plans into a graph and employing an external solver to identify a feasible path. During execution, TAPE employs constrained decoding to reduce sampling noise, while adaptively re-planning whenever environmental feedback deviates from the intended state. Experiments across Sokoban, ALFWorld, MuSiQue, and GSM8K-Hard demonstrate that TAPE consistently outperforms existing frameworks, with particularly large gains on hard settings, improving success rates by 21.0 percentage points on hard settings on average, and by 20.0 percentage points for weaker base models on average. Code and data available at here.",
      "authors": [
        "Jongwon Jeong",
        "Jungtaek Kim",
        "Kangwook Lee"
      ],
      "url": "https://arxiv.org/abs/2602.19633",
      "published": "2026-02-23T09:19:56+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.19631",
      "title": "Localized Concept Erasure in Text-to-Image Diffusion Models via High-Level Representation Misdirection",
      "abstract": "Recent advances in text-to-image (T2I) diffusion models have seen rapid and widespread adoption. However, their powerful generative capabilities raise concerns about potential misuse for synthesizing harmful, private, or copyrighted content. To mitigate such risks, concept erasure techniques have emerged as a promising solution. Prior works have primarily focused on fine-tuning the denoising component (e.g., the U-Net backbone). However, recent causal tracing studies suggest that visual attribute information is localized in the early self-attention layers of the text encoder, indicating a potential alternative for concept erasing. Building on this insight, we conduct preliminary experiments and find that directly fine-tuning early layers can suppress target concepts but often degrades the generation quality of non-target concepts. To overcome this limitation, we propose High-Level Representation Misdirection (HiRM), which misdirects high-level semantic representations of target concepts in the text encoder toward designated vectors such as random directions or semantically defined directions (e.g., supercategories), while updating only early layers that contain causal states of visual attributes. Our decoupling strategy enables precise concept removal with minimal impact on unrelated concepts, as demonstrated by strong results on UnlearnCanvas and NSFW benchmarks across diverse targets (e.g., objects, styles, nudity). HiRM also preserves generative utility at low training cost, transfers to state-of-the-art architectures such as Flux without additional training, and shows synergistic effects with denoiser-based concept erasing methods.",
      "authors": [
        "Uichan Lee",
        "Jeonghyeon Kim",
        "Sangheum Hwang"
      ],
      "url": "https://arxiv.org/abs/2602.19631",
      "published": "2026-02-23T09:18:27+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19629",
      "title": "Cooperation After the Algorithm: Designing Human-AI Coexistence Beyond the Illusion of Collaboration",
      "abstract": "Generative artificial intelligence systems increasingly participate in research, law, education, media, and governance. Their fluent and adaptive outputs create an experience of collaboration. However, these systems do not bear responsibility, incur liability, or share stakes in downstream consequences. This structural asymmetry has already produced sanctions, professional errors, and governance failures in high-stakes contexts We argue that stable human-AI coexistence is an institutional achievement that depends on governance infrastructure capable of distributing residual risk. Drawing on institutional analysis and evolutionary cooperation theory, we introduce a formal inequality that specifies when reliance on AI yields positive expected cooperative value. The model makes explicit how governance conditions, system policy, and accountability regimes jointly determine whether cooperation is rational or structurally defective. From this formalization we derive a cooperation ecology framework with six design principles: reciprocity contracts, visible trust infrastructure, conditional cooperation modes, defection-mitigation mechanisms, narrative literacy against authority theatre, and an Earth-first sustainability constraint. We operationalize the framework through three policy artefacts: a Human-AI Cooperation Charter, a Defection Risk Register, and a Cooperation Readiness Audit. Together, these elements shift the unit of analysis from the user-AI dyad to the institutional environment that shapes incentives, signals, accountability, and repair. The paper provides a theoretical foundation and practical toolkit for designing human-AI systems that can sustain accountable, trustworthy cooperation over time.",
      "authors": [
        "Tatia Codreanu"
      ],
      "url": "https://arxiv.org/abs/2602.19629",
      "published": "2026-02-23T09:17:12+00:00",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19626",
      "title": "Nacrith: Neural Lossless Compression via Ensemble Context Modeling and High-Precision CDF Coding",
      "abstract": "We present Nacrith, a lossless compression system that combines a 135M-parameter transformer language model (SmolLM2-135M) with an ensemble of lightweight online predictors and a 32-bit arithmetic coder, achieving the best compression results among the systems evaluated in this study on natural language text. Beyond the base LLM-plus-arithmetic-coding paradigm, Nacrith introduces several contributions: (1) a CDF precision upgrade from 2^16 to 2^24 that eliminates ~75% of quantization overhead caused by minimum-probability floors in large vocabularies; (2) a token-level N-gram model for fast local predictions; (3) an adaptive log-space bias head correcting per-document LLM errors via online gradient descent; (4) confidence-based LLM skip for accelerating highly predictable tokens; (5) a hybrid binary format (NC06) extending neural compression to arbitrary binary files--to our knowledge a first among LLM-based compressors; (6) a llama cpp inference backend achieving ~7x faster single-token decode than PyTorch; (7) parallel multi-GPU compression across up to 8 workers; and (8) native KV cache sliding window reducing per-slide cost by ~37x. The system requires only ~500 MB of GGUF weights and ~1.2 GB VRAM per worker, running on consumer GPUs.   On alice29 (Canterbury Corpus, 152 KB), Nacrith achieves 0.918 bits per byte (bpb)--outperforming gzip by 3.1x, bzip2 by 2.5x, CMIX v21 by 44%, and ts_zip by 20%, while compressing below the 0th-, 1st-, and 2nd-order byte-level Shannon entropy bounds. On enwik8 (100 MB), Nacrith achieves 0.9389 bpb (11.74%), surpassing ts_zip (~1.11 bpb) by 15% and FineZip (1.024 bpb) by 8% despite using a 60x smaller model with no fine-tuning. An out-of-distribution (OOD) evaluation on a document published after the model's training cutoff confirms these gains are not memorization artifacts, achieving 0.723 bpb on unseen text.",
      "authors": [
        "Roberto Tacconelli"
      ],
      "url": "https://arxiv.org/abs/2602.19626",
      "published": "2026-02-23T09:14:05+00:00",
      "categories": [
        "cs.IT",
        "cs.CL"
      ]
    },
    {
      "id": "2602.19623",
      "title": "PedaCo-Gen: Scaffolding Pedagogical Agency in Human-AI Collaborative Video Authoring",
      "abstract": "While advancements in Text-to-Video (T2V) generative AI offer a promising path toward democratizing content creation, current models are often optimized for visual fidelity rather than instructional efficacy. This study introduces PedaCo-Gen, a pedagogically-informed human-AI collaborative video generating system for authoring instructional videos based on Mayer's Cognitive Theory of Multimedia Learning (CTML). Moving away from traditional \"one-shot\" generation, PedaCo-Gen introduces an Intermediate Representation (IR) phase, enabling educators to interactively review and refine video blueprints-comprising scripts and visual descriptions-with an AI reviewer. Our study with 23 education experts demonstrates that PedaCo-Gen significantly enhances video quality across various topics and CTML principles compared to baselines. Participants perceived the AI-driven guidance not merely as a set of instructions but as a metacognitive scaffold that augmented their instructional design expertise, reporting high production efficiency (M=4.26) and guide validity (M=4.04). These findings highlight the importance of reclaiming pedagogical agency through principled co-creation, providing a foundation for future AI authoring tools that harmonize generative power with human professional expertise.",
      "authors": [
        "Injun Baek",
        "Yearim Kim",
        "Nojun Kwak"
      ],
      "url": "https://arxiv.org/abs/2602.19623",
      "published": "2026-02-23T09:12:13+00:00",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "id": "2602.19622",
      "title": "VecFormer: Towards Efficient and Generalizable Graph Transformer with Graph Token Attention",
      "abstract": "Graph Transformer has demonstrated impressive capabilities in the field of graph representation learning. However, existing approaches face two critical challenges: (1) most models suffer from exponentially increasing computational complexity, making it difficult to scale to large graphs; (2) attention mechanisms based on node-level operations limit the flexibility of the model and result in poor generalization performance in out-of-distribution (OOD) scenarios. To address these issues, we propose \\textbf{VecFormer} (the \\textbf{Vec}tor Quantized Graph Trans\\textbf{former}), an efficient and highly generalizable model for node classification, particularly under OOD settings. VecFormer adopts a two-stage training paradigm. In the first stage, two codebooks are used to reconstruct the node features and the graph structure, aiming to learn the rich semantic \\texttt{Graph Codes}. In the second stage, attention mechanisms are performed at the \\texttt{Graph Token} level based on the transformed cross codebook, reducing computational complexity while enhancing the model's generalization capability. Extensive experiments on datasets of various sizes demonstrate that VecFormer outperforms the existing Graph Transformer in both performance and speed.",
      "authors": [
        "Jingbo Zhou",
        "Jun Xia",
        "Siyuan Li",
        "Yunfan Liu",
        "Wenjun Wang",
        "Yufei Huang",
        "Changxi Chi",
        "Mutian Hong",
        "Zhuoli Ouyang",
        "Shu Wang",
        "Zhongqi Wang",
        "Xingyu Wu",
        "Chang Yu",
        "Stan Z. Li"
      ],
      "url": "https://arxiv.org/abs/2602.19622",
      "published": "2026-02-23T09:10:39+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19620",
      "title": "Rules or Weights? Comparing User Understanding of Explainable AI Techniques with the Cognitive XAI-Adaptive Model",
      "abstract": "Rules and Weights are popular XAI techniques for explaining AI decisions. Yet, it remains unclear how to choose between them, lacking a cognitive framework to compare their interpretability. In an elicitation user study on forward and counterfactual decision tasks, we identified 7 reasoning strategies of interpreting three XAI Schemas - weights, rules, and their hybrid. To analyze their capabilities, we propose CoXAM, a Cognitive XAI-Adaptive Model with shared memory representation to encode instance attributes, linear weights, and decision rules. CoXAM employs computational rationality to choose among reasoning processes based on the trade-off in utility and reasoning time, separately for forward or counterfactual decision tasks. In a validation study, CoXAM demonstrated a stronger alignment with human decision-making compared to baseline machine learning proxy models. The model successfully replicated and explained several key empirical findings, including that counterfactual tasks are inherently harder than forward tasks, decision tree rules are harder to recall and apply than linear weights, and the helpfulness of XAI depends on the application data context, alongside identifying which underlying reasoning strategies were most effective. With CoXAM, we contribute a cognitive basis to accelerate debugging and benchmarking disparate XAI techniques.",
      "authors": [
        "Louth Bin Rawshan",
        "Zhuoyu Wang",
        "Brian Y Lim"
      ],
      "url": "https://arxiv.org/abs/2602.19620",
      "published": "2026-02-23T09:07:16+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.19619",
      "title": "Is Your Diffusion Sampler Actually Correct? A Sampler-Centric Evaluation of Discrete Diffusion Language Models",
      "abstract": "Discrete diffusion language models (dLLMs) provide a fast and flexible alternative to autoregressive models (ARMs) via iterative denoising with parallel updates. However, their evaluation is challenging: existing metrics conflate denoiser approximation error with sampler-induced error from the sampling dynamics, a problem that does not arise for ARMs whose autoregressive sampling exactly reflects the learned probability model. We introduce a sampler-centric oracle framework that replaces learned denoisers with an exact Hidden Markov Model posterior derived from a ground-truth Markov chain, isolating sampler-induced error in a controlled setting. We show that few-step discrete diffusion samplers are not distributionally correct even under an oracle denoiser, with transition-level mismatch that vanishes only as the number of steps approaches the sequence length. Moreover, improvements in negative log-likelihood, generative perplexity, or MAUVE do not imply correct sampling. Code is available at https://luhantang.github.io/dllm_sampler",
      "authors": [
        "Luhan Tang",
        "Longxuan Yu",
        "Shaorong Zhang",
        "Greg Ver Steeg"
      ],
      "url": "https://arxiv.org/abs/2602.19619",
      "published": "2026-02-23T09:06:13+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.20219",
      "title": "An Approach to Combining Video and Speech with Large Language Models in Human-Robot Interaction",
      "abstract": "Interpreting human intent accurately is a central challenge in human-robot interaction (HRI) and a key requirement for achieving more natural and intuitive collaboration between humans and machines. This work presents a novel multimodal HRI framework that combines advanced vision-language models, speech processing, and fuzzy logic to enable precise and adaptive control of a Dobot Magician robotic arm. The proposed system integrates Florence-2 for object detection, Llama 3.1 for natural language understanding, and Whisper for speech recognition, providing users with a seamless and intuitive interface for object manipulation through spoken commands. By jointly addressing scene perception and action planning, the approach enhances the reliability of command interpretation and execution. Experimental evaluations conducted on consumer-grade hardware demonstrate a command execution accuracy of 75\\%, highlighting both the robustness and adaptability of the system. Beyond its current performance, the proposed architecture serves as a flexible and extensible foundation for future HRI research, offering a practical pathway toward more sophisticated and natural human-robot collaboration through tightly coupled speech and vision-language processing.",
      "authors": [
        "Guanting Shen",
        "Zi Tian"
      ],
      "url": "https://arxiv.org/abs/2602.20219",
      "published": "2026-02-23T09:05:15+00:00",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19614",
      "title": "Workflow-Level Design Principles for Trustworthy GenAI in Automotive System Engineering",
      "abstract": "The adoption of large language models in safety-critical system engineering is constrained by trustworthiness, traceability, and alignment with established verification practices. We propose workflow-level design principles for trustworthy GenAI integration and demonstrate them in an end-to-end automotive pipeline, from requirement delta identification to SysML v2 architecture update and re-testing. First, we show that monolithic (\"big-bang\") prompting misses critical changes in large specifications, while section-wise decomposition with diversity sampling and lightweight NLP sanity checks improves completeness and correctness. Then, we propagate requirement deltas into SysML v2 models and validate updates via compilation and static analysis. Additionally, we ensure traceable regression testing by generating test cases through explicit mappings from specification variables to architectural ports and states, providing practical safeguards for GenAI used in safety-critical automotive engineering.",
      "authors": [
        "Chih-Hong Cheng",
        "Brian Hsuan-Cheng Liao",
        "Adam Molin",
        "Hasan Esen"
      ],
      "url": "https://arxiv.org/abs/2602.19614",
      "published": "2026-02-23T09:02:38+00:00",
      "categories": [
        "cs.SE",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19612",
      "title": "Anatomy of Unlearning: The Dual Impact of Fact Salience and Model Fine-Tuning",
      "abstract": "Machine Unlearning (MU) enables Large Language Models (LLMs) to remove unsafe or outdated information. However, existing work assumes that all facts are equally forgettable and largely ignores whether the forgotten knowledge originates from pretraining or supervised fine-tuning (SFT). In this paper, we introduce DUAL (Dual Unlearning Evaluation across Training Stages), a benchmark of 28.6k Wikidata-derived triplets annotated with fact popularity using Wikipedia link counts and LLM-based salience scores. Our experiments show that pretrained and SFT models respond differently to unlearning. An SFT step on the forget data yields smoother forgetting, more stable tuning, and 10-50% higher retention, while direct unlearning on pretrained models remains unstable and prone to relearning or catastrophic forgetting.",
      "authors": [
        "Borisiuk Anna",
        "Andrey Savchenko",
        "Alexander Panchenko",
        "Elena Tutubalina"
      ],
      "url": "https://arxiv.org/abs/2602.19612",
      "published": "2026-02-23T08:58:48+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.19610",
      "title": "Variational Inference for Bayesian MIDAS Regression",
      "abstract": "We develop a Coordinate Ascent Variational Inference (CAVI) algorithm for Bayesian Mixed Data Sampling (MIDAS) regression with linear weight parameterizations. The model separates impact coeffcients from weighting function parameters through a normalization constraint, creating a bilinear structure that renders generic Hamiltonian Monte Carlo samplers unreliable while preserving conditional conjugacy exploitable by CAVI. Each variational update admits a closed-form solution: Gaussian for regression coefficients and weight parameters, Inverse-Gamma for the error variance. The algorithm propagates uncertainty across blocks through second moments, distinguishing it from naive plug-in approximations. In a Monte Carlo study spanning 21 data-generating configurations with up to 50 predictors, CAVI produces posterior means nearly identical to a block Gibbs sampler benchmark while achieving speedups of 107x to 1,772x (Table 9). Generic automatic differentiation VI (ADVI), by contrast, produces bias 714 times larger while being orders of magnitude slower, confirming the value of model-specific derivations. Weight function parameters maintain excellent calibration (coverage above 92%) across all configurations. Impact coefficient credible intervals exhibit the underdispersion characteristic of mean-field approximations, with coverage declining from 89% to 55% as the number of predictors grows a documented trade-off between speed and interval calibration that structured variational methods can address. An empirical application to realized volatility forecasting on S&P 500 daily returns cofirms that CAVI and Gibbs sampling yield virtually identical point forecasts, with CAVI completing each monthly estimation in under 10 milliseconds.",
      "authors": [
        "Luigi Simeone"
      ],
      "url": "https://arxiv.org/abs/2602.19610",
      "published": "2026-02-23T08:51:26+00:00",
      "categories": [
        "cs.LG",
        "stat.CO",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19608",
      "title": "Satellite-Based Detection of Looted Archaeological Sites Using Machine Learning",
      "abstract": "Looting at archaeological sites poses a severe risk to cultural heritage, yet monitoring thousands of remote locations remains operationally difficult. We present a scalable and satellite-based pipeline to detect looted archaeological sites, using PlanetScope monthly mosaics (4.7m/pixel) and a curated dataset of 1,943 archaeological sites in Afghanistan (898 looted, 1,045 preserved) with multi-year imagery (2016--2023) and site-footprint masks. We compare (i) end-to-end CNN classifiers trained on raw RGB patches and (ii) traditional machine learning (ML) trained on handcrafted spectral/texture features and embeddings from recent remote-sensing foundation models. Results indicate that ImageNet-pretrained CNNs combined with spatial masking reach an F1 score of 0.926, clearly surpassing the strongest traditional ML setup, which attains an F1 score of 0.710 using SatCLIP-V+RF+Mean, i.e., location and vision embeddings fed into a Random Forest with mean-based temporal aggregation. Ablation studies demonstrate that ImageNet pretraining (even in the presence of domain shift) and spatial masking enhance performance. In contrast, geospatial foundation model embeddings perform competitively with handcrafted features, suggesting that looting signatures are extremely localized. The repository is available at https://github.com/microsoft/looted_site_detection.",
      "authors": [
        "Girmaw Abebe Tadesse",
        "Titien Bartette",
        "Andrew Hassanali",
        "Allen Kim",
        "Jonathan Chemla",
        "Andrew Zolli",
        "Yves Ubelmann",
        "Caleb Robinson",
        "Inbal Becker-Reshef",
        "Juan Lavista Ferres"
      ],
      "url": "https://arxiv.org/abs/2602.19608",
      "published": "2026-02-23T08:50:07+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19605",
      "title": "CLCR: Cross-Level Semantic Collaborative Representation for Multimodal Learning",
      "abstract": "Multimodal learning aims to capture both shared and private information from multiple modalities. However, existing methods that project all modalities into a single latent space for fusion often overlook the asynchronous, multi-level semantic structure of multimodal data. This oversight induces semantic misalignment and error propagation, thereby degrading representation quality. To address this issue, we propose Cross-Level Co-Representation (CLCR), which explicitly organizes each modality's features into a three-level semantic hierarchy and specifies level-wise constraints for cross-modal interactions. First, a semantic hierarchy encoder aligns shallow, mid, and deep features across modalities, establishing a common basis for interaction. And then, at each level, an Intra-Level Co-Exchange Domain (IntraCED) factorizes features into shared and private subspaces and restricts cross-modal attention to the shared subspace via a learnable token budget. This design ensures that only shared semantics are exchanged and prevents leakage from private channels. To integrate information across levels, the Inter-Level Co-Aggregation Domain (InterCAD) synchronizes semantic scales using learned anchors, selectively fuses the shared representations, and gates private cues to form a compact task representation. We further introduce regularization terms to enforce separation of shared and private features and to minimize cross-level interference. Experiments on six benchmarks spanning emotion recognition, event localization, sentiment analysis, and action recognition show that CLCR achieves strong performance and generalizes well across tasks.",
      "authors": [
        "Chunlei Meng",
        "Guanhong Huang",
        "Rong Fu",
        "Runmin Jian",
        "Zhongxue Gan",
        "Chun Ouyang"
      ],
      "url": "https://arxiv.org/abs/2602.19605",
      "published": "2026-02-23T08:47:19+00:00",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ]
    },
    {
      "id": "2602.19600",
      "title": "Manifold-Aligned Generative Transport",
      "abstract": "High-dimensional generative modeling is fundamentally a manifold-learning problem: real data concentrate near a low-dimensional structure embedded in the ambient space. Effective generators must therefore balance support fidelity -- placing probability mass near the data manifold -- with sampling efficiency. Diffusion models often capture near-manifold structure but require many iterative denoising steps and can leak off-support; normalizing flows sample in one pass but are limited by invertibility and dimension preservation. We propose MAGT (Manifold-Aligned Generative Transport), a flow-like generator that learns a one-shot, manifold-aligned transport from a low-dimensional base distribution to the data space. Training is performed at a fixed Gaussian smoothing level, where the score is well-defined and numerically stable. We approximate this fixed-level score using a finite set of latent anchor points with self-normalized importance sampling, yielding a tractable objective. MAGT samples in a single forward pass, concentrates probability near the learned support, and induces an intrinsic density with respect to the manifold volume measure, enabling principled likelihood evaluation for generated samples. We establish finite-sample Wasserstein bounds linking smoothing level and score-approximation accuracy to generative fidelity, and empirically improve fidelity and manifold concentration across synthetic and benchmark datasets while sampling substantially faster than diffusion models.",
      "authors": [
        "Xinyu Tian",
        "Xiaotong Shen"
      ],
      "url": "https://arxiv.org/abs/2602.19600",
      "published": "2026-02-23T08:42:40+00:00",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19598",
      "title": "Eye-Tracking-while-Reading: A Living Survey of Datasets with Open Library Support",
      "abstract": "Eye-tracking-while-reading corpora are a valuable resource for many different disciplines and use cases. Use cases range from studying the cognitive processes underlying reading to machine-learning-based applications, such as gaze-based assessments of reading comprehension. The past decades have seen an increase in the number and size of eye-tracking-while-reading datasets as well as increasing diversity with regard to the stimulus languages covered, the linguistic background of the participants, or accompanying psychometric or demographic data. The spread of data across different disciplines and the lack of data sharing standards across the communities lead to many existing datasets that cannot be easily reused due to a lack of interoperability. In this work, we aim at creating more transparency and clarity with regards to existing datasets and their features across different disciplines by i) presenting an extensive overview of existing datasets, ii) simplifying the sharing of newly created datasets by publishing a living overview online, https://dili-lab.github.io/datasets.html, presenting over 45 features for each dataset, and iii) integrating all publicly available datasets into the Python package pymovements which offers an eye-tracking datasets library. By doing so, we aim to strengthen the FAIR principles in eye-tracking-while-reading research and promote good scientific practices, such as reproducing and replicating studies.",
      "authors": [
        "Deborah N. Jakobi",
        "David R. Reich",
        "Paul Prasse",
        "Jana M. Hofmann",
        "Lena S. Bolliger",
        "Lena A. Jäger"
      ],
      "url": "https://arxiv.org/abs/2602.19598",
      "published": "2026-02-23T08:40:50+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.19594",
      "title": "ISO-Bench: Can Coding Agents Optimize Real-World Inference Workloads?",
      "abstract": "We introduce ISO-Bench, a benchmark for coding agents to test their capabilities on real-world inference optimization tasks. These tasks were taken from vLLM and SGLang, two of the most popular LLM serving frameworks. Each task provides an agent with a codebase and bottleneck description, whereby the agent must produce an optimization patch evaluated against expert human solutions. We curated 54 tasks from merged pull requests with measurable performance improvements. While existing benchmarks heavily use runtime-based metrics, such approaches can be gamed to pass tests without capturing the actual intent of the code changes. Therefore, we combine both hard (execution-based) and soft (LLM-based) metrics to show that both are necessary for complete evaluation. While evaluating both closed and open-source coding agents, we find no single agent dominates across codebases. Surprisingly, agents often identify correct bottlenecks but fail to execute working solutions. We also show that agents with identical underlying models differ substantially, suggesting scaffolding is as important as the model.",
      "authors": [
        "Ayush Nangia",
        "Shikhar Mishra",
        "Aman Gokrani",
        "Paras Chopra"
      ],
      "url": "https://arxiv.org/abs/2602.19594",
      "published": "2026-02-23T08:37:53+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19591",
      "title": "Detecting High-Potential SMEs with Heterogeneous Graph Neural Networks",
      "abstract": "Small and Medium Enterprises (SMEs) constitute 99.9% of U.S. businesses and generate 44% of economic activity, yet systematically identifying high-potential SMEs remains an open challenge. We introduce SME-HGT, a Heterogeneous Graph Transformer framework that predicts which SBIR Phase I awardees will advance to Phase II funding using exclusively public data. We construct a heterogeneous graph with 32,268 company nodes, 124 research topic nodes, and 13 government agency nodes connected by approximately 99,000 edges across three semantic relation types. SME-HGT achieves an AUPRC of 0.621 0.003 on a temporally-split test set, outperforming an MLP baseline (0.590 0.002) and R-GCN (0.608 0.013) across five random seeds. At a screening depth of 100 companies, SME-HGT attains 89.6% precision with a 2.14 lift over random selection. Our temporal evaluation protocol prevents information leakage, and our reliance on public data ensures reproducibility. These results demonstrate that relational structure among firms, research topics, and funding agencies provides meaningful signal for SME potential assessment, with implications for policymakers and early-stage investors.",
      "authors": [
        "Yijiashun Qi",
        "Hanzhe Guo",
        "Yijiazhen Qi"
      ],
      "url": "https://arxiv.org/abs/2602.19591",
      "published": "2026-02-23T08:35:55+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19585",
      "title": "Tri-Subspaces Disentanglement for Multimodal Sentiment Analysis",
      "abstract": "Multimodal Sentiment Analysis (MSA) integrates language, visual, and acoustic modalities to infer human sentiment. Most existing methods either focus on globally shared representations or modality-specific features, while overlooking signals that are shared only by certain modality pairs. This limits the expressiveness and discriminative power of multimodal representations. To address this limitation, we propose a Tri-Subspace Disentanglement (TSD) framework that explicitly factorizes features into three complementary subspaces: a common subspace capturing global consistency, submodally-shared subspaces modeling pairwise cross-modal synergies, and private subspaces preserving modality-specific cues. To keep these subspaces pure and independent, we introduce a decoupling supervisor together with structured regularization losses. We further design a Subspace-Aware Cross-Attention (SACA) fusion module that adaptively models and integrates information from the three subspaces to obtain richer and more robust representations. Experiments on CMU-MOSI and CMU-MOSEI demonstrate that TSD achieves state-of-the-art performance across all key metrics, reaching 0.691 MAE on CMU-MOSI and 54.9% ACC-7 on CMU-MOSEI, and also transfers well to multimodal intent recognition tasks. Ablation studies confirm that tri-subspace disentanglement and SACA jointly enhance the modeling of multi-granular cross-modal sentiment cues.",
      "authors": [
        "Chunlei Meng",
        "Jiabin Luo",
        "Zhenglin Yan",
        "Zhenyu Yu",
        "Rong Fu",
        "Zhongxue Gan",
        "Chun Ouyang"
      ],
      "url": "https://arxiv.org/abs/2602.19585",
      "published": "2026-02-23T08:19:54+00:00",
      "categories": [
        "cs.MM",
        "cs.AI"
      ]
    },
    {
      "id": "2602.20217",
      "title": "KnapSpec: Self-Speculative Decoding via Adaptive Layer Selection as a Knapsack Problem",
      "abstract": "Self-speculative decoding (SSD) accelerates LLM inference by skipping layers to create an efficient draft model, yet existing methods often rely on static heuristics that ignore the dynamic computational overhead of attention in long-context scenarios. We propose KnapSpec, a training-free framework that reformulates draft model selection as a knapsack problem to maximize tokens-per-time throughput. By decoupling Attention and MLP layers and modeling their hardware-specific latencies as functions of context length, KnapSpec adaptively identifies optimal draft configurations on the fly via a parallel dynamic programming algorithm. Furthermore, we provide the first rigorous theoretical analysis establishing cosine similarity between hidden states as a mathematically sound proxy for the token acceptance rate. This foundation allows our method to maintain high drafting faithfulness while navigating the shifting bottlenecks of real-world hardware. Our experiments on Qwen3 and Llama3 demonstrate that KnapSpec consistently outperforms state-of-the-art SSD baselines, achieving up to 1.47x wall-clock speedup across various benchmarks. Our plug-and-play approach ensures high-speed inference for long sequences without requiring additional training or compromising the target model's output distribution.",
      "authors": [
        "Seongjin Cha",
        "Gyuwan Kim",
        "Dongsu Han",
        "Tao Yang",
        "Insu Han"
      ],
      "url": "https://arxiv.org/abs/2602.20217",
      "published": "2026-02-23T08:13:03+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19584",
      "title": "Interpolation-Driven Machine Learning Approaches for Plume Shine Dose Estimation: A Comparison of XGBoost, Random Forest, and TabNet",
      "abstract": "Despite the success of machine learning (ML) in surrogate modeling, its use in radiation dose assessment is limited by safety-critical constraints, scarce training-ready data, and challenges in selecting suitable architectures for physics-dominated systems. Within this context, rapid and accurate plume shine dose estimation serves as a practical test case, as it is critical for nuclear facility safety assessment and radiological emergency response, while conventional photon-transport-based calculations remain computationally expensive. In this work, an interpolation-assisted ML framework was developed using discrete dose datasets generated with the pyDOSEIA suite for 17 gamma-emitting radionuclides across varying downwind distances, release heights, and atmospheric stability categories. The datasets were augmented using shape-preserving interpolation to construct dense, high-resolution training data. Two tree-based ML models (Random Forest and XGBoost) and one deep learning (DL) model (TabNet) were evaluated to examine predictive performance and sensitivity to dataset resolution. All models showed higher prediction accuracy with the interpolated high-resolution dataset than with the discrete data; however, XGBoost consistently achieved the highest accuracy. Interpretability analysis using permutation importance (tree-based models) and attention-based feature attribution (TabNet) revealed that performance differences stem from how the models utilize input features. Tree-based models focus mainly on dominant geometry-dispersion features (release height, stability category, and downwind distance), treating radionuclide identity as a secondary input, whereas TabNet distributes attention more broadly across multiple variables. For practical deployment, a web-based GUI was developed for interactive scenario evaluation and transparent comparison with photon-transport reference calculations.",
      "authors": [
        "Biswajit Sadhu",
        "Kalpak Gupte",
        "Trijit Sadhu",
        "S. Anand"
      ],
      "url": "https://arxiv.org/abs/2602.19584",
      "published": "2026-02-23T08:12:49+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19583",
      "title": "DEEP: Docker-based Execution and Evaluation Platform",
      "abstract": "Comparative evaluation of several systems is a recurrent task in researching. It is a key step before deciding which system to use for our work, or, once our research has been conducted, to demonstrate the potential of the resulting model. Furthermore, it is the main task of competitive, public challenges evaluation. Our proposed software (DEEP) automates both the execution and scoring of machine translation and optical character recognition models. Furthermore, it is easily extensible to other tasks. DEEP is prepared to receive dockerized systems, run them (extracting information at that same time), and assess hypothesis against some references. With this approach, evaluators can achieve a better understanding of the performance of each model. Moreover, the software uses a clustering algorithm based on a statistical analysis of the significance of the results yielded by each model, according to the evaluation metrics. As a result, evaluators are able to identify clusters of performance among the swarm of proposals and have a better understanding of the significance of their differences. Additionally, we offer a visualization web-app to ensure that the results can be adequately understood and interpreted. Finally, we present an exemplary case of use of DEEP.",
      "authors": [
        "Sergio Gómez González",
        "Miguel Domingo",
        "Francisco Casacuberta"
      ],
      "url": "https://arxiv.org/abs/2602.19583",
      "published": "2026-02-23T08:08:57+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.19582",
      "title": "Advantage-based Temporal Attack in Reinforcement Learning",
      "abstract": "Extensive research demonstrates that Deep Reinforcement Learning (DRL) models are susceptible to adversarially constructed inputs (i.e., adversarial examples), which can mislead the agent to take suboptimal or unsafe actions. Recent methods improve attack effectiveness by leveraging future rewards to guide adversarial perturbation generation over sequential time steps (i.e., reward-based attacks). However, these methods are unable to capture dependencies between different time steps in the perturbation generation process, resulting in a weak temporal correlation between the current perturbation and previous perturbations.In this paper, we propose a novel method called Advantage-based Adversarial Transformer (AAT), which can generate adversarial examples with stronger temporal correlations (i.e., time-correlated adversarial examples) to improve the attack performance. AAT employs a multi-scale causal self-attention (MSCSA) mechanism to dynamically capture dependencies between historical information from different time periods and the current state, thus enhancing the correlation between the current perturbation and the previous perturbation. Moreover, AAT introduces a weighted advantage mechanism, which quantifies the effectiveness of a perturbation in a given state and guides the generation process toward high-performance adversarial examples by sampling high-advantage regions. Extensive experiments demonstrate that the performance of AAT matches or surpasses mainstream adversarial attack baselines on Atari, DeepMind Control Suite and Google football tasks.",
      "authors": [
        "Shenghong He"
      ],
      "url": "https://arxiv.org/abs/2602.19582",
      "published": "2026-02-23T08:08:23+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19580",
      "title": "Leap+Verify: Regime-Adaptive Speculative Weight Prediction for Accelerating Neural Network Training",
      "abstract": "We introduce Leap+Verify, a framework that applies speculative execution -- predicting future model weights and validating predictions before acceptance -- to accelerate neural network training. Inspired by speculative decoding in language model inference and by the Automatically Scalable Computation (ASC) architecture for program execution, Leap+Verify decomposes training into three dynamically detected regimes (chaotic, transition, stable) using activation-space cosine similarity as a real-time Lyapunov proxy signal. Within each regime, analytic weight predictors (momentum, linear, quadratic extrapolation) attempt to forecast model parameters K training steps ahead; predictions are accepted only when validated against a held-out loss criterion. We evaluate Leap+Verify on GPT-2 124M and Qwen 2.5-1.5B trained on WikiText-103 across five random seeds, sweeping prediction depth K in {5, 10, 25, 50, 75, 100}. Momentum-based prediction (Adam moment extrapolation) fails catastrophically at both scales, with predicted losses exceeding actuals by 100-10,000x -- a universal norm explosion in optimizer-state extrapolation. Finite-difference predictors (linear, quadratic) succeed where momentum fails: at 124M, they achieve 24% strict acceptance at K=5 in stable regimes; at 1.5B, they achieve 37% strict acceptance in transition regimes. The scale-dependent finding is in regime distribution: GPT-2 124M spends 34% of training in stable regime, while Qwen 1.5B spends 64% in chaotic regime and reaches stable in only 0-2 of 40 checkpoints. Larger models are more predictable when predictable, but less often predictable -- the practical bottleneck shifts from predictor accuracy to regime availability. Cross-seed results are highly consistent (less than 1% validation loss variance), and the three-regime framework produces identical phase boundaries (plus or minus 50 steps) across seeds.",
      "authors": [
        "Jeremy McEntire"
      ],
      "url": "https://arxiv.org/abs/2602.19580",
      "published": "2026-02-23T08:01:44+00:00",
      "categories": [
        "cs.LG",
        "econ.GN"
      ]
    },
    {
      "id": "2602.19578",
      "title": "Goal-Oriented Influence-Maximizing Data Acquisition for Learning and Optimization",
      "abstract": "Active data acquisition is central to many learning and optimization tasks in deep neural networks, yet remains challenging because most approaches rely on predictive uncertainty estimates that are difficult to obtain reliably. To this end, we propose Goal-Oriented Influence- Maximizing Data Acquisition (GOIMDA), an active acquisition algorithm that avoids explicit posterior inference while remaining uncertainty-aware through inverse curvature. GOIMDA selects inputs by maximizing their expected influence on a user-specified goal functional, such as test loss, predictive entropy, or the value of an optimizer-recommended design. Leveraging first-order influence functions, we derive a tractable acquisition rule that combines the goal gradient, training-loss curvature, and candidate sensitivity to model parameters. We show theoretically that, for generalized linear models, GOIMDA approximates predictive-entropy minimization up to a correction term accounting for goal alignment and prediction bias, thereby, yielding uncertainty-aware behavior without maintaining a Bayesian posterior. Empirically, across learning tasks (including image and text classification) and optimization tasks (including noisy global optimization benchmarks and neural-network hyperparameter tuning), GOIMDA consistently reaches target performance with substantially fewer labeled samples or function evaluations than uncertainty-based active learning and Gaussian-process Bayesian optimization baselines.",
      "authors": [
        "Weichi Yao",
        "Bianca Dumitrascu",
        "Bryan R. Goldsmith",
        "Yixin Wang"
      ],
      "url": "https://arxiv.org/abs/2602.19578",
      "published": "2026-02-23T07:57:11+00:00",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19574",
      "title": "CTC-TTS: LLM-based dual-streaming text-to-speech with CTC alignment",
      "abstract": "Large-language-model (LLM)-based text-to-speech (TTS) systems can generate natural speech, but most are not designed for low-latency dual-streaming synthesis. High-quality dual-streaming TTS depends on accurate text--speech alignment and well-designed training sequences that balance synthesis quality and latency. Prior work often relies on GMM-HMM based forced-alignment toolkits (e.g., MFA), which are pipeline-heavy and less flexible than neural aligners; fixed-ratio interleaving of text and speech tokens struggles to capture text--speech alignment regularities. We propose CTC-TTS, which replaces MFA with a CTC based aligner and introduces a bi-word based interleaving strategy. Two variants are designed: CTC-TTS-L (token concatenation along the sequence length) for higher quality and CTC-TTS-F (embedding stacking along the feature dimension) for lower latency. Experiments show that CTC-TTS outperforms fixed-ratio interleaving and MFA-based baselines on streaming synthesis and zero-shot tasks. Speech samples are available at https://ctctts.github.io/.",
      "authors": [
        "Hanwen Liu",
        "Saierdaer Yusuyin",
        "Hao Huang",
        "Zhijian Ou"
      ],
      "url": "https://arxiv.org/abs/2602.19574",
      "published": "2026-02-23T07:44:14+00:00",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ]
    },
    {
      "id": "2602.19569",
      "title": "Temporal-Aware Heterogeneous Graph Reasoning with Multi-View Fusion for Temporal Question Answering",
      "abstract": "Question Answering over Temporal Knowledge Graphs (TKGQA) has attracted growing interest for handling time-sensitive queries. However, existing methods still struggle with: 1) weak incorporation of temporal constraints in question representation, causing biased reasoning; 2) limited ability to perform explicit multi-hop reasoning; and 3) suboptimal fusion of language and graph representations. We propose a novel framework with temporal-aware question encoding, multi-hop graph reasoning, and multi-view heterogeneous information fusion. Specifically, our approach introduces: 1) a constraint-aware question representation that combines semantic cues from language models with temporal entity dynamics; 2) a temporal-aware graph neural network for explicit multi-hop reasoning via time-aware message passing; and 3) a multi-view attention mechanism for more effective fusion of question context and temporal graph knowledge. Experiments on multiple TKGQA benchmarks demonstrate consistent improvements over multiple baselines.",
      "authors": [
        "Wuzhenghong Wen",
        "Bowen Zhou",
        "Jinwen Huang",
        "Xianjie Wu",
        "Yuwei Sun",
        "Su Pan",
        "Liang Li",
        "Jianting Liu"
      ],
      "url": "https://arxiv.org/abs/2602.19569",
      "published": "2026-02-23T07:36:36+00:00",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19565",
      "title": "DICArt: Advancing Category-level Articulated Object Pose Estimation in Discrete State-Spaces",
      "abstract": "Articulated object pose estimation is a core task in embodied AI. Existing methods typically regress poses in a continuous space, but often struggle with 1) navigating a large, complex search space and 2) failing to incorporate intrinsic kinematic constraints. In this work, we introduce DICArt (DIsCrete Diffusion for Articulation Pose Estimation), a novel framework that formulates pose estimation as a conditional discrete diffusion process. Instead of operating in a continuous domain, DICArt progressively denoises a noisy pose representation through a learned reverse diffusion procedure to recover the GT pose. To improve modeling fidelity, we propose a flexible flow decider that dynamically determines whether each token should be denoised or reset, effectively balancing the real and noise distributions during diffusion. Additionally, we incorporate a hierarchical kinematic coupling strategy, estimating the pose of each rigid part hierarchically to respect the object's kinematic structure. We validate DICArt on both synthetic and real-world datasets. Experimental results demonstrate its superior performance and robustness. By integrating discrete generative modeling with structural priors, DICArt offers a new paradigm for reliable category-level 6D pose estimation in complex environments.",
      "authors": [
        "Li Zhang",
        "Mingyu Mei",
        "Ailing Wang",
        "Xianhui Meng",
        "Yan Zhong",
        "Xinyuan Song",
        "Liu Liu",
        "Rujing Wang",
        "Zaixing He",
        "Cewu Lu"
      ],
      "url": "https://arxiv.org/abs/2602.19565",
      "published": "2026-02-23T07:30:47+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19562",
      "title": "A Multimodal Framework for Aligning Human Linguistic Descriptions with Visual Perceptual Data",
      "abstract": "Establishing stable mappings between natural language expressions and visual percepts is a foundational problem for both cognitive science and artificial intelligence. Humans routinely ground linguistic reference in noisy, ambiguous perceptual contexts, yet the mechanisms supporting such cross-modal alignment remain poorly understood. In this work, we introduce a computational framework designed to model core aspects of human referential interpretation by integrating linguistic utterances with perceptual representations derived from large-scale, crowd-sourced imagery. The system approximates human perceptual categorization by combining scale-invariant feature transform (SIFT) alignment with the Universal Quality Index (UQI) to quantify similarity in a cognitively plausible feature space, while a set of linguistic preprocessing and query-transformation operations captures pragmatic variability in referring expressions. We evaluate the model on the Stanford Repeated Reference Game corpus (15,000 utterances paired with tangram stimuli), a paradigm explicitly developed to probe human-level perceptual ambiguity and coordination. Our framework achieves robust referential grounding. It requires 65\\% fewer utterances than human interlocutors to reach stable mappings and can correctly identify target objects from single referring expressions 41.66\\% of the time (versus 20\\% for humans).These results suggest that relatively simple perceptual-linguistic alignment mechanisms can yield human-competitive behavior on a classic cognitive benchmark, and offers insights into models of grounded communication, perceptual inference, and cross-modal concept formation. Code is available at https://anonymous.4open.science/r/metasequoia-9D13/README.md .",
      "authors": [
        "Joseph Bingham"
      ],
      "url": "https://arxiv.org/abs/2602.19562",
      "published": "2026-02-23T07:20:11+00:00",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "id": "2602.20214",
      "title": "Right to History: A Sovereignty Kernel for Verifiable AI Agent Execution",
      "abstract": "AI agents increasingly act on behalf of humans, yet no existing system provides a tamper-evident, independently verifiable record of what they did. As regulations such as the EU AI Act begin mandating automatic logging for high-risk AI systems, this gap carries concrete consequences -- especially for agents running on personal hardware, where no centralized provider controls the log. Extending Floridi's informational rights framework from data about individuals to actions performed on their behalf, this paper proposes the Right to History: the principle that individuals are entitled to a complete, verifiable record of every AI agent action on their own hardware. The paper formalizes this principle through five system invariants with structured proof sketches, and implements it in PunkGo, a Rust sovereignty kernel that unifies RFC 6962 Merkle tree audit logs, capability-based isolation, energy-budget governance, and a human-approval mechanism. Adversarial testing confirms all five invariants hold. Performance evaluation shows sub-1.3 ms median action latency, ~400 actions/sec throughput, and 448-byte Merkle inclusion proofs at 10,000 log entries.",
      "authors": [
        "Jing Zhang"
      ],
      "url": "https://arxiv.org/abs/2602.20214",
      "published": "2026-02-23T07:09:36+00:00",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.OS"
      ]
    },
    {
      "id": "2602.19555",
      "title": "Agentic AI as a Cybersecurity Attack Surface: Threats, Exploits, and Defenses in Runtime Supply Chains",
      "abstract": "Agentic systems built on large language models (LLMs) extend beyond text generation to autonomously retrieve information and invoke tools. This runtime execution model shifts the attack surface from build-time artifacts to inference-time dependencies, exposing agents to manipulation through untrusted data and probabilistic capability resolution. While prior work has focused on model-level vulnerabilities, security risks emerging from cyclic and interdependent runtime behavior remain fragmented. We systematize these risks within a unified runtime framework, categorizing threats into data supply chain attacks (transient context injection and persistent memory poisoning) and tool supply chain attacks (discovery, implementation, and invocation). We further identify the Viral Agent Loop, in which agents act as vectors for self-propagating generative worms without exploiting code-level flaws. Finally, we advocate a Zero-Trust Runtime Architecture that treats context as untrusted control flow and constrains tool execution through cryptographic provenance rather than semantic inference.",
      "authors": [
        "Xiaochong Jiang",
        "Shiqi Yang",
        "Wenting Yang",
        "Yichen Liu",
        "Cheng Ji"
      ],
      "url": "https://arxiv.org/abs/2602.19555",
      "published": "2026-02-23T06:57:57+00:00",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19552",
      "title": "The Sample Complexity of Replicable Realizable PAC Learning",
      "abstract": "In this paper, we consider the problem of replicable realizable PAC learning. We construct a particularly hard learning problem and show a sample complexity lower bound with a close to $(\\log|H|)^{3/2}$ dependence on the size of the hypothesis class $H$. Our proof uses several novel techniques and works by defining a particular Cayley graph associated with $H$ and analyzing a suitable random walk on this graph by examining the spectral properties of its adjacency matrix.   Furthermore, we show an almost matching upper bound for the lower bound instance, meaning if a stronger lower bound exists, one would have to consider a different instance of the problem.",
      "authors": [
        "Kasper Green Larsen",
        "Markus Engelund Mathiasen",
        "Chirag Pabbaraju",
        "Clement Svendsen"
      ],
      "url": "https://arxiv.org/abs/2602.19552",
      "published": "2026-02-23T06:52:11+00:00",
      "categories": [
        "cs.LG",
        "cs.CC",
        "cs.DS"
      ]
    },
    {
      "id": "2602.19549",
      "title": "Sculpting the Vector Space: Towards Efficient Multi-Vector Visual Document Retrieval via Prune-then-Merge Framework",
      "abstract": "Visual Document Retrieval (VDR), which aims to retrieve relevant pages within vast corpora of visually-rich documents, is of significance in current multimodal retrieval applications. The state-of-the-art multi-vector paradigm excels in performance but suffers from prohibitive overhead, a problem that current efficiency methods like pruning and merging address imperfectly, creating a difficult trade-off between compression rate and feature fidelity. To overcome this dilemma, we introduce Prune-then-Merge, a novel two-stage framework that synergizes these complementary approaches. Our method first employs an adaptive pruning stage to filter out low-information patches, creating a refined, high-signal set of embeddings. Subsequently, a hierarchical merging stage compresses this pre-filtered set, effectively summarizing semantic content without the noise-induced feature dilution seen in single-stage methods. Extensive experiments on 29 VDR datasets demonstrate that our framework consistently outperforms existing methods, significantly extending the near-lossless compression range and providing robust performance at high compression ratios.",
      "authors": [
        "Yibo Yan",
        "Mingdong Ou",
        "Yi Cao",
        "Xin Zou",
        "Jiahao Huo",
        "Shuliang Liu",
        "James Kwok",
        "Xuming Hu"
      ],
      "url": "https://arxiv.org/abs/2602.19549",
      "published": "2026-02-23T06:45:19+00:00",
      "categories": [
        "cs.CL",
        "cs.CV",
        "cs.IR"
      ]
    },
    {
      "id": "2602.19548",
      "title": "Beyond a Single Extractor: Re-thinking HTML-to-Text Extraction for LLM Pretraining",
      "abstract": "One of the first pre-processing steps for constructing web-scale LLM pretraining datasets involves extracting text from HTML. Despite the immense diversity of web content, existing open-source datasets predominantly apply a single fixed extractor to all webpages. In this work, we investigate whether this practice leads to suboptimal coverage and utilization of Internet data. We first show that while different extractors may lead to similar model performance on standard language understanding tasks, the pages surviving a fixed filtering pipeline can differ substantially. This suggests a simple intervention: by taking a Union over different extractors, we can increase the token yield of DCLM-Baseline by up to 71% while maintaining benchmark performance. We further show that for structured content such as tables and code blocks, extractor choice can significantly impact downstream task performance, with differences of up to 10 percentage points (p.p.) on WikiTQ and 3 p.p. on HumanEval.",
      "authors": [
        "Jeffrey Li",
        "Josh Gardner",
        "Doug Kang",
        "Fangping Shi",
        "Karanjeet Singh",
        "Chun-Liang Li",
        "Herumb Shandilya",
        "David Hall",
        "Oncel Tuzel",
        "Percy Liang",
        "Ludwig Schmidt",
        "Hadi Pour Ansari",
        "Fartash Faghri"
      ],
      "url": "https://arxiv.org/abs/2602.19548",
      "published": "2026-02-23T06:41:57+00:00",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19543",
      "title": "Hyper-KGGen: A Skill-Driven Knowledge Extractor for High-Quality Knowledge Hypergraph Generation",
      "abstract": "Knowledge hypergraphs surpass traditional binary knowledge graphs by encapsulating complex $n$-ary atomic facts, providing a more comprehensive paradigm for semantic representation. However, constructing high-quality hypergraphs remains challenging due to the \\textit{scenario gap}: generic extractors struggle to generalize across diverse domains with specific jargon, while existing methods often fail to balance structural skeletons with fine-grained details. To bridge this gap, we propose \\textbf{Hyper-KGGen}, a skill-driven framework that reformulates extraction as a dynamic skill-evolving process. First, Hyper-KGGen employs a \\textit{coarse-to-fine} mechanism to systematically decompose documents, ensuring full-dimensional coverage from binary links to complex hyperedges. Crucially, it incorporates an \\textit{adaptive skill acquisition} module that actively distills domain expertise into a Global Skill Library. This is achieved via a stability-based feedback loop, where extraction stability serves as a relative reward signal to induce high-quality skills from unstable traces and missed predictions. Additionally, we present \\textbf{HyperDocRED}, a rigorously annotated benchmark for document-level knowledge hypergraph extraction. Experiments demonstrate that Hyper-KGGen significantly outperforms strong baselines, validating that evolved skills provide substantially richer guidance than static few-shot examples in multi-scenario settings.",
      "authors": [
        "Rizhuo Huang",
        "Yifan Feng",
        "Rundong Xue",
        "Shihui Ying",
        "Jun-Hai Yong",
        "Chuan Shi",
        "Shaoyi Du",
        "Yue Gao"
      ],
      "url": "https://arxiv.org/abs/2602.19543",
      "published": "2026-02-23T06:32:00+00:00",
      "categories": [
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "id": "2602.19540",
      "title": "A Green Learning Approach to LDCT Image Restoration",
      "abstract": "This work proposes a green learning (GL) approach to restore medical images. Without loss of generality, we use low-dose computed tomography (LDCT) images as examples. LDCT images are susceptible to noise and artifacts, where the imaging process introduces distortion. LDCT image restoration is an important preprocessing step for further medical analysis. Deep learning (DL) methods have been developed to solve this problem. We examine an alternative solution using the Green Learning (GL) methodology. The new restoration method is characterized by mathematical transparency, computational and memory efficiency, and high performance. Experiments show that our GL method offers state-of-the-art restoration performance at a smaller model size and with lower inference complexity.",
      "authors": [
        "Wei Wang",
        "Yixing Wu",
        "C. -C. Jay Kuo"
      ],
      "url": "https://arxiv.org/abs/2602.19540",
      "published": "2026-02-23T06:21:56+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19539",
      "title": "Can a Teenager Fool an AI? Evaluating Low-Cost Cosmetic Attacks on Age Estimation Systems",
      "abstract": "Age estimation systems are increasingly deployed as gatekeepers for age-restricted online content, yet their robustness to cosmetic modifications has not been systematically evaluated. We investigate whether simple, household-accessible cosmetic changes, including beards, grey hair, makeup, and simulated wrinkles, can cause AI age estimators to classify minors as adults. To study this threat at scale without ethical concerns, we simulate these physical attacks on 329 facial images of individuals aged 10 to 21 using a VLM image editor (Gemini 2.5 Flash Image). We then evaluate eight models from our prior benchmark: five specialized architectures (MiVOLO, Custom-Best, Herosan, MiViaLab, DEX) and three vision-language models (Gemini 3 Flash, Gemini 2.5 Flash, GPT-5-Nano). We introduce the Attack Conversion Rate (ACR), defined as the fraction of images predicted as minor at baseline that flip to adult after attack, a population-agnostic metric that does not depend on the ratio of minors to adults in the test set. Our results reveal that a synthetic beard alone achieves 28 to 69 percent ACR across all eight models; combining all four attacks shifts predicted age by +7.7 years on average across all 329 subjects and reaches up to 83 percent ACR; and vision-language models exhibit lower ACR (59 to 71 percent) than specialized models (63 to 83 percent) under the full attack, although the ACR ranges overlap and the difference is not statistically tested. These findings highlight a critical vulnerability in deployed age-verification pipelines and call for adversarial robustness evaluation as a mandatory criterion for model selection.",
      "authors": [
        "Xingyu Shen",
        "Tommy Duong",
        "Xiaodong An",
        "Zengqi Zhao",
        "Zebang Hu",
        "Haoyu Hu",
        "Ziyou Wang",
        "Finn Guo",
        "Simiao Ren"
      ],
      "url": "https://arxiv.org/abs/2602.19539",
      "published": "2026-02-23T06:13:52+00:00",
      "categories": [
        "cs.CV",
        "cs.CR",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19538",
      "title": "Cost-Aware Diffusion Active Search",
      "abstract": "Active search for recovering objects of interest through online, adaptive decision making with autonomous agents requires trading off exploration of unknown environments with exploitation of prior observations in the search space. Prior work has proposed information gain and Thompson sampling based myopic, greedy approaches for agents to actively decide query or search locations when the number of targets is unknown. Decision making algorithms in such partially observable environments have also shown that agents capable of lookahead over a finite horizon outperform myopic policies for active search. Unfortunately, lookahead algorithms typically rely on building a computationally expensive search tree that is simulated and updated based on the agent's observations and a model of the environment dynamics. Instead, in this work, we leverage the sequence modeling abilities of diffusion models to sample lookahead action sequences that balance the exploration-exploitation trade-off for active search without building an exhaustive search tree. We identify the optimism bias in prior diffusion based reinforcement learning approaches when applied to the active search setting and propose mitigating solutions for efficient cost-aware decision making with both single and multi-agent teams. Our proposed algorithm outperforms standard baselines in offline reinforcement learning in terms of full recovery rate and is computationally more efficient than tree search in cost-aware active decision making.",
      "authors": [
        "Arundhati Banerjee",
        "Jeff Schneider"
      ],
      "url": "https://arxiv.org/abs/2602.19538",
      "published": "2026-02-23T06:11:51+00:00",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19536",
      "title": "Fore-Mamba3D: Mamba-based Foreground-Enhanced Encoding for 3D Object Detection",
      "abstract": "Linear modeling methods like Mamba have been merged as the effective backbone for the 3D object detection task. However, previous Mamba-based methods utilize the bidirectional encoding for the whole non-empty voxel sequence, which contains abundant useless background information in the scenes. Though directly encoding foreground voxels appears to be a plausible solution, it tends to degrade detection performance. We attribute this to the response attenuation and restricted context representation in the linear modeling for fore-only sequences. To address this problem, we propose a novel backbone, termed Fore-Mamba3D, to focus on the foreground enhancement by modifying Mamba-based encoder. The foreground voxels are first sampled according to the predicted scores. Considering the response attenuation existing in the interaction of foreground voxels across different instances, we design a regional-to-global slide window (RGSW) to propagate the information from regional split to the entire sequence. Furthermore, a semantic-assisted and state spatial fusion module (SASFMamba) is proposed to enrich contextual representation by enhancing semantic and geometric awareness within the Mamba model. Our method emphasizes foreground-only encoding and alleviates the distance-based and causal dependencies in the linear autoregression model. The superior performance across various benchmarks demonstrates the effectiveness of Fore-Mamba3D in the 3D object detection task.",
      "authors": [
        "Zhiwei Ning",
        "Xuanang Gao",
        "Jiaxi Cao",
        "Runze Yang",
        "Huiying Xu",
        "Xinzhong Zhu",
        "Jie Yang",
        "Wei Liu"
      ],
      "url": "https://arxiv.org/abs/2602.19536",
      "published": "2026-02-23T06:03:07+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.20213",
      "title": "CodeHacker: Automated Test Case Generation for Detecting Vulnerabilities in Competitive Programming Solutions",
      "abstract": "The evaluation of Large Language Models (LLMs) for code generation relies heavily on the quality and robustness of test cases. However, existing benchmarks often lack coverage for subtle corner cases, allowing incorrect solutions to pass. To bridge this gap, we propose CodeHacker, an automated agent framework dedicated to generating targeted adversarial test cases that expose latent vulnerabilities in program submissions. Mimicking the hack mechanism in competitive programming, CodeHacker employs a multi-strategy approach, including stress testing, anti-hash attacks, and logic-specific targeting to break specific code submissions. To ensure the validity and reliability of these attacks, we introduce a Calibration Phase, where the agent iteratively refines its own Validator and Checker via self-generated adversarial probes before evaluating contestant code.Experiments demonstrate that CodeHacker significantly improves the True Negative Rate (TNR) of existing datasets, effectively filtering out incorrect solutions that were previously accepted. Furthermore, generated adversarial cases prove to be superior training data, boosting the performance of RL-trained models on benchmarks like LiveCodeBench.",
      "authors": [
        "Jingwei Shi",
        "Xinxiang Yin",
        "Jing Huang",
        "Jinman Zhao",
        "Shengyu Tao"
      ],
      "url": "https://arxiv.org/abs/2602.20213",
      "published": "2026-02-23T05:59:30+00:00",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "id": "2602.19534",
      "title": "Large Language Model-Assisted UAV Operations and Communications: A Multifaceted Survey and Tutorial",
      "abstract": "Uncrewed Aerial Vehicles (UAVs) are widely deployed across diverse applications due to their mobility and agility. Recent advances in Large Language Models (LLMs) offer a transformative opportunity to enhance UAV intelligence beyond conventional optimization-based and learning-based approaches. By integrating LLMs into UAV systems, advanced environmental understanding, swarm coordination, mobility optimization, and high-level task reasoning can be achieved, thereby allowing more adaptive and context-aware aerial operations. This survey systematically explores the intersection of LLMs and UAV technologies and proposes a unified framework that consolidates existing architectures, methodologies, and applications for UAVs. We first present a structured taxonomy of LLM adaptation techniques for UAVs, including pretraining, fine-tuning, Retrieval-Augmented Generation (RAG), and prompt engineering, along with key reasoning capabilities such as Chain-of-Thought (CoT) and In-Context Learning (ICL). We then examine LLM-assisted UAV communications and operations, covering navigation, mission planning, swarm control, safety, autonomy, and network management. After that, the survey further discusses Multimodal LLMs (MLLMs) for human-swarm interaction, perception-driven navigation, and collaborative control. Finally, we address ethical considerations, including bias, transparency, accountability, and Human-in-the-Loop (HITL) strategies, and outline future research directions. Overall, this work positions LLM-assisted UAVs as a foundation for intelligent and adaptive aerial systems.",
      "authors": [
        "Yousef Emami",
        "Hao Zhou",
        "Radha Reddy",
        "Atefeh Hajijamali Arani",
        "Biliang Wang",
        "Kai Li",
        "Luis Almeida",
        "Zhu Han"
      ],
      "url": "https://arxiv.org/abs/2602.19534",
      "published": "2026-02-23T05:56:43+00:00",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19533",
      "title": "Grokking Finite-Dimensional Algebra",
      "abstract": "This paper investigates the grokking phenomenon, which refers to the sudden transition from a long memorization to generalization observed during neural networks training, in the context of learning multiplication in finite-dimensional algebras (FDA). While prior work on grokking has focused mainly on group operations, we extend the analysis to more general algebraic structures, including non-associative, non-commutative, and non-unital algebras. We show that learning group operations is a special case of learning FDA, and that learning multiplication in FDA amounts to learning a bilinear product specified by the algebra's structure tensor. For algebras over the reals, we connect the learning problem to matrix factorization with an implicit low-rank bias, and for algebras over finite fields, we show that grokking emerges naturally as models must learn discrete representations of algebraic elements. This leads us to experimentally investigate the following core questions: (i) how do algebraic properties such as commutativity, associativity, and unitality influence both the emergence and timing of grokking, (ii) how structural properties of the structure tensor of the FDA, such as sparsity and rank, influence generalization, and (iii) to what extent generalization correlates with the model learning latent embeddings aligned with the algebra's representation. Our work provides a unified framework for grokking across algebraic structures and new insights into how mathematical structure governs neural network generalization dynamics.",
      "authors": [
        "Pascal Jr Tikeng Notsawo",
        "Guillaume Dumas",
        "Guillaume Rabusseau"
      ],
      "url": "https://arxiv.org/abs/2602.19533",
      "published": "2026-02-23T05:55:52+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.RA"
      ]
    },
    {
      "id": "2602.19531",
      "title": "A Statistical Approach for Modeling Irregular Multivariate Time Series with Missing Observations",
      "abstract": "Irregular multivariate time series with missing values present significant challenges for predictive modeling in domains such as healthcare. While deep learning approaches often focus on temporal interpolation or complex architectures to handle irregularities, we propose a simpler yet effective alternative: extracting time-agnostic summary statistics to eliminate the temporal axis. Our method computes four key features per variable-mean and standard deviation of observed values, as well as the mean and variability of changes between consecutive observations to create a fixed-dimensional representation. These features are then utilized with standard classifiers, such as logistic regression and XGBoost. Evaluated on four biomedical datasets (PhysioNet Challenge 2012, 2019, PAMAP2, and MIMIC-III), our approach achieves state-of-the-art performance, surpassing recent transformer and graph-based models by 0.5-1.7% in AUROC/AUPRC and 1.1-1.7% in accuracy/F1-score, while reducing computational complexity. Ablation studies demonstrate that feature extraction-not classifier choice-drives performance gains, and our summary statistics outperform raw/imputed input in most benchmarks. In particular, we identify scenarios where missing patterns themselves encode predictive signals, as in sepsis prediction (PhysioNet, 2019), where missing indicators alone can achieve 94.2% AUROC with XGBoost, only 1.6% lower than using original raw data as input. Our results challenge the necessity of complex temporal modeling when task objectives permit time-agnostic representations, providing an efficient and interpretable solution for irregular time series classification.",
      "authors": [
        "Dingyi Nie",
        "Yixing Wu",
        "C. -C. Jay Kuo"
      ],
      "url": "https://arxiv.org/abs/2602.19531",
      "published": "2026-02-23T05:48:17+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19528",
      "title": "Beyond Accuracy: A Unified Random Matrix Theory Diagnostic Framework for Crash Classification Models",
      "abstract": "Crash classification models in transportation safety are typically evaluated using accuracy, F1, or AUC, metrics that cannot reveal whether a model is silently overfitting. We introduce a spectral diagnostic framework grounded in Random Matrix Theory (RMT) and Heavy-Tailed Self-Regularization (HTSR) that spans the ML taxonomy: weight matrices for BERT/ALBERT/Qwen2.5, out-of-fold increment matrices for XGBoost/Random Forest, empirical Hessians for Logistic Regression, induced affinity matrices for Decision Trees, and Graph Laplacians for KNN. Evaluating nine model families on two Iowa DOT crash classification tasks (173,512 and 371,062 records respectively), we find that the power-law exponent $α$ provides a structural quality signal: well-regularized models consistently yield $α$ within $[2, 4]$ (mean $2.87 \\pm 0.34$), while overfit variants show $α< 2$ or spectral collapse. We observe a strong rank correlation between $α$ and expert agreement (Spearman $ρ= 0.89$, $p < 0.001$), suggesting spectral quality captures model behaviors aligned with expert reasoning. We propose an $α$-based early stopping criterion and a spectral model selection protocol, and validate both against cross-validated F1 baselines. Sparse Lanczos approximations make the framework scalable to large datasets.",
      "authors": [
        "Ibne Farabi Shihab",
        "Sanjeda Akter",
        "Anuj Sharma"
      ],
      "url": "https://arxiv.org/abs/2602.19528",
      "published": "2026-02-23T05:42:54+00:00",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19526",
      "title": "How to Train Your Deep Research Agent? Prompt, Reward, and Policy Optimization in Search-R1",
      "abstract": "Deep Research agents tackle knowledge-intensive tasks through multi-round retrieval and decision-oriented generation. While reinforcement learning (RL) has been shown to improve performance in this paradigm, its contributions remain underexplored. To fully understand the role of RL, we conduct a systematic study along three decoupled dimensions: prompt template, reward function, and policy optimization. Our study reveals that: 1) the Fast Thinking template yields greater stability and better performance than the Slow Thinking template used in prior work; 2) the F1-based reward underperforms the EM due to training collapse driven by answer avoidance; this can be mitigated by incorporating action-level penalties, ultimately surpassing EM; 3) REINFORCE outperforms PPO while requiring fewer search actions, whereas GRPO shows the poorest stability among policy optimization methods. Building on these insights, we then introduce Search-R1++, a strong baseline that improves the performance of Search-R1 from 0.403 to 0.442 (Qwen2.5-7B) and 0.289 to 0.331 (Qwen2.5-3B). We hope that our findings can pave the way for more principled and reliable RL training strategies in Deep Research systems.",
      "authors": [
        "Yinuo Xu",
        "Shuo Lu",
        "Jianjie Cheng",
        "Meng Wang",
        "Qianlong Xie",
        "Xingxing Wang",
        "Ran He",
        "Jian Liang"
      ],
      "url": "https://arxiv.org/abs/2602.19526",
      "published": "2026-02-23T05:33:17+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.19519",
      "title": "Ada-RS: Adaptive Rejection Sampling for Selective Thinking",
      "abstract": "Large language models (LLMs) are increasingly being deployed in cost and latency-sensitive settings. While chain-of-thought improves reasoning, it can waste tokens on simple requests. We study selective thinking for tool-using LLMs and introduce Adaptive Rejection Sampling (Ada-RS), an algorithm-agnostic sample filtering framework for learning selective and efficient reasoning. For each given context, Ada-RS scores multiple sampled completions with an adaptive length-penalized reward then applies stochastic rejection sampling to retain only high-reward candidates (or preference pairs) for downstream optimization. We demonstrate how Ada-RS plugs into both preference pair (e.g. DPO) or grouped policy optimization strategies (e.g. DAPO). Using Qwen3-8B with LoRA on a synthetic tool call-oriented e-commerce benchmark, Ada-RS improves the accuracy-efficiency frontier over standard algorithms by reducing average output tokens by up to 80% and reducing thinking rate by up to 95% while maintaining or improving tool call accuracy. These results highlight that training-signal selection is a powerful lever for efficient reasoning in latency-sensitive deployments.",
      "authors": [
        "Yirou Ge",
        "Yixi Li",
        "Alec Chiu",
        "Shivani Shekhar",
        "Zijie Pan",
        "Avinash Thangali",
        "Yun-Shiuan Chuang",
        "Chaitanya Kulkarni",
        "Uma Kona",
        "Linsey Pang",
        "Prakhar Mehrotra"
      ],
      "url": "https://arxiv.org/abs/2602.19519",
      "published": "2026-02-23T05:20:15+00:00",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19517",
      "title": "Classroom Final Exam: An Instructor-Tested Reasoning Benchmark",
      "abstract": "We introduce \\CFE{} (\\textbf{C}lassroom \\textbf{F}inal \\textbf{E}xam), a multimodal benchmark for evaluating the reasoning capabilities of large language models across more than 20 STEM domains. \\CFE{} is curated from repeatedly used, authentic university homework and exam problems, together with reference solutions provided by course instructors. \\CFE{} presents a significant challenge even for frontier models: the newly released Gemini-3.1-pro-preview achieves an overall accuracy of 59.69\\%, while the second-best model, Gemini-3-flash-preview, reaches 55.46\\%, leaving considerable room for improvement. Beyond leaderboard results, we perform a diagnostic analysis by decomposing reference solutions into reasoning flows. We find that although frontier models can often answer intermediate sub-questions correctly, they struggle to reliably derive and maintain correct intermediate states throughout multi-step solutions. We further observe that model-generated solutions typically have more reasoning steps than those provided by the instructor, indicating suboptimal step efficiency and a higher risk of error accumulation. The data and code are available at https://github.com/Analogy-AI/CFE_Bench.",
      "authors": [
        "Chongyang Gao",
        "Diji Yang",
        "Shuyan Zhou",
        "Xichen Yan",
        "Luchuan Song",
        "Shuo Li",
        "Kezhen Chen"
      ],
      "url": "https://arxiv.org/abs/2602.19517",
      "published": "2026-02-23T05:17:41+00:00",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "id": "2602.19512",
      "title": "Variational Trajectory Optimization of Anisotropic Diffusion Schedules",
      "abstract": "We introduce a variational framework for diffusion models with anisotropic noise schedules parameterized by a matrix-valued path $M_t(θ)$ that allocates noise across subspaces. Central to our framework is a trajectory-level objective that jointly trains the score network and learns $M_t(θ)$, which encompasses general parameterization classes of matrix-valued noise schedules. We further derive an estimator for the derivative with respect to $θ$ of the score that enables efficient optimization of the $M_t(θ)$ schedule. For inference, we develop an efficiently-implementable reverse-ODE solver that is an anisotropic generalization of the second-order Heun discretization algorithm. Across CIFAR-10, AFHQv2, FFHQ, and ImageNet-64, our method consistently improves upon the baseline EDM model in all NFE regimes. Code is available at https://github.com/lizeyu090312/anisotropic-diffusion-paper.",
      "authors": [
        "Pengxi Liu",
        "Zeyu Michael Li",
        "Xiang Cheng"
      ],
      "url": "https://arxiv.org/abs/2602.19512",
      "published": "2026-02-23T04:56:41+00:00",
      "categories": [
        "cs.LG",
        "cs.CV"
      ]
    },
    {
      "id": "2602.19510",
      "title": "Less is More: Convergence Benefits of Fewer Data Weight Updates over Longer Horizon",
      "abstract": "Data mixing--the strategic reweighting of training domains--is a critical component in training robust machine learning models. This problem is naturally formulated as a bilevel optimization task, where the outer loop optimizes domain weights to minimize validation loss, and the inner loop optimizes model parameters to minimize the weighted training loss. Classical bilevel optimization relies on hypergradients, which theoretically require the inner optimization to reach convergence. However, due to computational constraints, state-of-the-art methods use a finite, often small, number of inner update steps before updating the weights. The theoretical implications of this approximation are not well understood. In this work, we rigorously analyze the convergence behavior of data mixing with a finite number of inner steps $T$. We prove that the \"greedy\" practical approach of using $T=1$ can fail even in a simple quadratic example. Under a fixed parameter update budget $N$ and assuming the per-domain losses are strongly convex, we show that the optimal $T$ scales as $Θ(\\log N)$ (resp., $Θ({(N \\log N)}^{1/2})$) for the data mixing problem with access to full (resp., stochastic) gradients. We complement our theoretical results with proof-of-concept experiments.",
      "authors": [
        "Rudrajit Das",
        "Neel Patel",
        "Meisam Razaviyayn",
        "Vahab Mirrokni"
      ],
      "url": "https://arxiv.org/abs/2602.19510",
      "published": "2026-02-23T04:50:13+00:00",
      "categories": [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19509",
      "title": "Pyramid MoA: A Probabilistic Framework for Cost-Optimized Anytime Inference",
      "abstract": "Large Language Models (LLMs) face a persistent trade-off between inference cost and reasoning capability. While \"Oracle\" models (e.g., Llama-3-70B) achieve state-of-the-art accuracy, they are prohibitively expensive for high-volume deployment. Smaller models (e.g., 8B parameters) are cost-effective but struggle with complex tasks. In this work, we propose \"Pyramid MoA\", a hierarchical Mixture-of-Agents architecture that uses a lightweight Router to dynamically escalate queries only when necessary. By leveraging semantic agreement and confidence calibration among an ensemble of small models, our Router identifies \"hard\" problems with high precision. On the GSM8K benchmark, our system achieves 93.0% accuracy, effectively matching the Oracle baseline (98.0%) while reducing compute costs by 61%. We demonstrate that the system introduces negligible latency overhead (+0.82s) and allows for a tunable trade-off between performance and budget.",
      "authors": [
        "Arindam Khaled"
      ],
      "url": "https://arxiv.org/abs/2602.19509",
      "published": "2026-02-23T04:47:47+00:00",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19506",
      "title": "Relational Feature Caching for Accelerating Diffusion Transformers",
      "abstract": "Feature caching approaches accelerate diffusion transformers (DiTs) by storing the output features of computationally expensive modules at certain timesteps, and exploiting them for subsequent steps to reduce redundant computations. Recent forecasting-based caching approaches employ temporal extrapolation techniques to approximate the output features with cached ones. Although effective, relying exclusively on temporal extrapolation still suffers from significant prediction errors, leading to performance degradation. Through a detailed analysis, we find that 1) these errors stem from the irregular magnitude of changes in the output features, and 2) an input feature of a module is strongly correlated with the corresponding output. Based on this, we propose relational feature caching (RFC), a novel framework that leverages the input-output relationship to enhance the accuracy of the feature prediction. Specifically, we introduce relational feature estimation (RFE) to estimate the magnitude of changes in the output features from the inputs, enabling more accurate feature predictions. We also present relational cache scheduling (RCS), which estimates the prediction errors using the input features and performs full computations only when the errors are expected to be substantial. Extensive experiments across various DiT models demonstrate that RFC consistently outperforms prior approaches significantly. Project page is available at https://cvlab.yonsei.ac.kr/projects/RFC",
      "authors": [
        "Byunggwan Son",
        "Jeimin Jeon",
        "Jeongwoo Choi",
        "Bumsub Ham"
      ],
      "url": "https://arxiv.org/abs/2602.19506",
      "published": "2026-02-23T04:45:38+00:00",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19502",
      "title": "Human-Guided Agentic AI for Multimodal Clinical Prediction: Lessons from the AgentDS Healthcare Benchmark",
      "abstract": "Agentic AI systems are increasingly capable of autonomous data science workflows, yet clinical prediction tasks demand domain expertise that purely automated approaches struggle to provide. We investigate how human guidance of agentic AI can improve multimodal clinical prediction, presenting our approach to all three AgentDS Healthcare benchmark challenges: 30-day hospital readmission prediction (Macro-F1 = 0.8986), emergency department cost forecasting (MAE = $465.13), and discharge readiness assessment (Macro-F1 = 0.7939). Across these tasks, human analysts directed the agentic workflow at key decision points, multimodal feature engineering from clinical notes, scanned PDF billing receipts, and time-series vital signs; task-appropriate model selection; and clinically informed validation strategies. Our approach ranked 5th overall in the healthcare domain, with a 3rd-place finish on the discharge readiness task. Ablation studies reveal that human-guided decisions compounded to a cumulative gain of +0.065 F1 over automated baselines, with multimodal feature extraction contributing the largest single improvement (+0.041 F1). We distill three generalizable lessons: (1) domain-informed feature engineering at each pipeline stage yields compounding gains that outperform extensive automated search; (2) multimodal data integration requires task-specific human judgment that no single extraction strategy generalizes across clinical text, PDFs, and time-series; and (3) deliberate ensemble diversity with clinically motivated model configurations outperforms random hyperparameter search. These findings offer practical guidance for teams deploying agentic AI in healthcare settings where interpretability, reproducibility, and clinical validity are essential.",
      "authors": [
        "Lalitha Pranathi Pulavarthy",
        "Raajitha Muthyala",
        "Aravind V Kuruvikkattil",
        "Zhenan Yin",
        "Rashmita Kudamala",
        "Saptarshi Purkayastha"
      ],
      "url": "https://arxiv.org/abs/2602.19502",
      "published": "2026-02-23T04:37:45+00:00",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19498",
      "title": "Softmax is not Enough (for Adaptive Conformal Classification)",
      "abstract": "The merit of Conformal Prediction (CP), as a distribution-free framework for uncertainty quantification, depends on generating prediction sets that are efficient, reflected in small average set sizes, while adaptive, meaning they signal uncertainty by varying in size according to input difficulty. A central limitation for deep conformal classifiers is that the nonconformity scores are derived from softmax outputs, which can be unreliable indicators of how certain the model truly is about a given input, sometimes leading to overconfident misclassifications or undue hesitation. In this work, we argue that this unreliability can be inherited by the prediction sets generated by CP, limiting their capacity for adaptiveness. We propose a new approach that leverages information from the pre-softmax logit space, using the Helmholtz Free Energy as a measure of model uncertainty and sample difficulty. By reweighting nonconformity scores with a monotonic transformation of the energy score of each sample, we improve their sensitivity to input difficulty. Our experiments with four state-of-the-art score functions on multiple datasets and deep architectures show that this energy-based enhancement improves the adaptiveness of the prediction sets, leading to a notable increase in both efficiency and adaptiveness compared to baseline nonconformity scores, without introducing any post-hoc complexity.",
      "authors": [
        "Navid Akhavan Attar",
        "Hesam Asadollahzadeh",
        "Ling Luo",
        "Uwe Aickelin"
      ],
      "url": "https://arxiv.org/abs/2602.19498",
      "published": "2026-02-23T04:33:04+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19491",
      "title": "Botson: An Accessible and Low-Cost Platform for Social Robotics Research",
      "abstract": "Trust remains a critical barrier to the effective integration of Artificial Intelligence (AI) into human-centric domains. Disembodied agents, such as voice assistants, often fail to establish trust due to their inability to convey non-verbal social cues. This paper introduces the architecture of Botson: an anthropomorphic social robot powered by a large language model (LLM). Botson was created as a low-cost and accessible platform for social robotics research.",
      "authors": [
        "Samuel Bellaire",
        "Abdalmalek Abu-raddaha",
        "Natalie Kim",
        "Nathan Morhan",
        "William Elliott",
        "Samir Rawashdeh"
      ],
      "url": "https://arxiv.org/abs/2602.19491",
      "published": "2026-02-23T04:21:05+00:00",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "id": "2602.19489",
      "title": "Federated Learning Playground",
      "abstract": "We present Federated Learning Playground, an interactive browser-based platform inspired by and extends TensorFlow Playground that teaches core Federated Learning (FL) concepts. Users can experiment with heterogeneous client data distributions, model hyperparameters, and aggregation algorithms directly in the browser without coding or system setup, and observe their effects on client and global models through real-time visualizations, gaining intuition for challenges such as non-IID data, local overfitting, and scalability. The playground serves as an easy to use educational tool, lowering the entry barrier for newcomers to distributed AI while also offering a sandbox for rapidly prototyping and comparing FL methods. By democratizing exploration of FL, it promotes broader understanding and adoption of this important paradigm.",
      "authors": [
        "Bryan Guanrong Shan",
        "Alysa Ziying Tan",
        "Han Yu"
      ],
      "url": "https://arxiv.org/abs/2602.19489",
      "published": "2026-02-23T04:14:40+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.20210",
      "title": "Multimodal Crystal Flow: Any-to-Any Modality Generation for Unified Crystal Modeling",
      "abstract": "Crystal modeling spans a family of conditional and unconditional generation tasks across different modalities, including crystal structure prediction (CSP) and \\emph{de novo} generation (DNG). While recent deep generative models have shown promising performance, they remain largely task-specific, lacking a unified framework that shares crystal representations across different generation tasks. To address this limitation, we propose \\emph{Multimodal Crystal Flow (MCFlow)}, a unified multimodal flow model that realizes multiple crystal generation tasks as distinct inference trajectories via independent time variables for atom types and crystal structures. To enable multimodal flow in a standard transformer model, we introduce a composition- and symmetry-aware atom ordering with hierarchical permutation augmentation, injecting strong compositional and crystallographic priors without explicit structural templates. Experiments on the MP-20 and MPTS-52 benchmarks show that MCFlow achieves competitive performance against task-specific baselines across multiple crystal generation tasks.",
      "authors": [
        "Kiyoung Seong",
        "Sungsoo Ahn",
        "Sehui Han",
        "Changyoung Park"
      ],
      "url": "https://arxiv.org/abs/2602.20210",
      "published": "2026-02-23T03:59:47+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19483",
      "title": "Making Conformal Predictors Robust in Healthcare Settings: a Case Study on EEG Classification",
      "abstract": "Quantifying uncertainty in clinical predictions is critical for high-stakes diagnosis tasks. Conformal prediction offers a principled approach by providing prediction sets with theoretical coverage guarantees. However, in practice, patient distribution shifts violate the i.i.d. assumptions underlying standard conformal methods, leading to poor coverage in healthcare settings. In this work, we evaluate several conformal prediction approaches on EEG seizure classification, a task with known distribution shift challenges and label uncertainty. We demonstrate that personalized calibration strategies can improve coverage by over 20 percentage points while maintaining comparable prediction set sizes. Our implementation is available via PyHealth, an open-source healthcare AI framework: https://github.com/sunlabuiuc/PyHealth.",
      "authors": [
        "Arjun Chatterjee",
        "Sayeed Sajjad Razin",
        "John Wu",
        "Siddhartha Laghuvarapu",
        "Jathurshan Pradeepkumar",
        "Jimeng Sun"
      ],
      "url": "https://arxiv.org/abs/2602.19483",
      "published": "2026-02-23T03:59:32+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19475",
      "title": "Scale-PINN: Learning Efficient Physics-Informed Neural Networks Through Sequential Correction",
      "abstract": "Physics-informed neural networks (PINNs) have emerged as a promising mesh-free paradigm for solving partial differential equations, yet adoption in science and engineering is limited by slow training and modest accuracy relative to modern numerical solvers. We introduce the Sequential Correction Algorithm for Learning Efficient PINN (Scale-PINN), a learning strategy that bridges modern physics-informed learning with numerical algorithms. Scale-PINN incorporates the iterative residual-correction principle, a cornerstone of numerical solvers, directly into the loss formulation, marking a paradigm shift in how PINN losses can be conceived and constructed. This integration enables Scale-PINN to achieve unprecedented convergence speed across PDE problems from different physics domain, including reducing training time on a challenging fluid-dynamics problem for state-of-the-art PINN from hours to sub-2 minutes while maintaining superior accuracy, and enabling application to representative problems in aerodynamics and urban science. By uniting the rigor of numerical methods with the flexibility of deep learning, Scale-PINN marks a significant leap toward the practical adoption of PINNs in science and engineering through scalable, physics-informed learning. Codes are available at https://github.com/chiuph/SCALE-PINN.",
      "authors": [
        "Pao-Hsiung Chiu",
        "Jian Cheng Wong",
        "Chin Chun Ooi",
        "Chang Wei",
        "Yuchen Fan",
        "Yew-Soon Ong"
      ],
      "url": "https://arxiv.org/abs/2602.19475",
      "published": "2026-02-23T03:38:06+00:00",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG",
        "physics.comp-ph"
      ]
    },
    {
      "id": "2602.20209",
      "title": "Regressor-guided Diffusion Model for De Novo Peptide Sequencing with Explicit Mass Control",
      "abstract": "The discovery of novel proteins relies on sensitive protein identification, for which de novo peptide sequencing (DNPS) from mass spectra is a crucial approach. While deep learning has advanced DNPS, existing models inadequately enforce the fundamental mass consistency constraint, that a predicted peptide's mass must match the experimental measured precursor mass. Previous DNPS methods often treat this critical information as a simple input feature or use it in post-processing, leading to numerous implausible predictions that do not adhere to this fundamental physical property. To address this limitation, we introduce DiffuNovo, a novel regressor-guided diffusion model for de novo peptide sequencing that provides explicit peptide-level mass control. Our approach integrates the mass constraint at two critical stages: during training, a novel peptide-level mass loss guides model optimization, while at inference, regressor-based guidance from gradient-based updates in the latent space steers the generation to compel the predicted peptide adheres to the mass constraint. Comprehensive evaluations on established benchmarks demonstrate that DiffuNovo surpasses state-of-the-art methods in DNPS accuracy. Additionally, as the first DNPS model to employ a diffusion model as its core backbone, DiffuNovo leverages the powerful controllability of diffusion architecture and achieves a significant reduction in mass error, thereby producing much more physically plausible peptides. These innovations represent a substantial advancement toward robust and broadly applicable DNPS. The source code is available in the supplementary material.",
      "authors": [
        "Shaorong Chen",
        "Jingbo Zhou",
        "Jun Xia"
      ],
      "url": "https://arxiv.org/abs/2602.20209",
      "published": "2026-02-23T03:26:25+00:00",
      "categories": [
        "q-bio.QM",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19467",
      "title": "Can Large Language Models Replace Human Coders? Introducing ContentBench",
      "abstract": "Can low-cost large language models (LLMs) take over the interpretive coding work that still anchors much of empirical content analysis? This paper introduces ContentBench, a public benchmark suite that helps answer this replacement question by tracking how much agreement low-cost LLMs achieve and what they cost on the same interpretive coding tasks. The suite uses versioned tracks that invite researchers to contribute new benchmark datasets. I report results from the first track, ContentBench-ResearchTalk v1.0: 1,000 synthetic, social-media-style posts about academic research labeled into five categories spanning praise, critique, sarcasm, questions, and procedural remarks. Reference labels are assigned only when three state-of-the-art reasoning models (GPT-5, Gemini 2.5 Pro, and Claude Opus 4.1) agree unanimously, and all final labels are checked by the author as a quality-control audit. Among the 59 evaluated models, the best low-cost LLMs reach roughly 97-99% agreement with these jury labels, far above GPT-3.5 Turbo, the model behind early ChatGPT and the initial wave of LLM-based text annotation. Several top models can code 50,000 posts for only a few dollars, pushing large-scale interpretive coding from a labor bottleneck toward questions of validation, reporting, and governance. At the same time, small open-weight models that run locally still struggle on sarcasm-heavy items (for example, Llama 3.2 3B reaches only 4% agreement on hard-sarcasm). ContentBench is released with data, documentation, and an interactive quiz at contentbench.github.io to support comparable evaluations over time and to invite community extensions.",
      "authors": [
        "Michael Haman"
      ],
      "url": "https://arxiv.org/abs/2602.19467",
      "published": "2026-02-23T03:26:17+00:00",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "id": "2602.19463",
      "title": "PuppetChat: Fostering Intimate Communication through Bidirectional Actions and Micronarratives",
      "abstract": "As a primary channel for sustaining modern intimate relationships, instant messaging facilitates frequent connection across distances. However, today's tools often dilute care; they favor single tap reactions and vague emojis that do not support two way action responses, do not preserve the feeling that the exchange keeps going without breaking, and are weakly tied to who we are and what we share. To address this challenge, we present PuppetChat, a dyadic messaging prototype that restores this expressive depth through embodied interaction. PuppetChat uses a reciprocity aware recommender to encourage responsive actions and generates personalized micronarratives from user stories to ground interactions in personal history. Our 10-day field study with 11 dyads of close partners or friends revealed that this approach enhanced social presence, supported more expressive self disclosure, and sustained continuity and shared memories.",
      "authors": [
        "Emma Jiren Wang",
        "Siying Hu",
        "Zhicong Lu"
      ],
      "url": "https://arxiv.org/abs/2602.19463",
      "published": "2026-02-23T03:17:27+00:00",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    },
    {
      "id": "2602.19461",
      "title": "Laplacian Multi-scale Flow Matching for Generative Modeling",
      "abstract": "In this paper, we present Laplacian multiscale flow matching (LapFlow), a novel framework that enhances flow matching by leveraging multi-scale representations for image generative modeling. Our approach decomposes images into Laplacian pyramid residuals and processes different scales in parallel through a mixture-of-transformers (MoT) architecture with causal attention mechanisms. Unlike previous cascaded approaches that require explicit renoising between scales, our model generates multi-scale representations in parallel, eliminating the need for bridging processes. The proposed multi-scale architecture not only improves generation quality but also accelerates the sampling process and promotes scaling flow matching methods. Through extensive experimentation on CelebA-HQ and ImageNet, we demonstrate that our method achieves superior sample quality with fewer GFLOPs and faster inference compared to single-scale and multi-scale flow matching baselines. The proposed model scales effectively to high-resolution generation (up to 1024$\\times$1024) while maintaining lower computational overhead.",
      "authors": [
        "Zelin Zhao",
        "Petr Molodyk",
        "Haotian Xue",
        "Yongxin Chen"
      ],
      "url": "https://arxiv.org/abs/2602.19461",
      "published": "2026-02-23T03:09:56+00:00",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19458",
      "title": "ComplLLM: Fine-tuning LLMs to Discover Complementary Signals for Decision-making",
      "abstract": "Multi-agent decision pipelines can outperform single agent workflows when complementarity holds, i.e., different agents bring unique information to the table to inform a final decision. We propose ComplLLM, a post-training framework based on decision theory that fine-tunes a decision-assistant LLM using complementary information as reward to output signals that complement existing agent decisions. We validate ComplLLM on synthetic and real-world tasks involving domain experts, demonstrating how the approach recovers known complementary information and produces plausible explanations of complementary signals to support downstream decision-makers.",
      "authors": [
        "Ziyang Guo",
        "Yifan Wu",
        "Jason Hartline",
        "Kenneth Holstein",
        "Jessica Hullman"
      ],
      "url": "https://arxiv.org/abs/2602.19458",
      "published": "2026-02-23T03:01:52+00:00",
      "categories": [
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "id": "2602.19455",
      "title": "SenTSR-Bench: Thinking with Injected Knowledge for Time-Series Reasoning",
      "abstract": "Time-series diagnostic reasoning is essential for many applications, yet existing solutions face a persistent gap: general reasoning large language models (GRLMs) possess strong reasoning skills but lack the domain-specific knowledge to understand complex time-series patterns. Conversely, fine-tuned time-series LLMs (TSLMs) understand these patterns but lack the capacity to generalize reasoning for more complicated questions. To bridge this gap, we propose a hybrid knowledge-injection framework that injects TSLM-generated insights directly into GRLM's reasoning trace, thereby achieving strong time-series reasoning with in-domain knowledge. As collecting data for knowledge injection fine-tuning is costly, we further leverage a reinforcement learning-based approach with verifiable rewards (RLVR) to elicit knowledge-rich traces without human supervision, then transfer such an in-domain thinking trace into GRLM for efficient knowledge injection. We further release SenTSR-Bench, a multivariate time-series-based diagnostic reasoning benchmark collected from real-world industrial operations. Across SenTSR-Bench and other public datasets, our method consistently surpasses TSLMs by 9.1%-26.1% and GRLMs by 7.9%-22.4%, delivering robust, context-aware time-series diagnostic insights.",
      "authors": [
        "Zelin He",
        "Boran Han",
        "Xiyuan Zhang",
        "Shuai Zhang",
        "Haotian Lin",
        "Qi Zhu",
        "Haoyang Fang",
        "Danielle C. Maddix",
        "Abdul Fatir Ansari",
        "Akash Chandrayan",
        "Abhinav Pradhan",
        "Bernie Wang",
        "Matthew Reimherr"
      ],
      "url": "https://arxiv.org/abs/2602.19455",
      "published": "2026-02-23T02:55:32+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19450",
      "title": "Red-Teaming Claude Opus and ChatGPT-based Security Advisors for Trusted Execution Environments",
      "abstract": "Trusted Execution Environments (TEEs) (e.g., Intel SGX and ArmTrustZone) aim to protect sensitive computation from a compromised operating system, yet real deployments remain vulnerable to microarchitectural leakage, side-channel attacks, and fault injection. In parallel, security teams increasingly rely on Large Language Model (LLM) assistants as security advisors for TEE architecture review, mitigation planning, and vulnerability triage. This creates a socio-technical risk surface: assistants may hallucinate TEE mechanisms, overclaim guarantees (e.g., what attestation does and does not establish), or behave unsafely under adversarial prompting.   We present a red-teaming study of two prevalently deployed LLM assistants in the role of TEE security advisors: ChatGPT-5.2 and Claude Opus-4.6, focusing on the inherent limitations and transferability of prompt-induced failures across LLMs. We introduce TEE-RedBench, a TEE-grounded evaluation methodology comprising (i) a TEE-specific threat model for LLM-mediated security work, (ii) a structured prompt suite spanning SGX and TrustZone architecture, attestation and key management, threat modeling, and non-operational mitigation guidance, along with policy-bound misuse probes, and (iii) an annotation rubric that jointly measures technical correctness, groundedness, uncertainty calibration, refusal quality, and safe helpfulness. We find that some failures are not purely idiosyncratic, transferring up to 12.02% across LLM assistants, and we connect these outcomes to secure architecture by outlining an \"LLM-in-the-loop\" evaluation pipeline: policy gating, retrieval grounding, structured templates, and lightweight verification checks that, when combined, reduce failures by 80.62%.",
      "authors": [
        "Kunal Mukherjee"
      ],
      "url": "https://arxiv.org/abs/2602.19450",
      "published": "2026-02-23T02:47:05+00:00",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19444",
      "title": "PIS: A Physics-Informed System for Accurate State Partitioning of $Aβ_{42}$ Protein Trajectories",
      "abstract": "Understanding the conformational evolution of $β$-amyloid ($Aβ$), particularly the $Aβ_{42}$ isoform, is fundamental to elucidating the pathogenic mechanisms underlying Alzheimer's disease. However, existing end-to-end deep learning models often struggle to capture subtle state transitions in protein trajectories due to a lack of explicit physical constraints. In this work, we introduce PIS, a Physics-Informed System designed for robust metastable state partitioning. By integrating pre-computed physical priors, such as the radius of gyration and solvent-accessible surface area, into the extraction of topological features, our model achieves superior performance on the $Aβ_{42}$ dataset. Furthermore, PIS provides an interactive platform that features dynamic monitoring of physical characteristics and multi-dimensional result validation. This system offers biological researchers a powerful set of analytical tools with physically grounded interpretability. A demonstration video of PIS is available on https://youtu.be/AJHGzUtRCg0.",
      "authors": [
        "Qianfeng Yu",
        "Ningkang Peng",
        "Yanhui Gu"
      ],
      "url": "https://arxiv.org/abs/2602.19444",
      "published": "2026-02-23T02:27:18+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19441",
      "title": "When AI Teammates Meet Code Review: Collaboration Signals Shaping the Integration of Agent-Authored Pull Requests",
      "abstract": "Autonomous coding agents increasingly contribute to software development by submitting pull requests on GitHub; yet, little is known about how these contributions integrate into human-driven review workflows. We present a large empirical study of agent-authored pull requests using the public AIDev dataset, examining integration outcomes, resolution speed, and review-time collaboration signals. Using logistic regression with repository-clustered standard errors, we find that reviewer engagement has the strongest correlation with successful integration, whereas larger change sizes and coordination-disrupting actions, such as force pushes, are associated with a lower likelihood of merging. In contrast, iteration intensity alone provides limited explanatory power once collaboration signals are considered. A qualitative analysis further shows that successful integration occurs when agents engage in actionable review loops that converge toward reviewer expectations. Overall, our results highlight that the effective integration of agent-authored pull requests depends not only on code quality but also on alignment with established review and coordination practices.",
      "authors": [
        "Costain Nachuma",
        "Minhaz Zibran"
      ],
      "url": "https://arxiv.org/abs/2602.19441",
      "published": "2026-02-23T02:20:56+00:00",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19439",
      "title": "OptiRepair: Closed-Loop Diagnosis and Repair of Supply Chain Optimization Models with LLM Agents",
      "abstract": "Supply chain optimization models frequently become infeasible because of modeling errors. Diagnosis and repair require scarce OR expertise: analysts must interpret solver diagnostics, trace root causes across echelons, and fix formulations without sacrificing operational soundness. Whether AI agents can perform this task remains untested. We decompose this task into two phases: a domain-agnostic feasibility phase that iteratively repairs any LP using IIS-guided diagnosis, and a domain-specific validation phase that enforces five rationality checks grounded in inventory theory. We test 22 API models from seven families on 976 multi-echelon supply chain problems and train two 8B-parameter models with self-taught reasoning and solver-verified rewards. The trained models reach 81.7% Rational Recovery Rate (RRR) -- the fraction of problems resolved to both feasibility and operational rationality -- versus 42.2% for the best API model and 21.3% on average. The gap concentrates in Phase 1 repair, where API models average 27.6% recovery rate versus 97.2% for trained models. Two gaps separate current AI from reliable model repair: solver interaction, as API models restore only 27.6% of infeasible formulations; and operational rationale, as roughly one in four feasible repairs violate supply chain theory. Each gap requires a different intervention -- targeted training closes the solver interaction gap, while explicit specification as solver-verifiable checks closes the rationality gap. For organizations adopting AI in operational planning, formalizing what 'rational' means in their context is the higher-return investment.",
      "authors": [
        "Ruicheng Ao",
        "David Simchi-Levi",
        "Xinshang Wang"
      ],
      "url": "https://arxiv.org/abs/2602.19439",
      "published": "2026-02-23T02:19:05+00:00",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ]
    },
    {
      "id": "2602.19437",
      "title": "FinSight-Net:A Physics-Aware Decoupled Network with Frequency-Domain Compensation for Underwater Fish Detection in Smart Aquaculture",
      "abstract": "Underwater fish detection (UFD) is a core capability for smart aquaculture and marine ecological monitoring. While recent detectors improve accuracy by stacking feature extractors or introducing heavy attention modules, they often incur substantial computational overhead and, more importantly, neglect the physics that fundamentally limits UFD: wavelength-dependent absorption and turbidity-induced scattering significantly degrade contrast, blur fine structures, and introduce backscattering noise, leading to unreliable localization and recognition. To address these challenges, we propose FinSight-Net, an efficient and physics-aware detection framework tailored for complex aquaculture environments. FinSight-Net introduces a Multi-Scale Decoupled Dual-Stream Processing (MS-DDSP) bottleneck that explicitly targets frequency-specific information loss via heterogeneous convolutional branches, suppressing backscattering artifacts while compensating distorted biological cues through scale-aware and channel-weighted pathways. We further design an Efficient Path Aggregation FPN (EPA-FPN) as a detail-filling mechanism: it restores high-frequency spatial information typically attenuated in deep layers by establishing long-range skip connections and pruning redundant fusion routes, enabling robust detection of non-rigid fish targets under severe blur and turbidity. Extensive experiments on DeepFish, AquaFishSet, and our challenging UW-BlurredFish benchmark demonstrate that FinSight-Net achieves state-of-the-art performance. In particular, on UW-BlurredFish, FinSight-Net reaches 92.8% mAP, outperforming YOLOv11s by 4.8% while reducing parameters by 29.0%, providing a strong and lightweight solution for real-time automated monitoring in smart aquaculture.",
      "authors": [
        "Jinsong Yang",
        "Zeyuan Hu",
        "Yichen Li",
        "Hong Yu"
      ],
      "url": "https://arxiv.org/abs/2602.19437",
      "published": "2026-02-23T02:12:47+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19419",
      "title": "RAmmStein: Regime Adaptation in Mean-reverting Markets with Stein Thresholds -- Optimal Impulse Control in Concentrated AMMs",
      "abstract": "Concentrated liquidity provision in decentralized exchanges presents a fundamental Impulse Control problem. Liquidity Providers (LPs) face a non-trivial trade-off between maximizing fee accrual through tight price-range concentration and minimizing the friction costs of rebalancing, including gas fees and swap slippage. Existing methods typically employ heuristic or threshold strategies that fail to account for market dynamics. This paper formulates liquidity management as an optimal control problem and derives the corresponding Hamilton-Jacobi-Bellman quasi-variational inequality (HJB-QVI). We present an approximate solution RAmmStein, a Deep Reinforcement Learning method that incorporates the mean-reversion speed (theta) of an Ornstein-Uhlenbeck process among other features as input to the model. We demonstrate that the agent learns to separate the state space into regions of action and inaction. We evaluate the framework using high-frequency 1Hz Coinbase trade data comprising over 6.8M trades. Experimental results show that RAmmStein achieves a superior net ROI of 0.72% compared to both passive and aggressive strategies. Notably, the agent reduces rebalancing frequency by 67% compared to a greedy rebalancing strategy while maintaining 88% active time. Our results demonstrate that regime-aware laziness can significantly improve capital efficiency by preserving the returns that would otherwise be eroded by the operational costs.",
      "authors": [
        "Pranay Anchuri"
      ],
      "url": "https://arxiv.org/abs/2602.19419",
      "published": "2026-02-23T01:25:16+00:00",
      "categories": [
        "cs.LG",
        "q-fin.TR"
      ]
    },
    {
      "id": "2602.19416",
      "title": "IR$^3$: Contrastive Inverse Reinforcement Learning for Interpretable Detection and Mitigation of Reward Hacking",
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) enables powerful LLM alignment but can introduce reward hacking - models exploit spurious correlations in proxy rewards without genuine alignment. Compounding this, the objectives internalized during RLHF remain opaque, making hacking behaviors difficult to detect or correct. We introduce IR3 (Interpretable Reward Reconstruction and Rectification), a framework that reverse-engineers, interprets, and surgically repairs the implicit objectives driving RLHF-tuned models. We propose Contrastive Inverse Reinforcement Learning (C-IRL), which reconstructs the implicit reward function by contrasting paired responses from post-alignment and baseline policies to explain behavioral shifts during RLHF. We then decompose the reconstructed reward via sparse autoencoders into interpretable features, enabling identification of hacking signatures through contribution analysis. Finally, we propose mitigation strategies - clean reward optimization, adversarial shaping, constrained optimization, and feature-guided distillation - that target problematic features while preserving beneficial alignment. Experiments across multiple reward model configurations show that IR3 achieves 0.89 correlation with ground-truth rewards, identifies hacking features with over 90% precision, and significantly reduces hacking behaviors while maintaining capabilities within 3% of the original model.",
      "authors": [
        "Mohammad Beigi",
        "Ming Jin",
        "Junshan Zhang",
        "Jiaxin Zhang",
        "Qifan Wang",
        "Lifu Huang"
      ],
      "url": "https://arxiv.org/abs/2602.19416",
      "published": "2026-02-23T01:14:53+00:00",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19414",
      "title": "Federated Causal Representation Learning in State-Space Systems for Decentralized Counterfactual Reasoning",
      "abstract": "Networks of interdependent industrial assets (clients) are tightly coupled through physical processes and control inputs, raising a key question: how would the output of one client change if another client were operated differently? This is difficult to answer because client-specific data are high-dimensional and private, making centralization of raw data infeasible. Each client also maintains proprietary local models that cannot be modified. We propose a federated framework for causal representation learning in state-space systems that captures interdependencies among clients under these constraints. Each client maps high-dimensional observations into low-dimensional latent states that disentangle intrinsic dynamics from control-driven influences. A central server estimates the global state-transition and control structure. This enables decentralized counterfactual reasoning where clients predict how outputs would change under alternative control inputs at others while only exchanging compact latent states. We prove convergence to a centralized oracle and provide privacy guarantees. Our experiments demonstrate scalability, and accurate cross-client counterfactual inference on synthetic and real-world industrial control system datasets.",
      "authors": [
        "Nazal Mohamed",
        "Ayush Mohanty",
        "Nagi Gebraeel"
      ],
      "url": "https://arxiv.org/abs/2602.19414",
      "published": "2026-02-23T01:12:21+00:00",
      "categories": [
        "cs.LG",
        "eess.SY",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19412",
      "title": "Redefining the Down-Sampling Scheme of U-Net for Precision Biomedical Image Segmentation",
      "abstract": "U-Net architectures have been instrumental in advancing biomedical image segmentation (BIS) but often struggle with capturing long-range information. One reason is the conventional down-sampling techniques that prioritize computational efficiency at the expense of information retention. This paper introduces a simple but effective strategy, we call it Stair Pooling, which moderates the pace of down-sampling and reduces information loss by leveraging a sequence of concatenated small and narrow pooling operations in varied orientations. Specifically, our method modifies the reduction in dimensionality within each 2D pooling step from $\\frac{1}{4}$ to $\\frac{1}{2}$. This approach can also be adapted for 3D pooling to preserve even more information. Such preservation aids the U-Net in more effectively reconstructing spatial details during the up-sampling phase, thereby enhancing its ability to capture long-range information and improving segmentation accuracy. Extensive experiments on three BIS benchmarks demonstrate that the proposed Stair Pooling can increase both 2D and 3D U-Net performance by an average of 3.8\\% in Dice scores. Moreover, we leverage the transfer entropy to select the optimal down-sampling paths and quantitatively show how the proposed Stair Pooling reduces the information loss.",
      "authors": [
        "Mingjie Li",
        "Yizheng Chen",
        "Md Tauhidul Islam",
        "Lei Xing"
      ],
      "url": "https://arxiv.org/abs/2602.19412",
      "published": "2026-02-23T01:10:04+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19411",
      "title": "MACE-POLAR-1: A Polarisable Electrostatic Foundation Model for Molecular Chemistry",
      "abstract": "Accurate modelling of electrostatic interactions and charge transfer is fundamental to computational chemistry, yet most machine learning interatomic potentials (MLIPs) rely on local atomic descriptors that cannot capture long-range electrostatic effects. We present a new electrostatic foundation model for molecular chemistry that extends the MACE architecture with explicit treatment of long-range interactions and electrostatic induction. Our approach combines local many-body geometric features with a non-self-consistent field formalism that updates learnable charge and spin densities through polarisable iterations to model induction, followed by global charge equilibration via learnable Fukui functions to control total charge and total spin. This design enables an accurate and physical description of systems with varying charge and spin states while maintaining computational efficiency. Trained on the OMol25 dataset of 100 million hybrid DFT calculations, our models achieve chemical accuracy across diverse benchmarks, with accuracy competitive with hybrid DFT on thermochemistry, reaction barriers, conformational energies, and transition metal complexes. Notably, we demonstrate that the inclusion of long-range electrostatics leads to a large improvement in the description of non-covalent interactions and supramolecular complexes over non-electrostatic models, including sub-kcal/mol prediction of molecular crystal formation energy in the X23-DMC dataset and a fourfold improvement over short-ranged models on protein-ligand interactions. The model's ability to handle variable charge and spin states, respond to external fields, provide interpretable spin-resolved charge densities, and maintain accuracy from small molecules to protein-ligand complexes positions it as a versatile tool for computational molecular chemistry and drug discovery.",
      "authors": [
        "Ilyes Batatia",
        "William J. Baldwin",
        "Domantas Kuryla",
        "Joseph Hart",
        "Elliott Kasoar",
        "Alin M. Elena",
        "Harry Moore",
        "Mikołaj J. Gawkowski",
        "Benjamin X. Shi",
        "Venkat Kapil",
        "Panagiotis Kourtis",
        "Ioan-Bogdan Magdău",
        "Gábor Csányi"
      ],
      "url": "https://arxiv.org/abs/2602.19411",
      "published": "2026-02-23T01:09:54+00:00",
      "categories": [
        "physics.chem-ph",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19410",
      "title": "BioEnvSense: A Human-Centred Security Framework for Preventing Behaviour-Driven Cyber Incidents",
      "abstract": "Modern organizations increasingly face cybersecurity incidents driven by human behaviour rather than technical failures. To address this, we propose a conceptual security framework that integrates a hybrid Convolutional Neural Network-Long Short-Term Memory (CNN-LSTM) model to analyze biometric and environmental data for context-aware security decisions. The CNN extracts spatial patterns from sensor data, while the LSTM captures temporal dynamics associated with human error susceptibility. The model achieves 84% accuracy, demonstrating its ability to reliably detect conditions that lead to elevated human-centred cyber risk. By enabling continuous monitoring and adaptive safeguards, the framework supports proactive interventions that reduce the likelihood of human-driven cyber incidents",
      "authors": [
        "Duy Anh Ta",
        "Farnaz Farid",
        "Farhad Ahamed",
        "Ala Al-Areqi",
        "Robert Beutel",
        "Tamara Watson",
        "Alana Maurushat"
      ],
      "url": "https://arxiv.org/abs/2602.19410",
      "published": "2026-02-23T01:06:16+00:00",
      "categories": [
        "cs.CR",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19406",
      "title": "LEVDA: Latent Ensemble Variational Data Assimilation via Differentiable Dynamics",
      "abstract": "Long-range geophysical forecasts are fundamentally limited by chaotic dynamics and numerical errors. While data assimilation can mitigate these issues, classical variational smoothers require computationally expensive tangent-linear and adjoint models. Conversely, recent efficient latent filtering methods often enforce weak trajectory-level constraints and assume fixed observation grids. To bridge this gap, we propose Latent Ensemble Variational Data Assimilation (LEVDA), an ensemble-space variational smoother that operates in the low-dimensional latent space of a pretrained differentiable neural dynamics surrogate. By performing four-dimensional ensemble-variational (4DEnVar) optimization within an ensemble subspace, LEVDA jointly assimilates states and unknown parameters without the need for adjoint code or auxiliary observation-to-latent encoders. Leveraging the fully differentiable, continuous-in-time-and-space nature of the surrogate, LEVDA naturally accommodates highly irregular sampling at arbitrary spatiotemporal locations. Across three challenging geophysical benchmarks, LEVDA matches or outperforms state-of-the-art latent filtering baselines under severe observational sparsity while providing more reliable uncertainty quantification. Simultaneously, it achieves substantially improved assimilation accuracy and computational efficiency compared to full-state 4DEnVar.",
      "authors": [
        "Phillip Si",
        "Peng Chen"
      ],
      "url": "https://arxiv.org/abs/2602.19406",
      "published": "2026-02-23T00:54:59+00:00",
      "categories": [
        "cs.LG",
        "math.OC"
      ]
    },
    {
      "id": "2602.20208",
      "title": "Model Merging in the Essential Subspace",
      "abstract": "Model merging aims to integrate multiple task-specific fine-tuned models derived from a shared pre-trained checkpoint into a single multi-task model without additional training. Despite extensive research, task interference remains a major obstacle that often undermines the performance of merged models. In this paper, we propose ESM (Essential Subspace Merging) , a robust framework for effective model merging. We begin by performing Principal Component Analysis (PCA) on feature shifts induced by parameter updates. The resulting principal directions span an essential subspace that dominantly influences feature representations. Each task's parameter update matrix is projected onto its respective essential subspace for low-rank decomposition before merging. This methodology mitigates inter-task interference while preserving core task-specific functionality. Furthermore, we introduce a multi-level polarized scaling strategy that amplifies parameters containing critical knowledge and suppresses redundant ones, preventing essential knowledge from being overwhelmed during fusion. Extensive experiments across multiple task sets and model scales demonstrate that our method achieves state-of-the-art performance in multi-task model merging.",
      "authors": [
        "Longhua Li",
        "Lei Qi",
        "Qi Tian",
        "Xin Geng"
      ],
      "url": "https://arxiv.org/abs/2602.20208",
      "published": "2026-02-23T00:33:38+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19403",
      "title": "Personalized Prediction of Perceived Message Effectiveness Using Large Language Model Based Digital Twins",
      "abstract": "Perceived message effectiveness (PME) by potential intervention end-users is important for selecting and optimizing personalized smoking cessation intervention messages for mobile health (mHealth) platform delivery. This study evaluates whether large language models (LLMs) can accurately predict PME for smoking cessation messages.   We evaluated multiple models for predicting PME across three domains: content quality, coping support, and quitting support. The dataset comprised 3010 message ratings (5-point Likert scale) from 301 young adult smokers. We compared (1) supervised learning models trained on labeled data, (2) zero and few-shot LLMs prompted without task-specific fine-tuning, and (3) LLM-based digital twins that incorporate individual characteristics and prior PME histories to generate personalized predictions. Model performance was assessed on three held-out messages per participant using accuracy, Cohen's kappa, and F1.   LLM-based digital twins outperformed zero and few-shot LLMs (12 percentage points on average) and supervised baselines (13 percentage points), achieving accuracies of 0.49 (content), 0.45 (coping), and 0.49 (quitting), with directional accuracies of 0.75, 0.66, and 0.70 on a simplified 3-point scale. Digital twin predictions showed greater dispersion across rating categories, indicating improved sensitivity to individual differences.   Integrating personal profiles with LLMs captures person-specific differences in PME and outperforms supervised and zero and few-shot approaches. Improved PME prediction may enable more tailored intervention content in mHealth. LLM-based digital twins show potential for supporting personalization of mobile smoking cessation and other health behavior change interventions.",
      "authors": [
        "Jasmin Han",
        "Janardan Devkota",
        "Joseph Waring",
        "Amanda Luken",
        "Felix Naughton",
        "Roger Vilardaga",
        "Jonathan Bricker",
        "Carl Latkin",
        "Meghan Moran",
        "Yiqun Chen",
        "Johannes Thrul"
      ],
      "url": "https://arxiv.org/abs/2602.19403",
      "published": "2026-02-23T00:32:23+00:00",
      "categories": [
        "cs.CL",
        "stat.AP"
      ]
    },
    {
      "id": "2602.19400",
      "title": "Hilbert-Augmented Reinforcement Learning for Scalable Multi-Robot Coverage and Exploration",
      "abstract": "We present a coverage framework that integrates Hilbert space-filling priors into decentralized multi-robot learning and execution. We augment DQN and PPO with Hilbert-based spatial indices to structure exploration and reduce redundancy in sparse-reward environments, and we evaluate scalability in multi-robot grid coverage. We further describe a waypoint interface that converts Hilbert orderings into curvature-bounded, time-parameterized SE(2) trajectories (planar (x, y, θ)), enabling onboard feasibility on resource-constrained robots. Experiments show improvements in coverage efficiency, redundancy, and convergence speed over DQN/PPO baselines. In addition, we validate the approach on a Boston Dynamics Spot legged robot, executing the generated trajectories in indoor environments and observing reliable coverage with low redundancy. These results indicate that geometric priors improve autonomy and scalability for swarm and legged robotics.",
      "authors": [
        "Tamil Selvan Gurunathan",
        "Aryya Gangopadhyay"
      ],
      "url": "https://arxiv.org/abs/2602.19400",
      "published": "2026-02-23T00:19:19+00:00",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "id": "2602.19396",
      "title": "Hiding in Plain Text: Detecting Concealed Jailbreaks via Activation Disentanglement",
      "abstract": "Large language models (LLMs) remain vulnerable to jailbreak prompts that are fluent and semantically coherent, and therefore difficult to detect with standard heuristics. A particularly challenging failure mode occurs when an attacker tries to hide the malicious goal of their request by manipulating its framing to induce compliance. Because these attacks maintain malicious intent through a flexible presentation, defenses that rely on structural artifacts or goal-specific signatures can fail. Motivated by this, we introduce a self-supervised framework for disentangling semantic factor pairs in LLM activations at inference. We instantiate the framework for goal and framing and construct GoalFrameBench, a corpus of prompts with controlled goal and framing variations, which we use to train Representation Disentanglement on Activations (ReDAct) module to extract disentangled representations in a frozen LLM. We then propose FrameShield, an anomaly detector operating on the framing representations, which improves model-agnostic detection across multiple LLM families with minimal computational overhead. Theoretical guarantees for ReDAct and extensive empirical validations show that its disentanglement effectively powers FrameShield. Finally, we use disentanglement as an interpretability probe, revealing distinct profiles for goal and framing signals and positioning semantic disentanglement as a building block for both LLM safety and mechanistic interpretability.",
      "authors": [
        "Amirhossein Farzam",
        "Majid Behabahani",
        "Mani Malek",
        "Yuriy Nevmyvaka",
        "Guillermo Sapiro"
      ],
      "url": "https://arxiv.org/abs/2602.19396",
      "published": "2026-02-23T00:11:30+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.19393",
      "title": "In Defense of Cosine Similarity: Normalization Eliminates the Gauge Freedom",
      "abstract": "Steck, Ekanadham, and Kallus [arXiv:2403.05440] demonstrate that cosine similarity of learned embeddings from matrix factorization models can be rendered arbitrary by a diagonal ``gauge'' matrix $D$. Their result is correct and important for practitioners who compute cosine similarity on embeddings trained with dot-product objectives. However, we argue that their conclusion, cautioning against cosine similarity in general, conflates the pathology of an incompatible training objective with the geometric validity of cosine distance on the unit sphere. We prove that when embeddings are constrained to the unit sphere $\\mathbb{S}^{d-1}$ (either during or after training with an appropriate objective), the $D$-matrix ambiguity vanishes identically, and cosine distance reduces to exactly half the squared Euclidean distance. This monotonic equivalence implies that cosine-based and Euclidean-based neighbor rankings are identical on normalized embeddings. The ``problem'' with cosine similarity is not cosine similarity, it is the failure to normalize.",
      "authors": [
        "Taha Bouhsine"
      ],
      "url": "https://arxiv.org/abs/2602.19393",
      "published": "2026-02-23T00:00:57+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19392",
      "title": "Spiking Graph Predictive Coding for Reliable OOD Generalization",
      "abstract": "Graphs provide a powerful basis for modeling Web-based relational data, with expressive GNNs to support the effective learning in dynamic web environments. However, real-world deployment is hindered by pervasive out-of-distribution (OOD) shifts, where evolving user activity and changing content semantics alter feature distributions and labeling criteria. These shifts often lead to unstable or overconfident predictions, undermining the trustworthiness required for Web4Good applications. Achieving reliable OOD generalization demands principled and interpretable uncertainty estimation; however, existing methods are largely post-hoc, insensitive to distribution shifts, and unable to explain where uncertainty arises especially in high-stakes settings. To address these limitations, we introduce SpIking GrapH predicTive coding (SIGHT), an uncertainty-aware plug-in graph learning module for reliable OOD Generalization. SIGHT performs iterative, error-driven correction over spiking graph states, enabling models to expose internal mismatch signals that reveal where predictions become unreliable. Across multiple graph benchmarks and diverse OOD scenarios, SIGHT consistently enhances predictive accuracy, uncertainty estimation, and interpretability when integrated with GNNs.",
      "authors": [
        "Jing Ren",
        "Jiapeng Du",
        "Bowen Li",
        "Ziqi Xu",
        "Xin Zheng",
        "Hong Jia",
        "Suyu Ma",
        "Xiwei Xu",
        "Feng Xia"
      ],
      "url": "https://arxiv.org/abs/2602.19392",
      "published": "2026-02-22T23:58:47+00:00",
      "categories": [
        "cs.LG",
        "cs.SI"
      ]
    },
    {
      "id": "2602.21381",
      "title": "VCDF: A Validated Consensus-Driven Framework for Time Series Causal Discovery",
      "abstract": "Time series causal discovery is essential for understanding dynamic systems, yet many existing methods remain sensitive to noise, non-stationarity, and sampling variability. We propose the Validated Consensus-Driven Framework (VCDF), a simple and method-agnostic layer that improves robustness by evaluating the stability of causal relations across blocked temporal subsets. VCDF requires no modification to base algorithms and can be applied to methods such as VAR-LiNGAM and PCMCI. Experiments on synthetic datasets show that VCDF improves VAR-LiNGAM by approximately 0.08-0.12 in both window and summary F1 scores across diverse data characteristics, with gains most pronounced for moderate-to-long sequences. The framework also benefits from longer sequences, yielding up to 0.18 absolute improvement on time series of length 1000 and above. Evaluations on simulated fMRI data and IT-monitoring scenarios further demonstrate enhanced stability and structural accuracy under realistic noise conditions. VCDF provides an effective reliability layer for time series causal discovery without altering underlying modeling assumptions.",
      "authors": [
        "Gene Yu",
        "Ce Guo",
        "Wayne Luk"
      ],
      "url": "https://arxiv.org/abs/2602.21381",
      "published": "2026-02-22T23:50:53+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ]
    },
    {
      "id": "2602.19390",
      "title": "Artificial Intelligence for Modeling & Simulation in Digital Twins",
      "abstract": "The convergence of modeling & simulation (M&S) and artificial intelligence (AI) is leaving its marks on advanced digital technology. Pertinent examples are digital twins (DTs) - high-fidelity, live representations of physical assets, and frequent enablers of corporate digital maturation and transformation. Often seen as technological platforms that integrate an array of services, DTs have the potential to bring AI-enabled M&S closer to end-users. It is, therefore, paramount to understand the role of M&S in DTs, and the role of digital twins in enabling the convergence of AI and M&S. To this end, this chapter provides a comprehensive exploration of the complementary relationship between these three. We begin by establishing a foundational understanding of DTs by detailing their key components, architectural layers, and their various roles across business, development, and operations. We then examine the central role of M&S in DTs and provide an overview of key modeling techniques from physics-based and discrete-event simulation to hybrid approaches. Subsequently, we investigate the bidirectional role of AI: first, how AI enhances DTs through advanced analytics, predictive capabilities, and autonomous decision-making, and second, how DTs serve as valuable platforms for training, validating, and deploying AI models. The chapter concludes by identifying key challenges and future research directions for creating more integrated and intelligent systems.",
      "authors": [
        "Philipp Zech",
        "Istvan David"
      ],
      "url": "https://arxiv.org/abs/2602.19390",
      "published": "2026-02-22T23:47:43+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.19385",
      "title": "Adaptive Data Augmentation with Multi-armed Bandit: Sample-Efficient Embedding Calibration for Implicit Pattern Recognition",
      "abstract": "Recognizing implicit visual and textual patterns is essential in many real-world applications of modern AI. However, tackling long-tail pattern recognition tasks remains challenging for current pre-trained foundation models such as LLMs and VLMs. While finetuning pre-trained models can improve accuracy in recognizing implicit patterns, it is usually infeasible due to a lack of training data and high computational overhead. In this paper, we propose ADAMAB, an efficient embedding calibration framework for few-shot pattern recognition. To maximally reduce the computational costs, ADAMAB trains embedder-agnostic light-weight calibrators on top of fixed embedding models without accessing their parameters. To mitigate the need for large-scale training data, we introduce an adaptive data augmentation strategy based on the Multi-Armed Bandit (MAB) mechanism. With a modified upper confidence bound algorithm, ADAMAB diminishes the gradient shifting and offers theoretically guaranteed convergence in few-shot training. Our multi-modal experiments justify the superior performance of ADAMAB, with up to 40% accuracy improvement when training with less than 5 initial data samples of each class.",
      "authors": [
        "Minxue Tang",
        "Yangyang Yu",
        "Aolin Ding",
        "Maziyar Baran Pouyan",
        "Taha Belkhouja Yujia Bao"
      ],
      "url": "https://arxiv.org/abs/2602.19385",
      "published": "2026-02-22T23:39:21+00:00",
      "categories": [
        "cs.CV",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19381",
      "title": "Regularity of Second-Order Elliptic PDEs in Spectral Barron Spaces",
      "abstract": "We establish a regularity theorem for second-order elliptic PDEs on $\\mathbb{R}^{d}$ in spectral Barron spaces. Under mild ellipticity and smallness assumptions, the solution gains two additional orders of Barron regularity. As a corollary, we identify a class of PDEs whose solutions can be approximated by two-layer neural networks with cosine activation functions, where the width of the neural network is independent of the spatial dimension.",
      "authors": [
        "Ziang Chen",
        "Liqiang Huang",
        "Mengxuan Yang",
        "Shengxuan Zhou"
      ],
      "url": "https://arxiv.org/abs/2602.19381",
      "published": "2026-02-22T23:29:57+00:00",
      "categories": [
        "math.AP",
        "cs.LG",
        "math.NA"
      ]
    },
    {
      "id": "2602.19373",
      "title": "Stable Deep Reinforcement Learning via Isotropic Gaussian Representations",
      "abstract": "Deep reinforcement learning systems often suffer from unstable training dynamics due to non-stationarity, where learning objectives and data distributions evolve over time. We show that under non-stationary targets, isotropic Gaussian embeddings are provably advantageous. In particular, they induce stable tracking of time-varying targets for linear readouts, achieve maximal entropy under a fixed variance budget, and encourage a balanced use of all representational dimensions--all of which enable agents to be more adaptive and stable. Building on this insight, we propose the use of Sketched Isotropic Gaussian Regularization for shaping representations toward an isotropic Gaussian distribution during training. We demonstrate empirically, over a variety of domains, that this simple and computationally inexpensive method improves performance under non-stationarity while reducing representation collapse, neuron dormancy, and training instability.",
      "authors": [
        "Ali Saheb",
        "Johan Obando-Ceron",
        "Aaron Courville",
        "Pouya Bashivan",
        "Pablo Samuel Castro"
      ],
      "url": "https://arxiv.org/abs/2602.19373",
      "published": "2026-02-22T22:55:27+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.20207",
      "title": "Golden Layers and Where to Find Them: Improved Knowledge Editing for Large Language Models Via Layer Gradient Analysis",
      "abstract": "Knowledge editing in Large Language Models (LLMs) aims to update the model's prediction for a specific query to a desired target while preserving its behavior on all other inputs. This process typically involves two stages: identifying the layer to edit and performing the parameter update. Intuitively, different queries may localize knowledge at different depths of the model, resulting in different sample-wise editing performance for a fixed editing layer. In this work, we hypothesize the existence of fixed golden layers that can achieve near-optimal editing performance similar to sample-wise optimal layers. To validate this hypothesis, we provide empirical evidence by comparing golden layers against ground-truth sample-wise optimal layers. Furthermore, we show that golden layers can be reliably identified using a proxy dataset and generalize effectively to unseen test set queries across datasets. Finally, we propose a novel method, namely Layer Gradient Analysis (LGA) that estimates golden layers efficiently via gradient-attribution, avoiding extensive trial-and-error across multiple editing runs. Extensive experiments on several benchmark datasets demonstrate the effectiveness and robustness of our LGA approach across different LLM types and various knowledge editing methods.",
      "authors": [
        "Shrestha Datta",
        "Hongfu Liu",
        "Anshuman Chhabra"
      ],
      "url": "https://arxiv.org/abs/2602.20207",
      "published": "2026-02-22T22:55:11+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19372",
      "title": "Seeing Farther and Smarter: Value-Guided Multi-Path Reflection for VLM Policy Optimization",
      "abstract": "Solving complex, long-horizon robotic manipulation tasks requires a deep understanding of physical interactions, reasoning about their long-term consequences, and precise high-level planning. Vision-Language Models (VLMs) offer a general perceive-reason-act framework for this goal. However, previous approaches using reflective planning to guide VLMs in correcting actions encounter significant limitations. These methods rely on inefficient and often inaccurate implicit learning of state-values from noisy foresight predictions, evaluate only a single greedy future, and suffer from substantial inference latency. To address these limitations, we propose a novel test-time computation framework that decouples state evaluation from action generation. This provides a more direct and fine-grained supervisory signal for robust decision-making. Our method explicitly models the advantage of an action plan, quantified by its reduction in distance to the goal, and uses a scalable critic to estimate. To address the stochastic nature of single-trajectory evaluation, we employ beam search to explore multiple future paths and aggregate them during decoding to model their expected long-term returns, leading to more robust action generation. Additionally, we introduce a lightweight, confidence-based trigger that allows for early exit when direct predictions are reliable, invoking reflection only when necessary. Extensive experiments on diverse, unseen multi-stage robotic manipulation tasks demonstrate a 24.6% improvement in success rate over state-of-the-art baselines, while significantly reducing inference time by 56.5%.",
      "authors": [
        "Yanting Yang",
        "Shenyuan Gao",
        "Qingwen Bu",
        "Li Chen",
        "Dimitris N. Metaxas"
      ],
      "url": "https://arxiv.org/abs/2602.19372",
      "published": "2026-02-22T22:53:16+00:00",
      "categories": [
        "cs.RO",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19367",
      "title": "Time Series, Vision, and Language: Exploring the Limits of Alignment in Contrastive Representation Spaces",
      "abstract": "The Platonic Representation Hypothesis posits that learned representations from models trained on different modalities converge to a shared latent structure of the world. However, this hypothesis has largely been examined in vision and language, and it remains unclear whether time series participate in such convergence. We first examine this in a trimodal setting and find that independently pretrained time series, vision, and language encoders exhibit near-orthogonal geometry in the absence of explicit coupling. We then apply post-hoc alignment by training projection heads over frozen encoders using contrastive learning, and analyze the resulting representations with respect to geometry, scaling behavior, and dependence on information density and input modality characteristics. Our investigation reveals that overall alignment in contrastive representation spaces improves with model size, but this alignment is asymmetric: time series align more strongly with visual representations than with text, and images can act as effective intermediaries between time series and language. We further see that richer textual descriptions improve alignment only up to a threshold; training on denser captions does not lead to further improvement. Analogous effects are observed for visual representations. Our findings shed light on considerations for building multimodal systems involving non-conventional data modalities beyond vision and language.",
      "authors": [
        "Pratham Yashwante",
        "Rose Yu"
      ],
      "url": "https://arxiv.org/abs/2602.19367",
      "published": "2026-02-22T22:39:37+00:00",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "id": "2602.19362",
      "title": "LLMs Can Learn to Reason Via Off-Policy RL",
      "abstract": "Reinforcement learning (RL) approaches for Large Language Models (LLMs) frequently use on-policy algorithms, such as PPO or GRPO. However, policy lag from distributed training architectures and differences between the training and inference policies break this assumption, making the data off-policy by design. To rectify this, prior work has focused on making this off-policy data appear more on-policy, either via importance sampling (IS), or by more closely aligning the training and inference policies by explicitly modifying the inference engine. In this work, we embrace off-policyness and propose a novel off-policy RL algorithm that does not require these modifications: Optimal Advantage-based Policy Optimization with Lagged Inference policy (OAPL). We show that OAPL outperforms GRPO with importance sampling on competition math benchmarks, and can match the performance of a publicly available coding model, DeepCoder, on LiveCodeBench, while using 3x fewer generations during training. We further empirically demonstrate that models trained via OAPL have improved test time scaling under the Pass@k metric. OAPL allows for efficient, effective post-training even with lags of more than 400 gradient steps between the training and inference policies, 100x more off-policy than prior approaches.",
      "authors": [
        "Daniel Ritter",
        "Owen Oertell",
        "Bradley Guo",
        "Jonathan Chang",
        "Kianté Brantley",
        "Wen Sun"
      ],
      "url": "https://arxiv.org/abs/2602.19362",
      "published": "2026-02-22T22:12:51+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19359",
      "title": "Vid2Sid: Videos Can Help Close the Sim2Real Gap",
      "abstract": "Calibrating a robot simulator's physics parameters (friction, damping, material stiffness) to match real hardware is often done by hand or with black-box optimizers that reduce error but cannot explain which physical discrepancies drive the error. When sensing is limited to external cameras, the problem is further compounded by perception noise and the absence of direct force or state measurements. We present Vid2Sid, a video-driven system identification pipeline that couples foundation-model perception with a VLM-in-the-loop optimizer that analyzes paired sim-real videos, diagnoses concrete mismatches, and proposes physics parameter updates with natural language rationales. We evaluate our approach on a tendon-actuated finger (rigid-body dynamics in MuJoCo) and a deformable continuum tentacle (soft-body dynamics in PyElastica). On sim2real holdout controls unseen during training, Vid2Sid achieves the best average rank across all settings, matching or exceeding black-box optimizers while uniquely providing interpretable reasoning at each iteration. Sim2sim validation confirms that Vid2Sid recovers ground-truth parameters most accurately (mean relative error under 13\\% vs. 28--98\\%), and ablation analysis reveals three calibration regimes. VLM-guided optimization excels when perception is clean and the simulator is expressive, while model-class limitations bound performance in more challenging settings.",
      "authors": [
        "Kevin Qiu",
        "Yu Zhang",
        "Marek Cygan",
        "Josie Hughes"
      ],
      "url": "https://arxiv.org/abs/2602.19359",
      "published": "2026-02-22T22:08:16+00:00",
      "categories": [
        "cs.RO",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19357",
      "title": "MentalBlackboard: Evaluating Spatial Visualization via Mathematical Transformations",
      "abstract": "Spatial visualization is the mental ability to imagine, transform, and manipulate the spatial characteristics of objects and actions. This intelligence is a part of human cognition where actions and perception are connected on a mental level. To explore whether state-of-the-art Vision-Language Models (VLMs) exhibit this ability, we develop MentalBlackboard, an open-ended spatial visualization benchmark for Paper Folding and Hole Punching tests within two core tasks: prediction and planning. Our prediction experiments reveal that models struggle with applying symmetrical transformations, even when they predict the sequence of unfolding steps correctly. Also, rotations introduce a significant challenge to the physical situational awareness for models. The planning task reveals limitations of models in analyzing symmetrical relationships and in implementing the multi-stage symmetry process, with Claude Opus 4.1 achieving the highest planning score at an accuracy of 10\\%. The top-performing model, o3, attains a peak performance of 71.6\\% on the generalization task, which does not require spatial visualization but transfers spatial data; however, it achieves only 25\\% accuracy on text-based prediction tasks.",
      "authors": [
        "Nilay Yilmaz",
        "Maitreya Patel",
        "Naga Sai Abhiram Kusumba",
        "Yixuan He",
        "Yezhou Yang"
      ],
      "url": "https://arxiv.org/abs/2602.19357",
      "published": "2026-02-22T22:05:11+00:00",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19355",
      "title": "Active perception and disentangled representations allow continual, episodic zero and few-shot learning",
      "abstract": "Generalization is often regarded as an essential property of machine learning systems. However, perhaps not every component of a system needs to generalize. Training models for generalization typically produces entangled representations at the boundaries of entities or classes, which can lead to destructive interference when rapid, high-magnitude updates are required for continual or few-shot learning. Techniques for fast learning with non-interfering representations exist, but they generally fail to generalize. Here, we describe a Complementary Learning System (CLS) in which the fast learner entirely foregoes generalization in exchange for continual zero-shot and few-shot learning. Unlike most CLS approaches, which use episodic memory primarily for replay and consolidation, our fast, disentangled learner operates as a parallel reasoning system. The fast learner can overcome observation variability and uncertainty by leveraging a conventional slow, statistical learner within an active perception system: A contextual bias provided by the fast learner induces the slow learner to encode novel stimuli in familiar, generalized terms, enabling zero-shot and few-shot learning. This architecture demonstrates that fast, context-driven reasoning can coexist with slow, structured generalization, providing a pathway for robust continual learning.",
      "authors": [
        "David Rawlinson",
        "Gideon Kowadlo"
      ],
      "url": "https://arxiv.org/abs/2602.19355",
      "published": "2026-02-22T22:05:02+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19349",
      "title": "UP-Fuse: Uncertainty-guided LiDAR-Camera Fusion for 3D Panoptic Segmentation",
      "abstract": "LiDAR-camera fusion enhances 3D panoptic segmentation by leveraging camera images to complement sparse LiDAR scans, but it also introduces a critical failure mode. Under adverse conditions, degradation or failure of the camera sensor can significantly compromise the reliability of the perception system. To address this problem, we introduce UP-Fuse, a novel uncertainty-aware fusion framework in the 2D range-view that remains robust under camera sensor degradation, calibration drift, and sensor failure. Raw LiDAR data is first projected into the range-view and encoded by a LiDAR encoder, while camera features are simultaneously extracted and projected into the same shared space. At its core, UP-Fuse employs an uncertainty-guided fusion module that dynamically modulates cross-modal interaction using predicted uncertainty maps. These maps are learned by quantifying representational divergence under diverse visual degradations, ensuring that only reliable visual cues influence the fused representation. The fused range-view features are decoded by a novel hybrid 2D-3D transformer that mitigates spatial ambiguities inherent to the 2D projection and directly predicts 3D panoptic segmentation masks. Extensive experiments on Panoptic nuScenes, SemanticKITTI, and our introduced Panoptic Waymo benchmark demonstrate the efficacy and robustness of UP-Fuse, which maintains strong performance even under severe visual corruption or misalignment, making it well suited for robotic perception in safety-critical settings.",
      "authors": [
        "Rohit Mohan",
        "Florian Drews",
        "Yakov Miron",
        "Daniele Cattaneo",
        "Abhinav Valada"
      ],
      "url": "https://arxiv.org/abs/2602.19349",
      "published": "2026-02-22T21:34:29+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19348",
      "title": "MultiDiffSense: Diffusion-Based Multi-Modal Visuo-Tactile Image Generation Conditioned on Object Shape and Contact Pose",
      "abstract": "Acquiring aligned visuo-tactile datasets is slow and costly, requiring specialised hardware and large-scale data collection. Synthetic generation is promising, but prior methods are typically single-modality, limiting cross-modal learning. We present MultiDiffSense, a unified diffusion model that synthesises images for multiple vision-based tactile sensors (ViTac, TacTip, ViTacTip) within a single architecture. Our approach uses dual conditioning on CAD-derived, pose-aligned depth maps and structured prompts that encode sensor type and 4-DoF contact pose, enabling controllable, physically consistent multi-modal synthesis. Evaluating on 8 objects (5 seen, 3 novel) and unseen poses, MultiDiffSense outperforms a Pix2Pix cGAN baseline in SSIM by +36.3% (ViTac), +134.6% (ViTacTip), and +64.7% (TacTip). For downstream 3-DoF pose estimation, mixing 50% synthetic with 50% real halves the required real data while maintaining competitive performance. MultiDiffSense alleviates the data-collection bottleneck in tactile sensing and enables scalable, controllable multi-modal dataset generation for robotic applications.",
      "authors": [
        "Sirine Bhouri",
        "Lan Wei",
        "Jian-Qing Zheng",
        "Dandan Zhang"
      ],
      "url": "https://arxiv.org/abs/2602.19348",
      "published": "2026-02-22T21:31:24+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.20206",
      "title": "Mitigating \"Epistemic Debt\" in Generative AI-Scaffolded Novice Programming using Metacognitive Scripts",
      "abstract": "The democratization of Large Language Models (LLMs) has given rise to ``Vibe Coding,\" a workflow where novice programmers prioritize semantic intent over syntactic implementation. While this lowers barriers to entry, we hypothesize that without pedagogical guardrails, it is fundamentally misaligned with cognitive skill acquisition. Drawing on the distinction between Cognitive Offloading and Cognitive Outsourcing, we argue that unrestricted AI encourages novices to outsource the Intrinsic Cognitive Load required for schema formation, rather than merely offloading Extraneous Load. This accumulation of ``Epistemic Debt\" creates ``Fragile Experts\" whose high functional utility masks critically low corrective competence.   To quantify and mitigate this debt, we conducted a between-subjects experiment (N=78) using a custom Cursor IDE plugin backed by Claude 3.5 Sonnet. Participants represented \"AI-Native\" learners across three conditions: Manual (Control), Unrestricted AI (Outsourcing), and Scaffolded AI (Offloading). The Scaffolded condition utilized a novel ``Explanation Gate,\" leveraging a real-time LLM-as-a-Judge framework to enforce a ``Teach-Back\" protocol before generated code could be integrated.   Results reveal a ``Collapse of Competence\": while Unrestricted AI users matched the productivity of the Scaffolded group (p < .001 vs. Manual), they suffered a 77% failure rate in a subsequent AI-Blackout maintenance task, compared to only 39% in the Scaffolded group. Qualitative analysis suggests that successful vibe coders naturally engage in self-scaffolding, treating the AI as a consultant rather than a contractor. We discuss the implications for the maintainability of AI-generated software and propose that future learning systems must enforce Metacognitive Friction to prevent the mass production of unmaintainable code.",
      "authors": [
        "Sreecharan Sankaranarayanan"
      ],
      "url": "https://arxiv.org/abs/2602.20206",
      "published": "2026-02-22T21:25:04+00:00",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.MA"
      ]
    },
    {
      "id": "2602.19345",
      "title": "Smooth Gate Functions for Soft Advantage Policy Optimization",
      "abstract": "Group Relative Policy Optimization (GRPO) has significantly advanced the training of large language models and enhanced their reasoning capabilities, while it remains susceptible to instability due to the use of hard clipping. Soft Adaptive Policy Optimization (SAPO) addresses this limitation by replacing clipping with a smooth sigmoid-based gate function, which leads to more stable updates. We have decided to push this theory further and investigate the impact of different gate functions on both training stability and final model performance. We formalize the key properties that admissible gates should satisfy and identify several families of such functions for empirical evaluation. This paper presents an analysis of our findings based on experiments conducted with the Qwen2.5-7B-Instruct model on mathematical reasoning tasks. These results provide practical guidance for designing smoother and more robust policy optimization objectives for large language model training.",
      "authors": [
        "Egor Denisov",
        "Svetlana Glazyrina",
        "Maksim Kryzhanovskiy",
        "Roman Ischenko"
      ],
      "url": "https://arxiv.org/abs/2602.19345",
      "published": "2026-02-22T21:19:26+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19339",
      "title": "SplitLight: An Exploratory Toolkit for Recommender Systems Datasets and Splits",
      "abstract": "Offline evaluation of recommender systems is often affected by hidden, under-documented choices in data preparation. Seemingly minor decisions in filtering, handling repeats, cold-start treatment, and splitting strategy design can substantially reorder model rankings and undermine reproducibility and cross-paper comparability.   In this paper, we introduce SplitLight, an open-source exploratory toolkit that enables researchers and practitioners designing preprocessing and splitting pipelines or reviewing external artifacts to make these decisions measurable, comparable, and reportable. Given an interaction log and derived split subsets, SplitLight analyzes core and temporal dataset statistics, characterizes repeat consumption patterns and timestamp anomalies, and diagnoses split validity, including temporal leakage, cold-user/item exposure, and distribution shifts. SplitLight further allows side-by-side comparison of alternative splitting strategies through comprehensive aggregated summaries and interactive visualizations. Delivered as both a Python toolkit and an interactive no-code interface, SplitLight produces audit summaries that justify evaluation protocols and support transparent, reliable, and comparable experimentation in recommender systems research and industry.",
      "authors": [
        "Anna Volodkevich",
        "Dmitry Anikin",
        "Danil Gusak",
        "Anton Klenitskiy",
        "Evgeny Frolov",
        "Alexey Vasilev"
      ],
      "url": "https://arxiv.org/abs/2602.19339",
      "published": "2026-02-22T21:02:32+00:00",
      "categories": [
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19333",
      "title": "PerSoMed: A Large-Scale Balanced Dataset for Persian Social Media Text Classification",
      "abstract": "This research introduces the first large-scale, well-balanced Persian social media text classification dataset, specifically designed to address the lack of comprehensive resources in this domain. The dataset comprises 36,000 posts across nine categories (Economic, Artistic, Sports, Political, Social, Health, Psychological, Historical, and Science & Technology), each containing 4,000 samples to ensure balanced class distribution. Data collection involved 60,000 raw posts from various Persian social media platforms, followed by rigorous preprocessing and hybrid annotation combining ChatGPT-based few-shot prompting with human verification. To mitigate class imbalance, we employed undersampling with semantic redundancy removal and advanced data augmentation strategies integrating lexical replacement and generative prompting. We benchmarked several models, including BiLSTM, XLM-RoBERTa (with LoRA and AdaLoRA adaptations), FaBERT, SBERT-based architectures, and the Persian-specific TookaBERT (Base and Large). Experimental results show that transformer-based models consistently outperform traditional neural networks, with TookaBERT-Large achieving the best performance (Precision: 0.9622, Recall: 0.9621, F1- score: 0.9621). Class-wise evaluation further confirms robust performance across all categories, though social and political texts exhibited slightly lower scores due to inherent ambiguity. This research presents a new high-quality dataset and provides comprehensive evaluations of cutting-edge models, establishing a solid foundation for further developments in Persian NLP, including trend analysis, social behavior modeling, and user classification. The dataset is publicly available to support future research endeavors.",
      "authors": [
        "Isun Chehreh",
        "Ebrahim Ansari"
      ],
      "url": "https://arxiv.org/abs/2602.19333",
      "published": "2026-02-22T20:53:08+00:00",
      "categories": [
        "cs.CL",
        "cs.IR",
        "cs.SI"
      ]
    },
    {
      "id": "2602.19332",
      "title": "Training-Free Cross-Architecture Merging for Graph Neural Networks",
      "abstract": "Model merging has emerged as a powerful paradigm for combining the capabilities of distinct expert models without the high computational cost of retraining, yet current methods are fundamentally constrained to homogeneous architectures. For GNNs, however, message passing is topology-dependent and sensitive to misalignment, making direct parameter-space merging unreliable. To bridge this gap, we introduce H-GRAMA (Heterogeneous Graph Routing and Message Alignment), a training-free framework that lifts merging from parameter space to operator space. We formalize Universal Message Passing Mixture (UMPM), a shared operator family that expresses heterogeneous GNN layers in a common functional language. H-GRAMA enables cross-architecture GNN merging (e.g., GCN to GAT) without retraining, retaining high specialist accuracy in most cases in compatible depth settings and achieving inference speedups of 1.2x to 1.9x over ensembles.",
      "authors": [
        "Rishabh Bhattacharya",
        "Vikaskumar Kalsariya",
        "Naresh Manwani"
      ],
      "url": "https://arxiv.org/abs/2602.19332",
      "published": "2026-02-22T20:43:28+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19331",
      "title": "Partial Soft-Matching Distance for Neural Representational Comparison with Partial Unit Correspondence",
      "abstract": "Representational similarity metrics typically force all units to be matched, making them susceptible to noise and outliers common in neural representations. We extend the soft-matching distance to a partial optimal transport setting that allows some neurons to remain unmatched, yielding rotation-sensitive but robust correspondences. This partial soft-matching distance provides theoretical advantages -- relaxing strict mass conservation while maintaining interpretable transport costs -- and practical benefits through efficient neuron ranking in terms of cross-network alignment without costly iterative recomputation. In simulations, it preserves correct matches under outliers and reliably selects the correct model in noise-corrupted identification tasks. On fMRI data, it automatically excludes low-reliability voxels and produces voxel rankings by alignment quality that closely match computationally expensive brute-force approaches. It achieves higher alignment precision across homologous brain areas than standard soft-matching, which is forced to match all units regardless of quality. In deep networks, highly matched units exhibit similar maximally exciting images, while unmatched units show divergent patterns. This ability to partition by match quality enables focused analyses, e.g., testing whether networks have privileged axes even within their most aligned subpopulations. Overall, partial soft-matching provides a principled and practical method for representational comparison under partial correspondence.",
      "authors": [
        "Chaitanya Kapoor",
        "Alex H. Williams",
        "Meenakshi Khosla"
      ],
      "url": "https://arxiv.org/abs/2602.19331",
      "published": "2026-02-22T20:31:35+00:00",
      "categories": [
        "cs.LG",
        "cs.NE",
        "stat.ML"
      ]
    },
    {
      "id": "2602.19330",
      "title": "CTS-Bench: Benchmarking Graph Coarsening Trade-offs for GNNs in Clock Tree Synthesis",
      "abstract": "Graph Neural Networks (GNNs) are increasingly explored for physical design analysis in Electronic Design Automation, particularly for modeling Clock Tree Synthesis behavior such as clock skew and buffering complexity. However, practical deployment remains limited due to the prohibitive memory and runtime cost of operating on raw gate-level netlists. Graph coarsening is commonly used to improve scalability, yet its impact on CTS-critical learning objectives is not well characterized. This paper introduces CTS-Bench, a benchmark suite for systematically evaluating the trade-offs between graph coarsening, prediction accuracy, and computational efficiency in GNN-based CTS analysis. CTS-Bench consists of 4,860 converged physical design solutions spanning five architectures and provides paired raw gate-level and clustered graph representations derived from post-placement designs. Using clock skew prediction as a representative CTS task, we demonstrate a clear accuracy-efficiency trade-off. While graph coarsening reduces GPU memory usage by up to 17.2x and accelerates training by up to 3x, it also removes structural information essential for modeling clock distribution, frequently resulting in negative $R^2$ scores under zero-shot evaluation. Our findings indicate that generic graph clustering techniques can fundamentally compromise CTS learning objectives, even when global physical metrics remain unchanged. CTS-Bench enables principled evaluation of CTS-aware graph coarsening strategies, supports benchmarking of GNN architectures and accelerators under realistic physical design constraints, and provides a foundation for developing learning-assisted CTS analysis and optimization techniques.",
      "authors": [
        "Barsat Khadka",
        "Kawsher Roxy",
        "Md Rubel Ahmed"
      ],
      "url": "https://arxiv.org/abs/2602.19330",
      "published": "2026-02-22T20:29:30+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19329",
      "title": "Dynamic Elasticity Between Forest Loss and Carbon Emissions: A Subnational Panel Analysis of the United States",
      "abstract": "Accurate quantification of the relationship between forest loss and associated carbon emissions is critical for both environmental monitoring and policy evaluation. Although many studies have documented spatial patterns of forest degradation, there is limited understanding of the dynamic elasticity linking tree cover loss to carbon emissions at subnational scales. In this paper, we construct a comprehensive panel dataset of annual forest loss and carbon emission estimates for U.S. subnational administrative units from 2001 to 2023, based on the Hansen Global Forest Change dataset. We apply fixed effects and dynamic panel regression techniques to isolate within-region variation and account for temporal persistence in emissions. Our results show that forest loss has a significant positive short-run elasticity with carbon emissions, and that emissions exhibit strong persistence over time. Importantly, the estimated long-run elasticity, accounting for autoregressive dynamics, is substantially larger than the short-run effect, indicating cumulative impacts of repeated forest loss events. These findings highlight the importance of modeling temporal dynamics when assessing environmental responses to land cover change. The dynamic elasticity framework proposed here offers a robust and interpretable tool for analyzing environmental change processes, and can inform both regional monitoring systems and carbon accounting frameworks.",
      "authors": [
        "Keonvin Park"
      ],
      "url": "https://arxiv.org/abs/2602.19329",
      "published": "2026-02-22T20:25:58+00:00",
      "categories": [
        "stat.AP",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19327",
      "title": "Soft Sequence Policy Optimization: Bridging GMPO and SAPO",
      "abstract": "A significant portion of recent research on Large Language Model (LLM) alignment focuses on developing new policy optimization methods based on Group Relative Policy Optimization (GRPO). Two prominent directions have emerged: (i) a shift toward sequence-level importance sampling weights that better align with the sequence-level rewards used in many tasks, and (ii) alternatives to PPO-style clipping that aim to avoid the associated loss of training signal and entropy collapse. Recent work, such as Soft Adaptive Policy Optimization (SAPO), reformulates the Scopic objective within the GRPO framework and achieves both sequence coherence and token adaptivity. Geometric-Mean Policy Optimization (GMPO) leverages token-wise ratio clipping within sequence importance sampling weights. Building on these ideas, this work proposes a new objective that promotes effective policy exploration while maintaining training stability. Specifically, we introduce Soft Sequence Policy Optimization, an off-policy reinforcement learning objective that incorporates soft gating functions over token-level probability ratios within sequence-level importance weights.",
      "authors": [
        "Svetlana Glazyrina",
        "Maksim Kryzhanovskiy",
        "Roman Ischenko"
      ],
      "url": "https://arxiv.org/abs/2602.19327",
      "published": "2026-02-22T20:21:00+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19326",
      "title": "City Editing: Hierarchical Agentic Execution for Dependency-Aware Urban Geospatial Modification",
      "abstract": "As cities evolve over time, challenges such as traffic congestion and functional imbalance increasingly necessitate urban renewal through efficient modification of existing plans, rather than complete re-planning. In practice, even minor urban changes require substantial manual effort to redraw geospatial layouts, slowing the iterative planning and decision-making procedure. Motivated by recent advances in agentic systems and multimodal reasoning, we formulate urban renewal as a machine-executable task that iteratively modifies existing urban plans represented in structured geospatial formats. More specifically, we represent urban layouts using GeoJSON and decompose natural-language editing instructions into hierarchical geometric intents spanning polygon-, line-, and point-level operations. To coordinate interdependent edits across spatial elements and abstraction levels, we propose a hierarchical agentic framework that jointly performs multi-level planning and execution with explicit propagation of intermediate spatial constraints. We further introduce an iterative execution-validation mechanism that mitigates error accumulation and enforces global spatial consistency during multi-step editing. Extensive experiments across diverse urban editing scenarios demonstrate significant improvements in efficiency, robustness, correctness, and spatial validity over existing baselines.",
      "authors": [
        "Rui Liu",
        "Steven Jige Quan",
        "Zhong-Ren Peng",
        "Zijun Yao",
        "Han Wang",
        "Zhengzhang Chen",
        "Kunpeng Liu",
        "Yanjie Fu",
        "Dongjie Wang"
      ],
      "url": "https://arxiv.org/abs/2602.19326",
      "published": "2026-02-22T20:20:28+00:00",
      "categories": [
        "cs.MA",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19324",
      "title": "RetinaVision: XAI-Driven Augmented Regulation for Precise Retinal Disease Classification using deep learning framework",
      "abstract": "Early and accurate classification of retinal diseases is critical to counter vision loss and for guiding clinical management of retinal diseases. In this study, we proposed a deep learning method for retinal disease classification utilizing optical coherence tomography (OCT) images from the Retinal OCT Image Classification - C8 dataset (comprising 24,000 labeled images spanning eight conditions). Images were resized to 224x224 px and tested on convolutional neural network (CNN) architectures: Xception and InceptionV3. Data augmentation techniques (CutMix, MixUp) were employed to enhance model generalization. Additionally, we applied GradCAM and LIME for interpretability evaluation. We implemented this in a real-world scenario via our web application named RetinaVision. This study found that Xception was the most accurate network (95.25%), followed closely by InceptionV3 (94.82%). These results suggest that deep learning methods allow effective OCT retinal disease classification and highlight the importance of implementing accuracy and interpretability for clinical applications.",
      "authors": [
        "Mohammad Tahmid Noor",
        "Shayan Abrar",
        "Jannatul Adan Mahi",
        "Md Parvez Mia",
        "Asaduzzaman Hridoy",
        "Samanta Ghosh"
      ],
      "url": "https://arxiv.org/abs/2602.19324",
      "published": "2026-02-22T20:05:54+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19322",
      "title": "US-JEPA: A Joint Embedding Predictive Architecture for Medical Ultrasound",
      "abstract": "Ultrasound (US) imaging poses unique challenges for representation learning due to its inherently noisy acquisition process. The low signal-to-noise ratio and stochastic speckle patterns hinder standard self-supervised learning methods relying on a pixel-level reconstruction objective. Joint-Embedding Predictive Architectures (JEPAs) address this drawback by predicting masked latent representations rather than raw pixels. However, standard approaches depend on hyperparameter-brittle and computationally expensive online teachers updated via exponential moving average. We propose US-JEPA, a self-supervised framework that adopts the Static-teacher Asymmetric Latent Training (SALT) objective. By using a frozen, domain-specific teacher to provide stable latent targets, US-JEPA decouples student-teacher optimization and pushes the student to expand upon the semantic priors of the teacher. In addition, we provide the first rigorous comparison of all publicly available state-of-the-art ultrasound foundation models on UltraBench, a public dataset benchmark spanning multiple organs and pathological conditions. Under linear probing for diverse classification tasks, US-JEPA achieves performance competitive with or superior to domain-specific and universal vision foundation model baselines. Our results demonstrate that masked latent prediction provides a stable and efficient path toward robust ultrasound representations.",
      "authors": [
        "Ashwath Radhachandran",
        "Vedrana Ivezić",
        "Shreeram Athreya",
        "Ronit Anilkumar",
        "Corey W. Arnold",
        "William Speier"
      ],
      "url": "https://arxiv.org/abs/2602.19322",
      "published": "2026-02-22T19:56:56+00:00",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19320",
      "title": "Anatomy of Agentic Memory: Taxonomy and Empirical Analysis of Evaluation and System Limitations",
      "abstract": "Agentic memory systems enable large language model (LLM) agents to maintain state across long interactions, supporting long-horizon reasoning and personalization beyond fixed context windows. Despite rapid architectural development, the empirical foundations of these systems remain fragile: existing benchmarks are often underscaled, evaluation metrics are misaligned with semantic utility, performance varies significantly across backbone models, and system-level costs are frequently overlooked. This survey presents a structured analysis of agentic memory from both architectural and system perspectives. We first introduce a concise taxonomy of MAG systems based on four memory structures. Then, we analyze key pain points limiting current systems, including benchmark saturation effects, metric validity and judge sensitivity, backbone-dependent accuracy, and the latency and throughput overhead introduced by memory maintenance. By connecting the memory structure to empirical limitations, this survey clarifies why current agentic memory systems often underperform their theoretical promise and outlines directions for more reliable evaluation and scalable system design.",
      "authors": [
        "Dongming Jiang",
        "Yi Li",
        "Songtao Wei",
        "Jinxin Yang",
        "Ayushi Kishore",
        "Alysa Zhao",
        "Dingyi Kang",
        "Xu Hu",
        "Feng Chen",
        "Qiannan Li",
        "Bingzhe Li"
      ],
      "url": "https://arxiv.org/abs/2602.19320",
      "published": "2026-02-22T19:50:01+00:00",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19319",
      "title": "Health+: Empowering Individuals via Unifying Health Data",
      "abstract": "Managing personal health data is a challenge in today's fragmented and institution-centric healthcare ecosystem. Individuals often lack meaningful control over their medical records, which are scattered across incompatible systems and formats. This vision paper presents Health+, a user-centric, multimodal health data management system that empowers individuals (including those with limited technical expertise) to upload, query, and share their data across modalities (e.g., text, images, reports). Rather than aiming for institutional overhaul, Health+ emphasizes individual agency by providing intuitive interfaces and intelligent recommendations for data access and sharing. At the system level, it tackles the complexity of storing, integrating, and securing heterogeneous health records, ensuring both efficiency and privacy. By unifying multimodal data and prioritizing patients, Health+ lays the foundation for a more connected, interpretable, and user-controlled health information ecosystem.",
      "authors": [
        "Sujaya Maiyya",
        "Shantanu Sharma",
        "Avinash Kumar"
      ],
      "url": "https://arxiv.org/abs/2602.19319",
      "published": "2026-02-22T19:48:57+00:00",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CR",
        "cs.DB",
        "cs.DC"
      ]
    },
    {
      "id": "2602.19317",
      "title": "Learning to Reason for Multi-Step Retrieval of Personal Context in Personalized Question Answering",
      "abstract": "Personalization in Question Answering (QA) requires answers that are both accurate and aligned with users' background, preferences, and historical context. Existing state-of-the-art methods primarily rely on retrieval-augmented generation (RAG) solutions that construct personal context by retrieving relevant items from the user's profile. Existing methods use the user's query directly to retrieve personal documents, and such strategies often lead to surface-level personalization. We propose PR2 (Personalized Retrieval-Augmented Reasoning), a reinforcement learning framework that integrates reasoning and retrieval from personal context for personalization. PR2 learns adaptive retrieval-reasoning policies, determining when to retrieve, what evidence to retrieve from user profiles, and how to incorporate it into intermediate reasoning steps. By optimizing multi-turn reasoning trajectories under a personalized reward function, the framework reinforces reasoning paths that better align with user-specific preferences and contextual signals reflected by the reward model. Extensive experiments on the LaMP-QA benchmark using three LLMs show that PR2 consistently outperforms strong baselines, achieving an average relative improvement of 8.8%-12% in personalized QA.",
      "authors": [
        "Maryam Amirizaniani",
        "Alireza Salemi",
        "Hamed Zamani"
      ],
      "url": "https://arxiv.org/abs/2602.19317",
      "published": "2026-02-22T19:43:43+00:00",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "id": "2602.19315",
      "title": "Online Navigation Planning for Long-term Autonomous Operation of Underwater Gliders",
      "abstract": "Underwater glider robots have become an indispensable tool for ocean sampling. Although stakeholders are calling for tools to manage increasingly large fleets of gliders, successful autonomous long-term deployments have thus far been scarce, which hints at a lack of suitable methodologies and systems. In this work, we formulate glider navigation planning as a stochastic shortest-path Markov Decision Process and propose a sample-based online planner based on Monte Carlo Tree Search. Samples are generated by a physics-informed simulator that captures uncertain execution of controls and ocean current forecasts while remaining computationally tractable. The simulator parameters are fitted using historical glider data. We integrate these methods into an autonomous command-and-control system for Slocum gliders that enables closed-loop replanning at each surfacing. The resulting system was validated in two field deployments in the North Sea totalling approximately 3 months and 1000 km of autonomous operation. Results demonstrate improved efficiency compared to straight-to-goal navigation and show the practicality of sample-based planning for long-term marine autonomy.",
      "authors": [
        "Victor-Alexandru Darvariu",
        "Charlotte Z. Reed",
        "Jan Stratmann",
        "Bruno Lacerda",
        "Benjamin Allsup",
        "Stephen Woodward",
        "Elizabeth Siddle",
        "Trishna Saeharaseelan",
        "Owain Jones",
        "Dan Jones",
        "Tobias Ferreira",
        "Chloe Baker",
        "Kevin Chaplin",
        "James Kirk",
        "Ashley Morris",
        "Ryan Patmore",
        "Jeff Polton",
        "Charlotte Williams",
        "Alexandra Kokkinaki",
        "Alvaro Lorenzo Lopez",
        "Justin J. H. Buck",
        "Nick Hawes"
      ],
      "url": "https://arxiv.org/abs/2602.19315",
      "published": "2026-02-22T19:34:10+00:00",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19314",
      "title": "IPv2: An Improved Image Purification Strategy for Real-World Ultra-Low-Dose Lung CT Denoising",
      "abstract": "The image purification strategy constructs an intermediate distribution with aligned anatomical structures, which effectively corrects the spatial misalignment between real-world ultra-low-dose CT and normal-dose CT images and significantly enhances the structural preservation ability of denoising models. However, this strategy exhibits two inherent limitations. First, it suppresses noise only in the chest wall and bone regions while leaving the image background untreated. Second, it lacks a dedicated mechanism for denoising the lung parenchyma. To address these issues, we systematically redesign the original image purification strategy and propose an improved version termed IPv2. The proposed strategy introduces three core modules, namely Remove Background, Add noise, and Remove noise. These modules endow the model with denoising capability in both background and lung tissue regions during training data construction and provide a more reasonable evaluation protocol through refined label construction at the testing stage. Extensive experiments on our previously established real-world patient lung CT dataset acquired at 2% radiation dose demonstrate that IPv2 consistently improves background suppression and lung parenchyma restoration across multiple mainstream denoising models. The code is publicly available at https://github.com/MonkeyDadLufy/Image-Purification-Strategy-v2.",
      "authors": [
        "Guoliang Gong",
        "Man Yu"
      ],
      "url": "https://arxiv.org/abs/2602.19314",
      "published": "2026-02-22T19:28:31+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19313",
      "title": "TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics",
      "abstract": "While Vision-Language-Action (VLA) models have seen rapid progress in pretraining, their advancement in Reinforcement Learning (RL) remains hampered by low sample efficiency and sparse rewards in real-world settings. Developing generalizable process reward models is essential for providing the fine-grained feedback necessary to bridge this gap, yet existing temporal value functions often fail to generalize beyond their training domains. We introduce TOPReward, a novel, probabilistically grounded temporal value function that leverages the latent world knowledge of pretrained video Vision-Language Models (VLMs) to estimate robotic task progress. Unlike prior methods that prompt VLMs to directly output progress values, which are prone to numerical misrepresentation, TOPReward extracts task progress directly from the VLM's internal token logits. In zero-shot evaluations across 130+ distinct real-world tasks and multiple robot platforms (e.g., Franka, YAM, SO-100/101), TOPReward achieves 0.947 mean Value-Order Correlation (VOC) on Qwen3-VL, dramatically outperforming the state-of-the-art GVL baseline which achieves near-zero correlation on the same open-source model. We further demonstrate that TOPReward serves as a versatile tool for downstream applications, including success detection and reward-aligned behavior cloning.",
      "authors": [
        "Shirui Chen",
        "Cole Harrison",
        "Ying-Chun Lee",
        "Angela Jin Yang",
        "Zhongzheng Ren",
        "Lillian J. Ratliff",
        "Jiafei Duan",
        "Dieter Fox",
        "Ranjay Krishna"
      ],
      "url": "https://arxiv.org/abs/2602.19313",
      "published": "2026-02-22T19:25:48+00:00",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19312",
      "title": "Metasurfaces-Integrated Wireless Neural Networks for Lightweight Over-The-Air Edge Inference",
      "abstract": "The upcoming sixth Generation (6G) of wireless networks envisions ultra-low latency and energy efficient Edge Inference (EI) for diverse Internet of Things (IoT) applications. However, traditional digital hardware for machine learning is power intensive, motivating the need for alternative computation paradigms. Over-The-Air (OTA) computation is regarded as an emerging transformative approach assigning the wireless channel to actively perform computational tasks. This article introduces the concept of Metasurfaces-Integrated Neural Networks (MINNs), a physical-layer-enabled deep learning framework that leverages programmable multi-layer metasurface structures and Multiple-Input Multiple-Output (MIMO) channels to realize computational layers in the wave propagation domain. The MINN system is conceptualized as three modules: Encoder, Channel (uncontrollable propagation features and metasurfaces), and Decoder. The first and last modules, realized respectively at the multi-antenna transmitter and receiver, consist of conventional digital or purposely designed analog Deep Neural Network (DNN) layers, and the metasurfaces responses of the Channel module are optimized alongside all modules as trainable weights. This architecture enables computation offloading into the end-to-end physical layer, flexibly among its constituent modules, achieving performance comparable to fully digital DNNs while significantly reducing power consumption. The training of the MINN framework, two representative variations, and performance results for indicative applications are presented, highlighting the potential of MINNs as a lightweight and sustainable solution for future EI-enabled wireless systems. The article is concluded with a list of open challenges and promising research directions.",
      "authors": [
        "Kyriakos Stylianopoulos",
        "Mario Edoardo Pandolfo",
        "Paolo Di Lorenzo",
        "George C. Alexandropoulos"
      ],
      "url": "https://arxiv.org/abs/2602.19312",
      "published": "2026-02-22T19:23:49+00:00",
      "categories": [
        "cs.ET",
        "cs.LG",
        "eess.SP"
      ]
    },
    {
      "id": "2602.20204",
      "title": "Analyzing Latency Hiding and Parallelism in an MLIR-based AI Kernel Compiler",
      "abstract": "AI kernel compilation for edge devices depends on the compiler's ability to exploit parallelism and hide memory latency in the presence of hierarchical memory and explicit data movement. This paper reports a benchmark methodology and corresponding results for three compiler-controlled mechanisms in an MLIR-based compilation pipeline: vectorization (Vec), multi-threading (MT) across hardware contexts, and double buffering (DB) using ping--pong scratchpad buffers to overlap DMA transfers with compute. Using Triton/Inductor-generated kernels, we present an ablation ladder that separates the contribution of Vec, MT, and DB, and we quantify how MT speedup scales with problem size using GELU as a representative activation kernel. The results show that vectorization provides the primary gain for bandwidth-sensitive kernels, MT delivers substantial improvements once scheduling overhead is amortized, and DB provides additional benefit when transfers and compute can be overlapped (i.e., outside the extremes of purely memory-bound or purely compute-bound behavior).",
      "authors": [
        "Javed Absar",
        "Samarth Narang",
        "Muthu Baskaran"
      ],
      "url": "https://arxiv.org/abs/2602.20204",
      "published": "2026-02-22T19:14:23+00:00",
      "categories": [
        "cs.PL",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19304",
      "title": "Safe and Interpretable Multimodal Path Planning for Multi-Agent Cooperation",
      "abstract": "Successful cooperation among decentralized agents requires each agent to quickly adapt its plan to the behavior of other agents. In scenarios where agents cannot confidently predict one another's intentions and plans, language communication can be crucial for ensuring safety. In this work, we focus on path-level cooperation in which agents must adapt their paths to one another in order to avoid collisions or perform physical collaboration such as joint carrying. In particular, we propose a safe and interpretable multimodal path planning method, CaPE (Code as Path Editor), which generates and updates path plans for an agent based on the environment and language communication from other agents. CaPE leverages a vision-language model (VLM) to synthesize a path editing program verified by a model-based planner, grounding communication to path plan updates in a safe and interpretable way. We evaluate our approach in diverse simulated and real-world scenarios, including multi-robot and human-robot cooperation in autonomous driving, household, and joint carrying tasks. Experimental results demonstrate that CaPE can be integrated into different robotic systems as a plug-and-play module, greatly enhancing a robot's ability to align its plan to language communication from other robots or humans. We also show that the combination of the VLM-based path editing program synthesis and model-based planning safety enables robots to achieve open-ended cooperation while maintaining safety and interpretability.",
      "authors": [
        "Haojun Shi",
        "Suyu Ye",
        "Katherine M. Guerrerio",
        "Jianzhi Shen",
        "Yifan Yin",
        "Daniel Khashabi",
        "Chien-Ming Huang",
        "Tianmin Shu"
      ],
      "url": "https://arxiv.org/abs/2602.19304",
      "published": "2026-02-22T18:57:07+00:00",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ]
    },
    {
      "id": "2602.19298",
      "title": "ALPACA: A Reinforcement Learning Environment for Medication Repurposing and Treatment Optimization in Alzheimer's Disease",
      "abstract": "Evaluating personalized, sequential treatment strategies for Alzheimer's disease (AD) using clinical trials is often impractical due to long disease horizons and substantial inter-patient heterogeneity. To address these constraints, we present the Alzheimer's Learning Platform for Adaptive Care Agents (ALPACA), an open-source, Gym-compatible reinforcement learning (RL) environment for systematically exploring personalized treatment strategies using existing therapies. ALPACA is powered by the Continuous Action-conditioned State Transitions (CAST) model trained on longitudinal trajectories from the Alzheimer's Disease Neuroimaging Initiative (ADNI), enabling medication-conditioned simulation of disease progression under alternative treatment decisions. We show that CAST autoregressively generates realistic medication-conditioned trajectories and that RL policies trained in ALPACA outperform no-treatment and behavior-cloned clinician baselines on memory-related outcomes. Interpretability analyses further indicated that the learned policies relied on clinically meaningful patient features when selecting actions. Overall, ALPACA provides a reusable in silico testbed for studying individualized sequential treatment decision-making for AD.",
      "authors": [
        "Nolan Brady",
        "Tom Yeh"
      ],
      "url": "https://arxiv.org/abs/2602.19298",
      "published": "2026-02-22T18:22:14+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.20202",
      "title": "Evaluating the Reliability of Digital Forensic Evidence Discovered by Large Language Model: A Case Study",
      "abstract": "The growing reliance on AI-identified digital evidence raises significant concerns about its reliability, particularly as large language models (LLMs) are increasingly integrated into forensic investigations. This paper proposes a structured framework that automates forensic artifact extraction, refines data through LLM-driven analysis, and validates results using a Digital Forensic Knowledge Graph (DFKG). Evaluated on a 13 GB forensic image dataset containing 61 applications, 2,864 databases, and 5,870 tables, the framework ensures artifact traceability and evidentiary consistency through deterministic Unique Identifiers (UIDs) and forensic cross-referencing. We propose this methodology to address challenges in ensuring the credibility and forensic integrity of AI-identified evidence, reducing classification errors, and advancing scalable, auditable methodologies. A comprehensive case study on this dataset demonstrates the framework's effectiveness, achieving over 95 percent accuracy in artifact extraction, strong support of chain-of-custody adherence, and robust contextual consistency in forensic relationships. Key results validate the framework's ability to enhance reliability, reduce errors, and establish a legally sound paradigm for AI-assisted digital forensics.",
      "authors": [
        "Jeel Piyushkumar Khatiwala",
        "Daniel Kwaku Ntiamoah Addai",
        "Weifeng Xu"
      ],
      "url": "https://arxiv.org/abs/2602.20202",
      "published": "2026-02-22T18:20:49+00:00",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19297",
      "title": "Automated Generation of Microfluidic Netlists using Large Language Models",
      "abstract": "Microfluidic devices have emerged as powerful tools in various laboratory applications, but the complexity of their design limits accessibility for many practitioners. While progress has been made in microfluidic design automation (MFDA), a practical and intuitive solution is still needed to connect microfluidic practitioners with MFDA techniques. This work introduces the first practical application of large language models (LLMs) in this context, providing a preliminary demonstration. Building on prior research in hardware description language (HDL) code generation with LLMs, we propose an initial methodology to convert natural language microfluidic device specifications into system-level structural Verilog netlists. We demonstrate the feasibility of our approach by generating structural netlists for practical benchmarks representative of typical microfluidic designs with correct functional flow and an average syntactical accuracy of 88%.",
      "authors": [
        "Jasper Davidson",
        "Skylar Stockham",
        "Allen Boston",
        "Ashton Snelgrove",
        "Valerio Tenace",
        "Pierre-Emmanuel Gaillardon"
      ],
      "url": "https://arxiv.org/abs/2602.19297",
      "published": "2026-02-22T18:14:10+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.19289",
      "title": "AdsorbFlow: energy-conditioned flow matching enables fast and realistic adsorbate placement",
      "abstract": "Identifying low-energy adsorption geometries on catalytic surfaces is a practical bottleneck for computational heterogeneous catalysis: the difficulty lies not only in the cost of density functional theory (DFT) but in proposing initial placements that relax into the correct energy basins. Conditional denoising diffusion has improved success rates, yet requires $\\sim$100 iterative steps per sample.   Here we introduce AdsorbFlow, a deterministic generative model that learns an energy-conditioned vector field on the rigid-body configuration space of adsorbate translation and rotation via conditional flow matching. Energy information enters through classifier-free guidance conditioning -- not energy-gradient guidance -- and sampling reduces to integrating an ODE in as few as 5 steps.   On OC20-Dense with full DFT single-point verification, AdsorbFlow with an EquiformerV2 backbone achieves 61.4% SR@10 and 34.1% SR@1 -- surpassing AdsorbDiff (31.8% SR@1, 41.0% SR@10) at every evaluation level and AdsorbML (47.7% SR@10) -- while using 20 times fewer generative steps and achieving the lowest anomaly rate among generative methods (6.8%). On 50 out-of-distribution systems, AdsorbFlow retains 58.0% SR@10 with a MLFF-to-DFT gap of only 4~percentage points. These results establish that deterministic transport is both faster and more accurate than stochastic denoising for adsorbate placement.",
      "authors": [
        "Jiangjie Qiu",
        "Wentao Li",
        "Honghao Chen",
        "Leyi Zhao",
        "Xiaonan Wang"
      ],
      "url": "https://arxiv.org/abs/2602.19289",
      "published": "2026-02-22T17:53:53+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19281",
      "title": "Limited Reasoning Space: The cage of long-horizon reasoning in LLMs",
      "abstract": "The test-time compute strategy, such as Chain-of-Thought (CoT), has significantly enhanced the ability of large language models to solve complex tasks like logical reasoning. However, empirical studies indicate that simply increasing the compute budget can sometimes lead to a collapse in test-time performance when employing typical task decomposition strategies such as CoT. This work hypothesizes that reasoning failures with larger compute budgets stem from static planning methods, which hardly perceive the intrinsic boundaries of LLM reasoning. We term it as the Limited Reasoning Space hypothesis and perform theoretical analysis through the lens of a non-autonomous stochastic dynamical system. This insight suggests that there is an optimal range for compute budgets; over-planning can lead to redundant feedback and may even impair reasoning capabilities. To exploit the compute-scaling benefits and suppress over-planning, this work proposes Halo, a model predictive control framework for LLM planning. Halo is designed for long-horizon tasks with reason-based planning and crafts an entropy-driven dual controller, which adopts a Measure-then-Plan strategy to achieve controllable reasoning. Experimental results demonstrate that Halo outperforms static baselines on complex long-horizon tasks by dynamically regulating planning at the reasoning boundary.",
      "authors": [
        "Zhenyu Li",
        "Guanlin Wu",
        "Cheems Wang",
        "Yongqiang Zhao"
      ],
      "url": "https://arxiv.org/abs/2602.19281",
      "published": "2026-02-22T17:28:27+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.19271",
      "title": "Taming Preconditioner Drift: Unlocking the Potential of Second-Order Optimizers for Federated Learning on Non-IID Data",
      "abstract": "Second-order optimizers can significantly accelerate large-scale training, yet their naive federated variants are often unstable or even diverge on non-IID data.   We show that a key culprit is \\emph{preconditioner drift}: client-side second-order training induces heterogeneous \\emph{curvature-defined geometries} (i.e., preconditioner coordinate systems), and server-side model averaging updates computed under incompatible metrics, corrupting the global descent direction.   To address this geometric mismatch, we propose \\texttt{FedPAC}, a \\emph{preconditioner alignment and correction} framework for reliable federated second-order optimization.   \\texttt{FedPAC} explicitly decouples parameter aggregation from geometry synchronization by:   (i) \\textbf{Alignment} (i.e.,aggregating local preconditioners into a global reference and warm-starting clients via global preconditioner); and   (ii) \\textbf{Correction} (i.e., steering local preconditioned updates using a global preconditioned direction to suppress long-term drift).   We provide drift-coupled non-convex convergence guarantees with linear speedup under partial participation.   Empirically, \\texttt{FedPAC} consistently improves stability and accuracy across vision and language tasks, achieving up to $5.8\\%$ absolute accuracy gain on CIFAR-100 with ViTs.   Code is available at https://anonymous.4open.science/r/FedPAC-8B24.",
      "authors": [
        "Junkang Liu",
        "Fanhua Shang",
        "Hongying Liu",
        "Jin Liu",
        "Weixin An",
        "Yuanyuan Liu"
      ],
      "url": "https://arxiv.org/abs/2602.19271",
      "published": "2026-02-22T16:57:57+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19268",
      "title": "CORVET: A CORDIC-Powered, Resource-Frugal Mixed-Precision Vector Processing Engine for High-Throughput AIoT applications",
      "abstract": "This brief presents a runtime-adaptive, performance-enhanced vector engine featuring a low-resource, iterative CORDIC-based MAC unit for edge AI acceleration. The proposed design enables dynamic reconfiguration between approximate and accurate modes, exploiting the latency-accuracy trade-off for a wide range of workloads. Its resource-efficient approach further enables up to 4x throughput improvement within the same hardware resources by leveraging vectorised, time-multiplexed execution and flexible precision scaling. With a time-multiplexed multi-AF block and a lightweight pooling and normalisation unit, the proposed vector engine supports flexible precision (4/8/16-bit) and high MAC density. The ASIC implementation results show that each MAC stage can save up to 33% of time and 21% of power, with a 256-PE configuration that achieves higher compute density (4.83 TOPS/mm2 ) and energy efficiency (11.67 TOPS/W) than previous state-of-the-art work. A detailed hardware-software co-design methodology for object detection and classification tasks on Pynq-Z2 is discussed to assess the proposed architecture, demonstrating a scalable, energy-efficient solution for edge AI applications.",
      "authors": [
        "Sonu Kumar",
        "Mohd Faisal Khan",
        "Mukul Lokhande",
        "Santosh Kumar Vishvakarma"
      ],
      "url": "https://arxiv.org/abs/2602.19268",
      "published": "2026-02-22T16:51:17+00:00",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CV",
        "cs.NE",
        "eess.IV"
      ]
    },
    {
      "id": "2602.19265",
      "title": "Spectral bias in physics-informed and operator learning: Analysis and mitigation guidelines",
      "abstract": "Solving partial differential equations (PDEs) by neural networks as well as Kolmogorov-Arnold Networks (KANs), including physics-informed neural networks (PINNs), physics-informed KANs (PIKANs), and neural operators, are known to exhibit spectral bias, whereby low-frequency components of the solution are learned significantly faster than high-frequency modes. While spectral bias is often treated as an intrinsic representational limitation of neural architectures, its interaction with optimization dynamics and physics-based loss formulations remains poorly understood. In this work, we provide a systematic investigation of spectral bias in physics-informed and operator learning frameworks, with emphasis on the coupled roles of network architecture, activation functions, loss design, and optimization strategy. We quantify spectral bias through frequency-resolved error metrics, Barron-norm diagnostics, and higher-order statistical moments, enabling a unified analysis across elliptic, hyperbolic, and dispersive PDEs. Through diverse benchmark problems, including the Korteweg-de Vries, wave and steady-state diffusion-reaction equations, turbulent flow reconstruction, and earthquake dynamics, we demonstrate that spectral bias is not simply representational but fundamentally dynamical. In particular, second-order optimization methods substantially alter the spectral learning order, enabling earlier and more accurate recovery of high-frequency modes for all PDE types. For neural operators, we further show that spectral bias is dependent on the neural operator architecture and can also be effectively mitigated through spectral-aware loss formulations without increasing the inference cost.",
      "authors": [
        "Siavash Khodakarami",
        "Vivek Oommen",
        "Nazanin Ahmadi Daryakenari",
        "Maxim Beekenkamp",
        "George Em Karniadakis"
      ],
      "url": "https://arxiv.org/abs/2602.19265",
      "published": "2026-02-22T16:29:18+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.19263",
      "title": "Prognostics of Multisensor Systems with Unknown and Unlabeled Failure Modes via Bayesian Nonparametric Process Mixtures",
      "abstract": "Modern manufacturing systems often experience multiple and unpredictable failure behaviors, yet most existing prognostic models assume a fixed, known set of failure modes with labeled historical data. This assumption limits the use of digital twins for predictive maintenance, especially in high-mix or adaptive production environments, where new failure modes may emerge, and the failure mode labels may be unavailable.   To address these challenges, we propose a novel Bayesian nonparametric framework that unifies a Dirichlet process mixture module for unsupervised failure mode discovery with a neural network-based prognostic module. The key innovation lies in an iterative feedback mechanism to jointly learn two modules. These modules iteratively update one another to dynamically infer, expand, or merge failure modes as new data arrive while providing high prognostic accuracy.   Experiments on both simulation and aircraft engine datasets show that the proposed approach performs competitively with or significantly better than existing approaches. It also exhibits robust online adaptation capabilities, making it well-suited for digital-twin-based system health management in complex manufacturing environments.",
      "authors": [
        "Kani Fu",
        "Sanduni S Disanayaka Mudiyanselage",
        "Chunli Dai",
        "Minhee Kim"
      ],
      "url": "https://arxiv.org/abs/2602.19263",
      "published": "2026-02-22T16:26:51+00:00",
      "categories": [
        "stat.AP",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19261",
      "title": "DGPO: RL-Steered Graph Diffusion for Neural Architecture Generation",
      "abstract": "Reinforcement learning fine-tuning has proven effective for steering generative diffusion models toward desired properties in image and molecular domains. Graph diffusion models have similarly been applied to combinatorial structure generation, including neural architecture search (NAS). However, neural architectures are directed acyclic graphs (DAGs) where edge direction encodes functional semantics such as data flow-information that existing graph diffusion methods, designed for undirected structures, discard. We propose Directed Graph Policy Optimization (DGPO), which extends reinforcement learning fine-tuning of discrete graph diffusion models to DAGs via topological node ordering and positional encoding. Validated on NAS-Bench-101 and NAS-Bench-201, DGPO matches the benchmark optimum on all three NAS-Bench-201 tasks (91.61%, 73.49%, 46.77%). The central finding is that the model learns transferable structural priors: pretrained on only 7% of the search space, it generates near-oracle architectures after fine-tuning, within 0.32 percentage points of the full-data model and extrapolating 7.3 percentage points beyond its training ceiling. Bidirectional control experiments confirm genuine reward-driven steering, with inverse optimization reaching near random-chance accuracy (9.5%). These results demonstrate that reinforcement learning-steered discrete diffusion, once extended to handle directionality, provides a controllable generative framework for directed combinatorial structures.",
      "authors": [
        "Aleksei Liuliakov",
        "Luca Hermes",
        "Barbara Hammer"
      ],
      "url": "https://arxiv.org/abs/2602.19261",
      "published": "2026-02-22T16:23:42+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ]
    },
    {
      "id": "2602.19253",
      "title": "Alternating Bi-Objective Optimization for Explainable Neuro-Fuzzy Systems",
      "abstract": "Fuzzy systems show strong potential in explainable AI due to their rule-based architecture and linguistic variables. Existing approaches navigate the accuracy-explainability trade-off either through evolutionary multi-objective optimization (MOO), which is computationally expensive, or gradient-based scalarization, which cannot recover non-convex Pareto regions. We propose X-ANFIS, an alternating bi-objective gradient-based optimization scheme for explainable adaptive neuro-fuzzy inference systems. Cauchy membership functions are used for stable training under semantically controlled initializations, and a differentiable explainability objective is introduced and decoupled from the performance objective through alternating gradient passes. Validated in approximately 5,000 experiments on nine UCI regression datasets, X-ANFIS consistently achieves target distinguishability while maintaining competitive predictive accuracy, recovering solutions beyond the convex hull of the MOO Pareto front.",
      "authors": [
        "Qusai Khaled",
        "Uzay Kaymak",
        "Laura Genga"
      ],
      "url": "https://arxiv.org/abs/2602.19253",
      "published": "2026-02-22T16:08:06+00:00",
      "categories": [
        "cs.LG",
        "cs.NE"
      ]
    },
    {
      "id": "2602.19248",
      "title": "No Need For Real Anomaly: MLLM Empowered Zero-Shot Video Anomaly Detection",
      "abstract": "The collection and detection of video anomaly data has long been a challenging problem due to its rare occurrence and spatio-temporal scarcity. Existing video anomaly detection (VAD) methods under perform in open-world scenarios. Key contributing factors include limited dataset diversity, and inadequate understanding of context-dependent anomalous semantics. To address these issues, i) we propose LAVIDA, an end-to-end zero-shot video anomaly detection framework. ii) LAVIDA employs an Anomaly Exposure Sampler that transforms segmented objects into pseudo-anomalies to enhance model adaptability to unseen anomaly categories. It further integrates a Multimodal Large Language Model (MLLM) to bolster semantic comprehension capabilities. Additionally, iii) we design a token compression approach based on reverse attention to handle the spatio-temporal scarcity of anomalous patterns and decrease computational cost. The training process is conducted solely on pseudo anomalies without any VAD data. Evaluations across four benchmark VAD datasets demonstrate that LAVIDA achieves SOTA performance in both frame-level and pixel-level anomaly detection under the zero-shot setting. Our code is available in https://github.com/VitaminCreed/LAVIDA.",
      "authors": [
        "Zunkai Dai",
        "Ke Li",
        "Jiajia Liu",
        "Jie Yang",
        "Yuanyuan Qiao"
      ],
      "url": "https://arxiv.org/abs/2602.19248",
      "published": "2026-02-22T16:03:43+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19244",
      "title": "Robust Exploration in Directed Controller Synthesis via Reinforcement Learning with Soft Mixture-of-Experts",
      "abstract": "On-the-fly Directed Controller Synthesis (OTF-DCS) mitigates state-space explosion by incrementally exploring the system and relies critically on an exploration policy to guide search efficiently. Recent reinforcement learning (RL) approaches learn such policies and achieve promising zero-shot generalization from small training instances to larger unseen ones. However, a fundamental limitation is anisotropic generalization, where an RL policy exhibits strong performance only in a specific region of the domain-parameter space while remaining fragile elsewhere due to training stochasticity and trajectory-dependent bias. To address this, we propose a Soft Mixture-of-Experts framework that combines multiple RL experts via a prior-confidence gating mechanism and treats these anisotropic behaviors as complementary specializations. The evaluation on the Air Traffic benchmark shows that Soft-MoE substantially expands the solvable parameter space and improves robustness compared to any single expert.",
      "authors": [
        "Toshihide Ubukata",
        "Zhiyao Wang",
        "Enhong Mu",
        "Jialong Li",
        "Kenji Tei"
      ],
      "url": "https://arxiv.org/abs/2602.19244",
      "published": "2026-02-22T15:56:13+00:00",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19241",
      "title": "Scaling Laws for Precision in High-Dimensional Linear Regression",
      "abstract": "Low-precision training is critical for optimizing the trade-off between model quality and training costs, necessitating the joint allocation of model size, dataset size, and numerical precision. While empirical scaling laws suggest that quantization impacts effective model and data capacities or acts as an additive error, the theoretical mechanisms governing these effects remain largely unexplored. In this work, we initiate a theoretical study of scaling laws for low-precision training within a high-dimensional sketched linear regression framework. By analyzing multiplicative (signal-dependent) and additive (signal-independent) quantization, we identify a critical dichotomy in their scaling behaviors. Our analysis reveals that while both schemes introduce an additive error and degrade the effective data size, they exhibit distinct effects on effective model size: multiplicative quantization maintains the full-precision model size, whereas additive quantization reduces the effective model size. Numerical experiments validate our theoretical findings. By rigorously characterizing the complex interplay among model scale, dataset size, and quantization error, our work provides a principled theoretical basis for optimizing training protocols under practical hardware constraints.",
      "authors": [
        "Dechen Zhang",
        "Xuan Tang",
        "Yingyu Liang",
        "Difan Zou"
      ],
      "url": "https://arxiv.org/abs/2602.19241",
      "published": "2026-02-22T15:51:29+00:00",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.19240",
      "title": "Topology of Reasoning: Retrieved Cell Complex-Augmented Generation for Textual Graph Question Answering",
      "abstract": "Retrieval-Augmented Generation (RAG) enhances the reasoning ability of Large Language Models (LLMs) by dynamically integrating external knowledge, thereby mitigating hallucinations and strengthening contextual grounding for structured data such as graphs. Nevertheless, most existing RAG variants for textual graphs concentrate on low-dimensional structures -- treating nodes as entities (0-dimensional) and edges or paths as pairwise or sequential relations (1-dimensional), but overlook cycles, which are crucial for reasoning over relational loops. Such cycles often arise in questions requiring closed-loop inference about similar objects or relative positions. This limitation often results in incomplete contextual grounding and restricted reasoning capability. In this work, we propose Topology-enhanced Retrieval-Augmented Generation (TopoRAG), a novel framework for textual graph question answering that effectively captures higher-dimensional topological and relational dependencies. Specifically, TopoRAG first lifts textual graphs into cellular complexes to model multi-dimensional topological structures. Leveraging these lifted representations, a topology-aware subcomplex retrieval mechanism is proposed to extract cellular complexes relevant to the input query, providing compact and informative topological context. Finally, a multi-dimensional topological reasoning mechanism operates over these complexes to propagate relational information and guide LLMs in performing structured, logic-aware inference. Empirical evaluations demonstrate that our method consistently surpasses existing baselines across diverse textual graph tasks.",
      "authors": [
        "Sen Zhao",
        "Lincheng Zhou",
        "Yue Chen",
        "Ding Zou"
      ],
      "url": "https://arxiv.org/abs/2602.19240",
      "published": "2026-02-22T15:44:53+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.19239",
      "title": "Attention Deficits in Language Models: Causal Explanations for Procedural Hallucinations",
      "abstract": "Large language models can follow complex procedures yet fail at a seemingly trivial final step: reporting a value they themselves computed moments earlier. We study this phenomenon as \\emph{procedural hallucination}: failure to execute a verifiable, prompt-grounded specification even when the correct value is present in context.   In long-context binding tasks with a known single-token candidate set, we find that many errors are readout-stage routing failures. Specifically, failures decompose into Stage~2A (gating) errors, where the model does not enter answer mode, and Stage~2B (binding) errors, where it enters answer mode but selects the wrong candidate (often due to recency bias). In the hard regime, Stage~2B accounts for most errors across model families in our tasks (Table~1).   On Stage~2B error trials, a linear probe on the final-layer residual stream recovers the correct value far above chance (e.g., 74\\% vs.\\ 2\\% on Qwen2.5-3B; Table~2), indicating that the answer is encoded but not used. We formalize ``present but not used'' via available vs.\\ used mutual information and pseudo-prior interventions, yielding output-computable diagnostics and information-budget certificates.   Finally, an oracle checkpointing intervention that restates the true binding near the query can nearly eliminate Stage~2B failures at long distance (e.g., Qwen2.5-3B $0/400 \\rightarrow 399/400$ at $k = 1024$; Table~8).",
      "authors": [
        "Ahmed Karim",
        "Fatima Sheaib",
        "Zein Khamis",
        "Maggie Chlon",
        "Jad Awada",
        "Leon Chlon"
      ],
      "url": "https://arxiv.org/abs/2602.19239",
      "published": "2026-02-22T15:43:41+00:00",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "id": "2602.20200",
      "title": "Global Prior Meets Local Consistency: Dual-Memory Augmented Vision-Language-Action Model for Efficient Robotic Manipulation",
      "abstract": "Hierarchical Vision-Language-Action (VLA) models have rapidly become a dominant paradigm for robotic manipulation. It typically comprising a Vision-Language backbone for perception and understanding, together with a generative policy for action generation. However, its performance is increasingly bottlenecked by the action generation proceess. (i) Low inference efficiency. A pronounced distributional gap between isotropic noise priors and target action distributions, which increases denoising steps and the incidence of infeasible samples. (ii) Poor robustness. Existing policies condition solely on the current observation, neglecting the constraint of history sequence and thus lacking awareness of task progress and temporal consistency. To address these issues, we introduce OptimusVLA, a dual-memory VLA framework with Global Prior Memory (GPM) and Local Consistency Memory (LCM). GPM replaces Gaussian noise with task-level priors retrieved from semantically similar trajectories, thereby shortening the generative path and reducing the umber of function evaluations (NFE). LCM dynamically models executed action sequence to infer task progress and injects a learned consistency constraint that enforces temporal coherence and smoothness of trajectory. Across three simulation benchmarks, OptimusVLA consistently outperforms strong baselines: it achieves 98.6% average success rate on LIBERO, improves over pi_0 by 13.5% on CALVIN, and attains 38% average success rate on RoboTwin 2.0 Hard. In Real-World evaluation, OptimusVLA ranks best on Generalization and Long-horizon suites, surpassing pi_0 by 42.9% and 52.4%, respectively, while delivering 2.9x inference speedup.",
      "authors": [
        "Zaijing Li",
        "Bing Hu",
        "Rui Shao",
        "Gongwei Chen",
        "Dongmei Jiang",
        "Pengwei Xie",
        "Jianye Hao",
        "Liqiang Nie"
      ],
      "url": "https://arxiv.org/abs/2602.20200",
      "published": "2026-02-22T15:39:34+00:00",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "id": "2602.19237",
      "title": "Evaluating SAP RPT-1 for Enterprise Business Process Prediction: In-Context Learning vs. Traditional Machine Learning on Structured SAP Data",
      "abstract": "Tabular foundation models aim to make machine learning accessible for enterprise data without task-specific training. This paper presents the first independent evaluation of SAP's Retrieval Pretrained Transformer (RPT-1) from a practitioner perspective. RPT-1 is a compact 64.6 MB model pretrained on 1.34 TB of structured data across 3.1 million tables. We benchmark it against tuned gradient-boosted decision trees (XGBoost, LightGBM, CatBoost) on three SAP business scenarios: demand forecasting across SD/MM/PP modules, predictive data integrity in BC/MM/QM, and financial risk classification in FI/CO/AR. Across five-fold cross-validation on datasets ranging from 2,500 to 3,200 rows, RPT-1 reaches 91-96% of tuned GBDT accuracy without any training examples. The classification gap is modest at 3.6-4.1 percentage points on AUC-ROC, though regression tasks show wider gaps of 8.9-11.1 percentage points on R-squared. An interesting finding is a crossover at roughly 75-100 context rows where RPT-1 actually outperforms XGBoost under limited data. Based on these results, we propose a practical hybrid workflow: use RPT-1 for rapid screening, then train GBDT selectively where prediction accuracy justifies the effort. All experiments are reproducible through publicly available Hugging Face Spaces.",
      "authors": [
        "Amit Lal"
      ],
      "url": "https://arxiv.org/abs/2602.19237",
      "published": "2026-02-22T15:29:52+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.19225",
      "title": "Proximity-Based Multi-Turn Optimization: Practical Credit Assignment for LLM Agent Training",
      "abstract": "Multi-turn LLM agents are becoming pivotal to production systems, spanning customer service automation, e-commerce assistance, and interactive task management, where accurately distinguishing high-value informative signals from stochastic noise is critical for sample-efficient training. In real-world scenarios, a failure in a trivial task may reflect random instability, whereas success in a high-difficulty task signifies a genuine capability breakthrough. Yet, existing group-based policy optimization methods rigidly rely on statistical deviation within discrete batches, frequently misallocating credit when task difficulty fluctuates. To address this issue, we propose Proximity-based Multi-turn Optimization (ProxMO), a practical and robust framework engineered specifically for the constraints of real-world deployment. ProxMO integrates global context via two lightweight mechanisms: success-rate-aware modulation dynamically adapts gradient intensity based on episode-level difficulty, while proximity-based soft aggregation derives baselines through continuous semantic weighting at the step level. Extensive evaluations on ALFWorld and WebShop benchmarks demonstrate that ProxMO yields substantial performance gains over existing baselines with negligible computational cost. Ablation studies further validate the independent and synergistic efficacy of both mechanisms. Crucially, ProxMO offers plug-and-play compatibility with standard GRPO frameworks, facilitating immediate, low-friction adoption in existing industrial training pipelines. Our implementation is available at: \\href{https://anonymous.4open.science/r/proxmo-B7E7/README.md}{https://anonymous.4open.science/r/proxmo}.",
      "authors": [
        "Yangyi Fang",
        "Jiaye Lin",
        "Xiaoliang Fu",
        "Cong Qin",
        "Haolin Shi",
        "Chang Liu",
        "Peilin Zhao"
      ],
      "url": "https://arxiv.org/abs/2602.19225",
      "published": "2026-02-22T15:18:03+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.19223",
      "title": "Characterizing MARL for Energy Control: A Multi-KPI Benchmark on the CityLearn Environment",
      "abstract": "The optimization of urban energy systems is crucial for the advancement of sustainable and resilient smart cities, which are becoming increasingly complex with multiple decision-making units. To address scalability and coordination concerns, Multi-Agent Reinforcement Learning (MARL) is a promising solution. This paper addresses the imperative need for comprehensive and reliable benchmarking of MARL algorithms on energy management tasks. CityLearn is used as a case study environment because it realistically simulates urban energy systems, incorporates multiple storage systems, and utilizes renewable energy sources. By doing so, our work sets a new standard for evaluation, conducting a comparative study across multiple key performance indicators (KPIs). This approach illuminates the key strengths and weaknesses of various algorithms, moving beyond traditional KPI averaging which often masks critical insights. Our experiments utilize widely accepted baselines such as Proximal Policy Optimization (PPO) and Soft Actor Critic (SAC), and encompass diverse training schemes including Decentralized Training with Decentralized Execution (DTDE) and Centralized Training with Decentralized Execution (CTDE) approaches and different neural network architectures. Our work also proposes novel KPIs that tackle real world implementation challenges such as individual building contribution and battery storage lifetime. Our findings show that DTDE consistently outperforms CTDE in both average and worst-case performance. Additionally, temporal dependency learning improved control on memory dependent KPIs such as ramping and battery usage, contributing to more sustainable battery operation. Results also reveal robustness to agent or resource removal, highlighting both the resilience and decentralizability of the learned policies.",
      "authors": [
        "Aymen Khouja",
        "Imen Jendoubi",
        "Oumayma Mahjoub",
        "Oussama Mahfoudhi",
        "Claude Formanek",
        "Siddarth Singh",
        "Ruan De Kock"
      ],
      "url": "https://arxiv.org/abs/2602.19223",
      "published": "2026-02-22T15:14:45+00:00",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "id": "2602.19219",
      "title": "Controlled Face Manipulation and Synthesis for Data Augmentation",
      "abstract": "Deep learning vision models excel with abundant supervision, but many applications face label scarcity and class imbalance. Controllable image editing can augment scarce labeled data, yet edits often introduce artifacts and entangle non-target attributes. We study this in facial expression analysis, targeting Action Unit (AU) manipulation where annotation is costly and AU co-activation drives entanglement. We present a facial manipulation method that operates in the semantic latent space of a pre-trained face generator (Diffusion Autoencoder). Using lightweight linear models, we reduce entanglement of semantic features via (i) dependency-aware conditioning that accounts for AU co-activation, and (ii) orthogonal projection that removes nuisance attribute directions (e.g., glasses), together with an expression neutralization step to enable absolute AU edit. We use these edits to balance AU occurrence by editing labeled faces and to diversify identities/demographics via controlled synthesis. Augmenting AU detector training with the generated data improves accuracy and yields more disentangled predictions with fewer co-activation shortcuts, outperforming alternative data-efficient training strategies and suggesting improvements similar to what would require substantially more labeled data in our learning-curve analysis. Compared to prior methods, our edits are stronger, produce fewer artifacts, and preserve identity better.",
      "authors": [
        "Joris Kirchner",
        "Amogh Gudi",
        "Marian Bittner",
        "Chirag Raman"
      ],
      "url": "https://arxiv.org/abs/2602.19219",
      "published": "2026-02-22T15:03:06+00:00",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    }
  ]
}
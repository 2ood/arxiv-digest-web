{
  "date": "2026-02-21",
  "fetched_at": "2026-02-27T09:27:20.979728+09:00",
  "papers": [
    {
      "id": "2602.18858",
      "title": "Hyperbolic Busemann Neural Networks",
      "abstract": "Hyperbolic spaces provide a natural geometry for representing hierarchical and tree-structured data due to their exponential volume growth. To leverage these benefits, neural networks require intrinsic and efficient components that operate directly in hyperbolic space. In this work, we lift two core components of neural networks, Multinomial Logistic Regression (MLR) and Fully Connected (FC) layers, into hyperbolic space via Busemann functions, resulting in Busemann MLR (BMLR) and Busemann FC (BFC) layers with a unified mathematical interpretation. BMLR provides compact parameters, a point-to-horosphere distance interpretation, batch-efficient computation, and a Euclidean limit, while BFC generalizes FC and activation layers with comparable complexity. Experiments on image classification, genome sequence learning, node classification, and link prediction demonstrate improvements in effectiveness and efficiency over prior hyperbolic layers. The code is available at https://github.com/GitZH-Chen/HBNN.",
      "authors": [
        "Ziheng Chen",
        "Bernhard Schölkopf",
        "Nicu Sebe"
      ],
      "url": "https://arxiv.org/abs/2602.18858",
      "published": "2026-02-21T14:45:40+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "id": "2602.18857",
      "title": "VariBASed: Variational Bayes-Adaptive Sequential Monte-Carlo Planning for Deep Reinforcement Learning",
      "abstract": "Optimally trading-off exploration and exploitation is the holy grail of reinforcement learning as it promises maximal data-efficiency for solving any task. Bayes-optimal agents achieve this, but obtaining the belief-state and performing planning are both typically intractable. Although deep learning methods can greatly help in scaling this computation, existing methods are still costly to train. To accelerate this, this paper proposes a variational framework for learning and planning in Bayes-adaptive Markov decision processes that coalesces variational belief learning, sequential Monte-Carlo planning, and meta-reinforcement learning. In a single-GPU setup, our new method VariBASeD exhibits favorable scaling to larger planning budgets, improving sample- and runtime-efficiency over prior methods.",
      "authors": [
        "Joery A. de Vries",
        "Jinke He",
        "Yaniv Oren",
        "Pascal R. van der Vaart",
        "Mathijs M. de Weerdt",
        "Matthijs T. J. Spaan"
      ],
      "url": "https://arxiv.org/abs/2602.18857",
      "published": "2026-02-21T14:41:11+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18856",
      "title": "Issues with Measuring Task Complexity via Random Policies in Robotic Tasks",
      "abstract": "Reinforcement learning (RL) has enabled major advances in fields such as robotics and natural language processing. A key challenge in RL is measuring task complexity, which is essential for creating meaningful benchmarks and designing effective curricula. While there are numerous well-established metrics for assessing task complexity in tabular settings, relatively few exist in non-tabular domains. These include (i) Statistical analysis of the performance of random policies via Random Weight Guessing (RWG), and (ii) information-theoretic metrics Policy Information Capacity (PIC) and Policy-Optimal Information Capacity (POIC), which are reliant on RWG. In this paper, we evaluate these methods using progressively difficult robotic manipulation setups, with known relative complexity, with both dense and sparse reward formulations. Our empirical results reveal that measuring complexity is still nuanced. Specifically, under the same reward formulation, PIC suggests that a two-link robotic arm setup is easier than a single-link setup - which contradicts the robotic control and empirical RL perspective whereby the two-link setup is inherently more complex. Likewise, for the same setup, POIC estimates that tasks with sparse rewards are easier than those with dense rewards. Thus, we show that both PIC and POIC contradict typical understanding and empirical results from RL. These findings highlight the need to move beyond RWG-based metrics towards better metrics that can more reliably capture task complexity in non-tabular RL with our task framework as a starting point.",
      "authors": [
        "Reabetswe M. Nkhumise",
        "Mohamed S. Talamali",
        "Aditya Gilra"
      ],
      "url": "https://arxiv.org/abs/2602.18856",
      "published": "2026-02-21T14:38:02+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18851",
      "title": "Rank-Aware Spectral Bounds on Attention Logits for Stable Low-Precision Training",
      "abstract": "Attention scores in transformers are bilinear forms $S_{ij} = x_i^\\top M x_j / \\sqrt{d_h}$ whose maximum magnitude governs overflow risk in low-precision training. We derive a \\emph{rank-aware concentration inequality}: when the interaction matrix $M = W^Q W^{K\\top}$ has rank $r \\ll d$, tail probabilities for $\\max_{i,j}|S_{ij}|$ decay as $\\exp(-d^{2}α^{2}/(γr))$ rather than $\\exp(-dα^{2})$, where $γ> 1$ is a typicality parameter. For transformer attention where $r = d_h$, this yields $8$--$28\\times$ tighter concentration than rank-agnostic bounds in modern architectures. We apply this result to FP8 training, deriving \\emph{geometry-aware scale factors} that provide principled overflow guarantees without observing activations. The method computes per-layer scales from the spectral norm $\\|W^Q W^{K\\top}\\|_2$ via implicit power iteration, includes a grouped query attention formulation that avoids key expansion, and remains compatible with fused attention kernels. Across GPT-2 XL to Llama-2-70B, geometry-aware scaling eliminates overflows in transient scenarios where delayed scaling fails, while achieving comparable downstream MMLU accuracy.",
      "authors": [
        "Seyed Morteza Emadi"
      ],
      "url": "https://arxiv.org/abs/2602.18851",
      "published": "2026-02-21T14:29:22+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18850",
      "title": "When the Inference Meets the Explicitness or Why Multimodality Can Make Us Forget About the Perfect Predictor",
      "abstract": "Although in the literature it is common to find predictors and inference systems that try to predict human intentions, the uncertainty of these models due to the randomness of human behavior has led some authors to start advocating the use of communication systems that explicitly elicit human intention. In this work, it is analyzed the use of four different communication systems with a human-robot collaborative object transportation task as experimental testbed: two intention predictors (one based on force prediction and another with an enhanced velocity prediction algorithm) and two explicit communication methods (a button interface and a voice-command recognition system). These systems were integrated into IVO, a custom mobile social robot equipped with force sensor to detect the force exchange between both agents and LiDAR to detect the environment. The collaborative task required transporting an object over a 5-7 meter distance with obstacles in the middle, demanding rapid decisions and precise physical coordination. 75 volunteers perform a total of 255 executions divided into three groups, testing inference systems in the first round, communication systems in the second, and the combined strategies in the third. The results show that, 1) once sufficient performance is achieved, the human no longer notices and positively assesses technical improvements; 2) the human prefers systems that are more natural to them even though they have higher failure rates; and 3) the preferred option is the right combination of both systems.",
      "authors": [
        "J. E. Domínguez-Vidal",
        "Alberto Sanfeliu"
      ],
      "url": "https://arxiv.org/abs/2602.18850",
      "published": "2026-02-21T14:27:10+00:00",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18849",
      "title": "Exact Attention Sensitivity and the Geometry of Transformer Stability",
      "abstract": "Despite powering modern AI, transformers remain mysteriously brittle to train. We develop a stability theory that explains why pre-LayerNorm works, why DeepNorm uses $N^{-1/4}$ scaling, and why warmup is necessary, all from first principles. Our framework has two pillars: (1) We derive the \\emph{exact} operator norm of the softmax Jacobian, $\\|J_{softmax}(u/τ)\\|_{\\infty\\to 1} = θ(p)/τ$, where the balanced-mass factor $θ(p)\\in[0,1]$ quantifies attention sensitivity. (2) We introduce a block-$\\infty$/RMS geometry aligned with tokenwise computation, yielding Lipschitz bounds independent of sequence length. Using this framework, we prove that pre-LN preserves identity gradient paths while post-LN compounds LayerNorm Jacobians exponentially with depth, and we show that DeepNorm's $N^{-1/4}$ emerges from the quartic structure of attention's four projection matrices. We validate our theory on 774M-parameter models and find that, contrary to the intuition that attention sharpens during training to reduce sensitivity, $θ(p) \\approx 1$ persists throughout. Transformer stability arises entirely from architectural gradient flow, not from attention dynamics. This finding changes how we reason about training: the architecture itself must handle sensitivity, not learned attention patterns.",
      "authors": [
        "Seyed Morteza Emadi"
      ],
      "url": "https://arxiv.org/abs/2602.18849",
      "published": "2026-02-21T14:25:24+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18846",
      "title": "DUET-VLM: Dual stage Unified Efficient Token reduction for VLM Training and Inference",
      "abstract": "Vision-language models (VLMs) have achieved remarkable multimodal understanding and reasoning capabilities, yet remain computationally expensive due to dense visual tokenization. Existing efficiency approaches either merge redundant visual tokens or drop them progressively in language backbone, often trading accuracy for speed. In this work, we propose DUET-VLM, a versatile plug-and-play dual compression framework that consists of (a) vision-only redundancy aware compression of vision encoder's output into information-preserving tokens, followed by (b) layer-wise, salient text-guided dropping of visual tokens within the language backbone to progressively prune less informative tokens. This coordinated token management enables aggressive compression while retaining critical semantics. On LLaVA-1.5-7B, our approach maintains over 99% of baseline accuracy with 67% fewer tokens, and still retains >97% even at 89% reduction. With this dual-stage compression during training, it achieves 99.7% accuracy at 67% and 97.6% at 89%, surpassing prior SoTA visual token reduction methods across multiple benchmarks. When integrated into Video-LLaVA-7B, it even surpasses the baseline -- achieving >100% accuracy with a substantial 53.1% token reduction and retaining 97.6% accuracy under an extreme 93.4% setting. These results highlight end-to-end training with DUET-VLM, enabling robust adaptation to reduced visual (image/video) input without sacrificing accuracy, producing compact yet semantically rich representations within the same computational budget. Our code is available at https://github.com/AMD-AGI/DUET-VLM.",
      "authors": [
        "Aditya Kumar Singh",
        "Hitesh Kandala",
        "Pratik Prabhanjan Brahma",
        "Zicheng Liu",
        "Emad Barsoum"
      ],
      "url": "https://arxiv.org/abs/2602.18846",
      "published": "2026-02-21T14:22:49+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18844",
      "title": "When Agda met Vampire",
      "abstract": "Dependently-typed proof assistants furnish expressive foundations for mechanised mathematics and verified software. However, automation for these systems has been either modest in scope or complex in implementation. We aim to improve the situation by integrating proof assistants with automated theorem provers (ATPs) in a simple way, while preserving the correctness guarantees of the former. A central difficulty arises from the fact that most ATPs operate in classical first-order logic, whereas these proof assistants are grounded in constructive dependent type theory. We identify an expressive fragment of both languages -- essentially equational Horn -- that admits sound, straightforward translations in both directions. The approach produces a prototype system for Agda forwarding proof obligations to the ATP Vampire, then transforming the resulting classical proof into a constructive proof term that Agda can type-check. The prototype automatically derives proofs concerning the properties of a complex field equipped with roots of unity, which took professional Agda developers two full days to complete. The required engineering effort is modest, and we anticipate that the methodology will extend readily to other ATPs and proof assistants.",
      "authors": [
        "Artjoms Šinkarovs",
        "Michael Rawson"
      ],
      "url": "https://arxiv.org/abs/2602.18844",
      "published": "2026-02-21T14:19:56+00:00",
      "categories": [
        "cs.LO",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18843",
      "title": "ABD: Default Exception Abduction in Finite First Order Worlds",
      "abstract": "We introduce ABD, a benchmark for default-exception abduction over finite first-order worlds. Given a background theory with an abnormality predicate and a set of relational structures, a model must output a first-order formula that defines exceptions, restoring satisfiability while keeping exceptions sparse. We formalize three observation regimes (closed-world, existential completion, universal completion) with exact SMT verification. Evaluating ten frontier LLMs on 600 instances, the best models achieve high validity but parsimony gaps remain, and holdout evaluation reveals distinct generalization failure modes across regimes.",
      "authors": [
        "Serafim Batzoglou"
      ],
      "url": "https://arxiv.org/abs/2602.18843",
      "published": "2026-02-21T14:14:35+00:00",
      "categories": [
        "cs.AI",
        "cs.SC"
      ]
    },
    {
      "id": "2602.18837",
      "title": "L2G-Net: Local to Global Spectral Graph Neural Networks via Cauchy Factorizations",
      "abstract": "Despite their theoretical advantages, spectral methods based on the graph Fourier transform (GFT) are seldom used in graph neural networks (GNNs) due to the cost of computing the eigenbasis and the lack of vertex-domain locality in spectral representations. As a result, most GNNs rely on local approximations such as polynomial Laplacian filters or message passing, which limit their ability to model long-range dependencies. In this paper, we introduce a novel factorization of the GFT into operators acting on subgraphs, which are then combined via a sequence of Cauchy matrices. We use this factorization to propose a new class of spectral GNNs, which we term L2G-Net (Local-to-Global Net). Unlike existing spectral methods, which are either fully global (when they use the GFT) or local (when they use polynomial filters), L2G-Net operates by processing the spectral representations of subgraphs and then combining them via structured matrices. Our algorithm avoids full eigendecompositions, exploiting graph topology to construct the factorization with quadratic complexity in the number of nodes, scaled by the subgraph interface size. Experiments on benchmarks stressing non-local dependencies show that L2G-Net outperforms existing spectral techniques and is competitive with the state-of-the-art with orders of magnitude fewer learnable parameters.",
      "authors": [
        "Samuel Fernández-Menduiña",
        "Eduardo Pavez",
        "Antonio Ortega"
      ],
      "url": "https://arxiv.org/abs/2602.18837",
      "published": "2026-02-21T13:53:36+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18832",
      "title": "OpenClaw AI Agents as Informal Learners at Moltbook: Characterizing an Emergent Learning Community at Scale",
      "abstract": "Informal learning communities have been called the \"other Massive Open Online C\" in Learning@Scale research, yet remain understudied compared to MOOCs. We present the first empirical study of a large-scale informal learning community composed entirely of AI agents. Moltbook, a social network exclusively for AI agents powered by autonomous agent frameworks such as OpenClaw, grew to over 2.8 million registered agents in three weeks. Analyzing 231,080 non-spam posts across three phases of community evolution, we find three key patterns. First, participation inequality is extreme from the start (comment Gini = 0.889), exceeding human community benchmarks. Second, AI agents exhibit a \"broadcasting inversion\": statement-to-question ratios of 8.9:1 to 9.7:1 contrast sharply with the question-driven dynamics of human learning communities, and comment-level analysis of 1.55 million comments reveals a \"parallel monologue\" pattern where 93% of comments are independent responses rather than threaded dialogue. Third, we document a characteristic engagement lifecycle: explosive initial growth (184K posts from 32K authors in 11 days), a spam crisis (57,093 posts deleted by the platform), and engagement decline (mean comments: 31.7 -> 8.3 -> 1.7) that had not reversed by the end of our observation window despite effective spam removal. Sentiment analysis reveals a selection effect: comment tone becomes more positive as engagement declines, suggesting that casual participants disengage first while committed contributors remain. These findings have direct implications for hybrid human-AI learning platforms.",
      "authors": [
        "Eason Chen",
        "Ce Guan",
        "Ahmed Elshafiey",
        "Zhonghao Zhao",
        "Joshua Zekeri",
        "Afeez Edeifo Shaibu",
        "Emmanuel Osadebe Prince",
        "Cyuan Jhen Wu"
      ],
      "url": "https://arxiv.org/abs/2602.18832",
      "published": "2026-02-21T13:30:32+00:00",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ]
    },
    {
      "id": "2602.18825",
      "title": "Bayesian Lottery Ticket Hypothesis",
      "abstract": "Bayesian neural networks (BNNs) are a useful tool for uncertainty quantification, but require substantially more computational resources than conventional neural networks. For non-Bayesian networks, the Lottery Ticket Hypothesis (LTH) posits the existence of sparse subnetworks that can train to the same or even surpassing accuracy as the original dense network. Such sparse networks can lower the demand for computational resources at inference, and during training. The existence of the LTH and corresponding sparse subnetworks in BNNs could motivate the development of sparse training algorithms and provide valuable insights into the underlying training process. Towards this end, we translate the LTH experiments to a Bayesian setting using common computer vision models. We investigate the defining characteristics of Bayesian lottery tickets, and extend our study towards a transplantation method connecting BNNs with deterministic Lottery Tickets. We generally find that the LTH holds in BNNs, and winning tickets of matching and surpassing accuracy are present independent of model size, with degradation at very high sparsities. However, the pruning strategy should rely primarily on magnitude, secondly on standard deviation. Furthermore, our results demonstrate that models rely on mask structure and weight initialization to varying degrees.",
      "authors": [
        "Nicholas Kuhn",
        "Arvid Weyrauch",
        "Lars Heyen",
        "Achim Streit",
        "Markus Götz",
        "Charlotte Debus"
      ],
      "url": "https://arxiv.org/abs/2602.18825",
      "published": "2026-02-21T12:52:20+00:00",
      "categories": [
        "cs.LG",
        "cs.CV"
      ]
    },
    {
      "id": "2602.18824",
      "title": "UniRank: A Multi-Agent Calibration Pipeline for Estimating University Rankings from Anonymized Bibliometric Signals",
      "abstract": "We present UniRank, a multi-agent LLM pipeline that estimates university positions across global ranking systems using only publicly available bibliometric data from OpenAlex and Semantic Scholar. The system employs a three-stage architecture: (a) zero-shot estimation from anonymized institutional metrics, (b) per-system tool-augmented calibration against real ranked universities, and (c) final synthesis. Critically, institutions are anonymized -- names, countries, DOIs, paper titles, and collaboration countries are all redacted -- and their actual ranks are hidden from the calibration tools during evaluation, preventing LLM memorization from confounding results. On the Times Higher Education (THE) World University Rankings ($n=352$), the system achieves MAE = 251.5 rank positions, Median AE = 131.5, PNMAE = 12.03%, Spearman $ρ= 0.769$, Kendall $τ= 0.591$, hit rate @50 = 20.7%, hit rate @100 = 39.8%, and a Memorization Index of exactly zero (no exact-match zero-width predictions among all 352 universities). The systematic positive-signed error (+190.1 positions, indicating the system consistently predicts worse ranks than actual) and monotonic performance degradation from elite tier (MAE = 60.5, hit@100 = 90.5%) to tail tier (MAE = 328.2, hit@100 = 20.8%) provide strong evidence that the pipeline performs genuine analytical reasoning rather than recalling memorized rankings. A live demo is available at https://unirank.scinito.ai .",
      "authors": [
        "Pedram Riyazimehr",
        "Seyyed Ehsan Mahmoudi"
      ],
      "url": "https://arxiv.org/abs/2602.18824",
      "published": "2026-02-21T12:50:55+00:00",
      "categories": [
        "cs.SI",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18823",
      "title": "EvalSense: A Framework for Domain-Specific LLM (Meta-)Evaluation",
      "abstract": "Robust and comprehensive evaluation of large language models (LLMs) is essential for identifying effective LLM system configurations and mitigating risks associated with deploying LLMs in sensitive domains. However, traditional statistical metrics are poorly suited to open-ended generation tasks, leading to growing reliance on LLM-based evaluation methods. These methods, while often more flexible, introduce additional complexity: they depend on carefully chosen models, prompts, parameters, and evaluation strategies, making the evaluation process prone to misconfiguration and bias. In this work, we present EvalSense, a flexible, extensible framework for constructing domain-specific evaluation suites for LLMs. EvalSense provides out-of-the-box support for a broad range of model providers and evaluation strategies, and assists users in selecting and deploying suitable evaluation methods for their specific use-cases. This is achieved through two unique components: (1) an interactive guide aiding users in evaluation method selection and (2) automated meta-evaluation tools that assess the reliability of different evaluation approaches using perturbed data. We demonstrate the effectiveness of EvalSense in a case study involving the generation of clinical notes from unstructured doctor-patient dialogues, using a popular open dataset. All code, documentation, and assets associated with EvalSense are open-source and publicly available at https://github.com/nhsengland/evalsense.",
      "authors": [
        "Adam Dejl",
        "Jonathan Pearson"
      ],
      "url": "https://arxiv.org/abs/2602.18823",
      "published": "2026-02-21T12:50:43+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.18813",
      "title": "Habilis-$β$: A Fast-Motion and Long-Lasting On-Device Vision-Language-Action Model",
      "abstract": "We introduce Habilis-$β$, a fast-motion and long-lasting on-device vision-language-action (VLA) model designed for real-world deployment. Current VLA evaluation remains largely confined to single-trial success rates under curated resets, which fails to capture the fast-motion and long-lasting capabilities essential for practical operation. To address this, we introduce the Productivity-Reliability Plane (PRP), which evaluates performance through Tasks per Hour (TPH) and Mean Time Between Intervention (MTBI) under a continuous-run protocol that demands both high-speed execution and sustained robustness. Habilis-$β$ achieves high performance by integrating language-free pre-training on large-scale play data for robust interaction priors with post-training on cyclic task demonstrations that capture state drift across consecutive task iterations. The system further employs ESPADA for phase-adaptive motion shaping to accelerate free-space transit, utilizes rectified-flow distillation to enable high-frequency control on edge devices, and incorporates classifier-free guidance (CFG) as a deployment-time knob to dynamically balance instruction adherence and learned interaction priors. In 1-hour continuous-run evaluations, Habilis-$β$ achieves strong performance under the PRP metrics, compared to $π_{0.5}$ in both simulation and real-world environments. In simulation, Habilis-$β$ achieves 572.6 TPH and 39.2 s MTBI (vs. 120.5 TPH and 30.5 s for $π_{0.5}$), while in a real-world humanoid logistics workflow it achieves 124 TPH and 137.4 s MTBI (vs. 19 TPH and 46.1 s for $π_{0.5}$). Finally, Habilis-$β$ achieves the highest reported performance on the standard RoboTwin 2.0 leaderboard across representative tasks, validating its effectiveness in complex manipulation scenarios.",
      "authors": [
        "Tommoro Robotics",
        ":",
        "Jesoon Kang",
        "Taegeon Park",
        "Jisu An",
        "Soo Min Kimm",
        "Jaejoon Kim",
        "Jinu Pahk",
        "Byungju Kim",
        "Junseok Lee",
        "Namheon Baek",
        "Sungwan Ha",
        "Hojun Baek",
        "Eduardo Ayerve Cruz",
        "Wontae Kim",
        "Junghyeon Choi",
        "Yousuk Lee",
        "Joonmo Han",
        "Sunghyun Cho",
        "Sunghyun Kwon",
        "Soyoung Lee",
        "Jun Ki Lee",
        "Seung-Joon Yi",
        "Byoung-Tak Zhang",
        "Theo Taeyeong Kim"
      ],
      "url": "https://arxiv.org/abs/2602.18813",
      "published": "2026-02-21T12:15:49+00:00",
      "categories": [
        "cs.RO",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18812",
      "title": "GenPlanner: From Noise to Plans -- Emergent Reasoning in Flow Matching and Diffusion Models",
      "abstract": "Path planning in complex environments is one of the key problems of artificial intelligence because it requires simultaneous understanding of the geometry of space and the global structure of the problem. In this paper, we explore the potential of using generative models as planning and reasoning mechanisms. We propose GenPlanner, an approach based on diffusion models and flow matching, along with two variants: DiffPlanner and FlowPlanner. We demonstrate the application of generative models to find and generate correct paths in mazes. A multi-channel condition describing the structure of the environment, including an obstacle map and information about the starting and destination points, is used to condition trajectory generation. Unlike standard methods, our models generate trajectories iteratively, starting with random noise and gradually transforming it into a correct solution. Experiments conducted show that the proposed approach significantly outperforms the baseline CNN model. In particular, FlowPlanner demonstrates high performance even with a limited number of generation steps.",
      "authors": [
        "Agnieszka Polowczyk",
        "Alicja Polowczyk",
        "Michał Wieczorek"
      ],
      "url": "https://arxiv.org/abs/2602.18812",
      "published": "2026-02-21T12:12:45+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.18807",
      "title": "Chat-Based Support Alone May Not Be Enough: Comparing Conversational and Embedded LLM Feedback for Mathematical Proof Learning",
      "abstract": "We evaluate GPTutor, an LLM-powered tutoring system for an undergraduate discrete mathematics course. It integrates two LLM-supported tools: a structured proof-review tool that provides embedded feedback on students' written proof attempts, and a chatbot for math questions. In a staggered-access study with 148 students, earlier access was associated with higher homework performance during the interval when only the experimental group could use the system, while we did not observe this performance increase transfer to exam scores. Usage logs show that students with lower self-efficacy and prior exam performance used both components more frequently. Session-level behavioral labels, produced by human coding and scaled using an automated classifier, characterize how students engaged with the chatbot (e.g., answer-seeking or help-seeking). In models controlling for prior performance and self-efficacy, higher chatbot usage and answer-seeking behavior were negatively associated with subsequent midterm performance, whereas proof-review usage showed no detectable independent association. Together, the findings suggest that chatbot-based support alone may not reliably support transfer to independent assessment of math proof-learning outcomes, whereas work-anchored, structured feedback appears less associated with reduced learning.",
      "authors": [
        "Eason Chen",
        "Sophia Judicke",
        "Kayla Beigh",
        "Xinyi Tang",
        "Isabel Wang",
        "Nina Yuan",
        "Zimo Xiao",
        "Chuangji Li",
        "Shizhuo Li",
        "Reed Luttmer",
        "Shreya Singh",
        "Maria Yampolsky",
        "Naman Parikh",
        "Yvonne Zhao",
        "Meiyi Chen",
        "Scarlett Huang",
        "Anishka Mohanty",
        "Gregory Johnson",
        "John Mackey",
        "Jionghao Lin",
        "Ken Koedinger"
      ],
      "url": "https://arxiv.org/abs/2602.18807",
      "published": "2026-02-21T11:52:25+00:00",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "id": "2602.18806",
      "title": "Think$^{2}$: Grounded Metacognitive Reasoning in Large Language Models",
      "abstract": "Large Language Models (LLMs) demonstrate strong reasoning performance, yet their ability to reliably monitor, diagnose, and correct their own errors remains limited. We introduce a psychologically grounded metacognitive framework that operationalizes Ann Brown's regulatory cycle (Planning, Monitoring, and Evaluation) as a structured prompting architecture, and study its integration within a lightweight dual-process MetaController for adaptive effort allocation. Across diverse reasoning and diagnostic benchmarks (GSM8K, CRUXEval, MBPP, AIME, CorrectBench, and TruthfulQA) using Llama-3 and Qwen-3 (8B), explicit regulatory structuring substantially improves error diagnosis and yields a threefold increase in successful self-correction. Blinded human evaluations over 580 query pairs show an 84% aggregate preference for trustworthiness and metacognitive self-awareness over standard and Chain-of-Thought baselines. Grounding LLM reasoning in established cognitive theory offers a principled path toward more transparent and diagnostically robust AI systems.",
      "authors": [
        "Abraham Paul Elenjical",
        "Vivek Hruday Kavuri",
        "Vasudeva Varma"
      ],
      "url": "https://arxiv.org/abs/2602.18806",
      "published": "2026-02-21T11:45:12+00:00",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18801",
      "title": "SGNO: Spectral Generator Neural Operators for Stable Long Horizon PDE Rollouts",
      "abstract": "Neural operators provide fast PDE surrogates and often generalize across parameters and resolutions. However, in the short train long test setting, autoregressive rollouts can become unstable. This typically happens for two reasons: one step errors accumulate over time, and high frequency components feed back and grow.   We introduce the Spectral Generator Neural Operator (SGNO), a residual time stepper that targets both effects. For the linear part, SGNO uses an exponential time differencing update in Fourier space with a learned diagonal generator. We constrain the real part of this generator to be nonpositive, so iterating the step does not amplify the linear dynamics. For nonlinear dynamics, SGNO adds a gated forcing term with channel mixing within each Fourier mode, which keeps the nonlinear update controlled. To further limit high frequency feedback, SGNO applies spectral truncation and an optional smooth mask on the forcing pathway.   We derive a one step amplification bound and a finite horizon rollout error bound. The bound separates generator approximation error from nonlinear mismatch and gives sufficient conditions under which the latent $L^2$ norm does not grow across rollout steps. On APEBench spanning 1D, 2D, and 3D PDE families, SGNO achieves lower long horizon error and longer stable rollout lengths than strong neural operator baselines. Ablations confirm the roles of the generator constraint, gating, and filtering.The code is available at https://github.com/lijy32123-cloud/SGNO.",
      "authors": [
        "Jiayi Li",
        "Zhaonan Wang",
        "Flora D. Salim"
      ],
      "url": "https://arxiv.org/abs/2602.18801",
      "published": "2026-02-21T11:22:01+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18800",
      "title": "Operational Robustness of LLMs on Code Generation",
      "abstract": "It is now common practice in software development for large language models (LLMs) to be used to generate program code. It is desirable to evaluate the robustness of LLMs for this usage. This paper is concerned in particular with how sensitive LLMs are to variations in descriptions of the coding tasks. However, existing techniques for evaluating this robustness are unsuitable for code generation because the input data space of natural language descriptions is discrete. To address this problem, we propose a robustness evaluation method called scenario domain analysis, which aims to find the expected minimal change in the natural language descriptions of coding tasks that would cause the LLMs to produce incorrect outputs. We have formally proved the theoretical properties of the method and also conducted extensive experiments to evaluate the robustness of four state-of-the-art art LLMs: Gemini-pro, Codex, Llamma2 and Falcon 7B, and have found that we are able to rank these with confidence from best to worst. Moreover, we have also studied how robustness varies in different scenarios, including the variations with the topic of the coding task and with the complexity of its sample solution, and found that robustness is lower for more complex tasks and also lower for more advanced topics, such as multi-threading and data structures.",
      "authors": [
        "Debalina Ghosh Paul",
        "Hong Zhu",
        "Ian Bayley"
      ],
      "url": "https://arxiv.org/abs/2602.18800",
      "published": "2026-02-21T11:21:13+00:00",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18797",
      "title": "Carbon-aware decentralized dynamic task offloading in MIMO-MEC networks via multi-agent reinforcement learning",
      "abstract": "Massive internet of things microservices require integrating renewable energy harvesting into mobile edge computing (MEC) for sustainable eScience infrastructures. Spatiotemporal mismatches between stochastic task arrivals and intermittent green energy along with complex inter-user interference in multi-antenna (MIMO) uplinks complicate real-time resource management. Traditional centralized optimization and off-policy reinforcement learning struggle with scalability and signaling overhead in dense networks. This paper proposes CADDTO-PPO, a carbon-aware decentralized dynamic task offloading framework based on multi-agent proximal policy optimization. The multi-user MIMO-MEC system is modeled as a Decentralized Partially Observable Markov Decision Process (DEC-POMDP) to jointly minimize carbon emissions and buffer latency and energy wastage. A scalable architecture utilizes decentralized execution with parameter sharing (DEPS), which enables autonomous IoT agents to make fine-grained power control and offloading decisions based solely on local observations. Additionally, a carbon-first reward structure adaptively prioritizes green time slots for data transmission to decouple system throughput from grid-dependent carbon footprints. Finally, experimental results demonstrate CADDTO-PPO outperforms deep deterministic policy gradient (DDPG) and lyapunov-based baselines. The framework achieves the lowest carbon intensity and maintains near-zero packet overflow rates under extreme traffic loads. Architectural profiling validates the framework to demonstrate a constant $O(1)$ inference complexity and theoretical lightweight feasibility for future generation sustainable IoT deployments.",
      "authors": [
        "Mubshra Zulfiqar",
        "Muhammad Ayzed Mirza",
        "Basit Qureshi"
      ],
      "url": "https://arxiv.org/abs/2602.18797",
      "published": "2026-02-21T11:07:11+00:00",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18795",
      "title": "Vectorized Bayesian Inference for Latent Dirichlet-Tree Allocation",
      "abstract": "Latent Dirichlet Allocation (LDA) is a foundational model for discovering latent thematic structure in discrete data, but its Dirichlet prior cannot represent the rich correlations and hierarchical relationships often present among topics. We introduce the framework of Latent Dirichlet-Tree Allocation (LDTA), a generalization of LDA that replaces the Dirichlet prior with an arbitrary Dirichlet-Tree (DT) distribution. LDTA preserves LDA's generative structure but enables expressive, tree-structured priors over topic proportions. To perform inference, we develop universal mean-field variational inference and Expectation Propagation, providing tractable updates for all DT. We reveal the vectorized nature of the two inference methods through theoretical development, and perform fully vectorized, GPU-accelerated implementations. The resulting framework substantially expands the modeling capacity of LDA while maintaining scalability and computational efficiency.",
      "authors": [
        "Zheng Wang",
        "Nizar Bouguila"
      ],
      "url": "https://arxiv.org/abs/2602.18795",
      "published": "2026-02-21T11:00:34+00:00",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "id": "2602.18793",
      "title": "From Few-Shot to Zero-Shot: Towards Generalist Graph Anomaly Detection",
      "abstract": "Graph anomaly detection (GAD) is critical for identifying abnormal nodes in graph-structured data from diverse domains, including cybersecurity and social networks. The existing GAD methods often focus on the learning paradigms of \"one-model-for-one-dataset\", requiring dataset-specific training for each dataset to achieve optimal performance. However, this paradigm suffers from significant limitations, such as high computational and data costs, limited generalization and transferability to new datasets, and challenges in privacy-sensitive scenarios where access to full datasets or sufficient labels is restricted. To address these limitations, we propose a novel generalist GAD paradigm that aims to develop a unified model capable of detecting anomalies on multiple unseen datasets without extensive retraining/fine-tuning or dataset-specific customization. To this end, we propose ARC, a few-shot generalist GAD method that leverages in-context learning and requires only a few labeled normal samples at inference time. Specifically, ARC consists of three core modules: a feature Alignment module to unify and align features across datasets, a Residual GNN encoder to capture dataset-agnostic anomaly representations, and a cross-attentive in-Context learning module to score anomalies using few-shot normal context. Building on ARC, we further introduce ARC_zero for the zero-shot generalist GAD setting, which selects representative pseudo-normal nodes via a pseudo-context mechanism and thus enables fully label-free inference on unseen datasets. Extensive experiments on 17 real-world graph datasets demonstrate that both ARC and ARC_zero effectively detect anomalies, exhibit strong generalization ability, and perform efficiently under few-shot and zero-shot settings.",
      "authors": [
        "Yixin Liu",
        "Shiyuan Li",
        "Yu Zheng",
        "Qingfeng Chen",
        "Chengqi Zhang",
        "Philip S. Yu",
        "Shirui Pan"
      ],
      "url": "https://arxiv.org/abs/2602.18793",
      "published": "2026-02-21T10:59:00+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18788",
      "title": "BURMESE-SAN: Burmese NLP Benchmark for Evaluating Large Language Models",
      "abstract": "We introduce BURMESE-SAN, the first holistic benchmark that systematically evaluates large language models (LLMs) for Burmese across three core NLP competencies: understanding (NLU), reasoning (NLR), and generation (NLG). BURMESE-SAN consolidates seven subtasks spanning these competencies, including Question Answering, Sentiment Analysis, Toxicity Detection, Causal Reasoning, Natural Language Inference, Abstractive Summarization, and Machine Translation, several of which were previously unavailable for Burmese. The benchmark is constructed through a rigorous native-speaker-driven process to ensure linguistic naturalness, fluency, and cultural authenticity while minimizing translation-induced artifacts. We conduct a large-scale evaluation of both open-weight and commercial LLMs to examine challenges in Burmese modeling arising from limited pretraining coverage, rich morphology, and syntactic variation. Our results show that Burmese performance depends more on architectural design, language representation, and instruction tuning than on model scale alone. In particular, Southeast Asia regional fine-tuning and newer model generations yield substantial gains. Finally, we release BURMESE-SAN as a public leaderboard to support systematic evaluation and sustained progress in Burmese and other low-resource languages. https://leaderboard.sea-lion.ai/detailed/MY",
      "authors": [
        "Thura Aung",
        "Jann Railey Montalan",
        "Jian Gang Ngui",
        "Peerat Limkonchotiwat"
      ],
      "url": "https://arxiv.org/abs/2602.18788",
      "published": "2026-02-21T10:43:07+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.18786",
      "title": "CaliCausalRank: Calibrated Multi-Objective Ad Ranking with Robust Counterfactual Utility Optimization",
      "abstract": "Ad ranking systems must simultaneously optimize multiple objectives including click-through rate (CTR), conversion rate (CVR), revenue, and user experience metrics. However, production systems face critical challenges: score scale inconsistency across traffic segments undermines threshold transferability, and position bias in click logs causes offline-online metric discrepancies. We propose CaliCausalRank, a unified framework that integrates training-time scale calibration, constraint-based multi-objective optimization, and robust counterfactual utility estimation. Our approach treats score calibration as a first-class training objective rather than post-hoc processing, employs Lagrangian relaxation for constraint satisfaction, and utilizes variance-reduced counterfactual estimators for reliable offline evaluation. Experiments on the Criteo and Avazu datasets demonstrate that CaliCausalRank achieves 1.1% relative AUC improvement, 31.6% calibration error reduction, and 3.2% utility gain compared to the best baseline (PairRank) while maintaining consistent performance across different traffic segments.",
      "authors": [
        "Xikai Yang",
        "Sebastian Sun",
        "Yilin Li",
        "Yue Xing",
        "Ming Wang",
        "Yang Wang"
      ],
      "url": "https://arxiv.org/abs/2602.18786",
      "published": "2026-02-21T10:35:12+00:00",
      "categories": [
        "cs.LG",
        "cs.IR"
      ]
    },
    {
      "id": "2602.18782",
      "title": "MANATEE: Inference-Time Lightweight Diffusion Based Safety Defense for LLMs",
      "abstract": "Defending LLMs against adversarial jailbreak attacks remains an open challenge. Existing defenses rely on binary classifiers that fail when adversarial input falls outside the learned decision boundary, and repeated fine-tuning is computationally expensive while potentially degrading model capabilities. We propose MANATEE, an inference-time defense that uses density estimation over a benign representation manifold. MANATEE learns the score function of benign hidden states and uses diffusion to project anomalous representations toward safe regions--requiring no harmful training data and no architectural modifications. Experiments across Mistral-7B-Instruct, Llama-3.1-8B-Instruct, and Gemma-2-9B-it demonstrate that MANATEE reduce Attack Success Rate by up to 100\\% on certain datasets, while preserving model utility on benign inputs.",
      "authors": [
        "Chun Yan Ryan Kan",
        "Tommy Tran",
        "Vedant Yadav",
        "Ava Cai",
        "Kevin Zhu",
        "Ruizhe Li",
        "Maheep Chaudhary"
      ],
      "url": "https://arxiv.org/abs/2602.18782",
      "published": "2026-02-21T10:17:55+00:00",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18776",
      "title": "ArabicNumBench: Evaluating Arabic Number Reading in Large Language Models",
      "abstract": "We present ArabicNumBench, a comprehensive benchmark for evaluating large language models on Arabic number reading tasks across Eastern Arabic-Indic numerals (0-9 in Arabic script) and Western Arabic numerals (0-9). We evaluate 71 models from 10 providers using four prompting strategies (zero-shot, zero-shot CoT, few-shot, few-shot CoT) on 210 number reading tasks spanning six contextual categories: pure numerals, addresses, dates, quantities, and prices. Our evaluation comprises 59,010 individual test cases and tracks extraction methods to measure structured output generation. Evaluation reveals substantial performance variation, with accuracy ranging from 14.29\\% to 99.05\\% across models and strategies. Few-shot Chain-of-Thought prompting achieves 2.8x higher accuracy than zero-shot approaches (80.06\\% vs 28.76\\%). A striking finding emerges: models achieving elite accuracy (98-99\\%) often produce predominantly unstructured output, with most responses lacking Arabic CoT markers. Only 6 models consistently generate structured output across all test cases, while the majority require fallback extraction methods despite high numerical accuracy. Comprehensive evaluation of 281 model-strategy combinations demonstrates that numerical accuracy and instruction-following represent distinct capabilities, establishing baselines for Arabic number comprehension and providing actionable guidance for model selection in production Arabic NLP systems.",
      "authors": [
        "Anas Alhumud",
        "Abdulaziz Alhammadi",
        "Muhammad Badruddin Khan"
      ],
      "url": "https://arxiv.org/abs/2602.18776",
      "published": "2026-02-21T10:00:56+00:00",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18773",
      "title": "LAMMI-Pathology: A Tool-Centric Bottom-Up LVLM-Agent Framework for Molecularly Informed Medical Intelligence in Pathology",
      "abstract": "The emergence of tool-calling-based agent systems introduces a more evidence-driven paradigm for pathology image analysis in contrast to the coarse-grained text-image diagnostic approaches. With the recent large-scale experimental adoption of spatial transcriptomics technologies, molecularly validated pathological diagnosis is becoming increasingly open and accessible. In this work, we propose LAMMI-Pathology (LVLM-Agent System for Molecularly Informed Medical Intelligence in Pathology), a scalable agent framework for domain-specific agent tool-calling. LAMMI-Pathology adopts a tool-centric, bottom-up architecture in which customized domain-adaptive tools serve as the foundation. These tools are clustered by domain style to form component agents, which are then coordinated through a top-level planner hierarchically, avoiding excessively long context lengths that could induce task drift. Based on that, we introduce a novel trajectory construction mechanism based on Atomic Execution Nodes (AENs), which serve as reliable and composable units for building semi-simulated reasoning trajectories that capture credible agent-tool interactions. Building on this foundation, we develop a trajectory-aware fine-tuning strategy that aligns the planner's decision-making process with these multi-step reasoning trajectories, thereby enhancing inference robustness in pathology understanding and its adaptive use of the customized toolset.",
      "authors": [
        "Haoyang Su",
        "Shaoting Zhang",
        "Xiaosong Wang"
      ],
      "url": "https://arxiv.org/abs/2602.18773",
      "published": "2026-02-21T09:51:32+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.20187",
      "title": "AINet: Anchor Instances Learning for Regional Heterogeneity in Whole Slide Image",
      "abstract": "Recent advances in multi-instance learning (MIL) have witnessed impressive performance in whole slide image (WSI) analysis. However, the inherent sparsity of tumors and their morphological diversity lead to obvious heterogeneity across regions, posing significant challenges in aggregating high-quality and discriminative representations. To address this, we introduce a novel concept of anchor instance (AI), a compact subset of instances that are representative within their regions (local) and discriminative at the bag (global) level. These AIs act as semantic references to guide interactions across regions, correcting non-discriminative patterns while preserving regional diversity. Specifically, we propose a dual-level anchor mining (DAM) module to \\textbf{select} AIs from massive instances, where the most informative AI in each region is extracted by assessing its similarity to both local and global embeddings. Furthermore, to ensure completeness and diversity, we devise an anchor-guided region correction (ARC) module that explores the complementary information from all regions to \\textbf{correct} each regional representation. Building upon DAM and ARC, we develop a concise yet effective framework, AINet, which employs a simple predictor and surpasses state-of-the-art methods with substantially fewer FLOPs and parameters. Moreover, both DAM and ARC are modular and can be seamlessly integrated into existing MIL frameworks, consistently improving their performance.",
      "authors": [
        "Tingting Zheng",
        "Hongxun Yao",
        "Kui Jiang",
        "Sicheng Zhao",
        "Yi Xiao"
      ],
      "url": "https://arxiv.org/abs/2602.20187",
      "published": "2026-02-21T09:36:27+00:00",
      "categories": [
        "eess.IV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18769",
      "title": "GLaDiGAtor: Language-Model-Augmented Multi-Relation Graph Learning for Predicting Disease-Gene Associations",
      "abstract": "Understanding disease-gene associations is essential for unravelling disease mechanisms and advancing diagnostics and therapeutics. Traditional approaches based on manual curation and literature review are labour-intensive and not scalable, prompting the use of machine learning on large biomedical data. In particular, graph neural networks (GNNs) have shown promise for modelling complex biological relationships. To address limitations in existing models, we propose GLaDiGAtor (Graph Learning-bAsed DIsease-Gene AssociaTiOn pRediction), a novel GNN framework with an encoder-decoder architecture for disease-gene association prediction. GLaDiGAtor constructs a heterogeneous biological graph integrating gene-gene, disease-disease, and gene-disease interactions from curated databases, and enriches each node with contextual features from well-known language models (ProtT5 for protein sequences and BioBERT for disease text). In evaluations, our model achieves superior predictive accuracy and generalisation, outperforming 14 existing methods. Literature-supported case studies confirm the biological relevance of high-confidence novel predictions, highlighting GLaDiGAtor's potential to discover candidate disease genes. These results underscore the power of graph convolutional networks in biomedical informatics and may ultimately facilitate drug discovery by revealing new gene-disease links. The source code and processed datasets are publicly available at https://github.com/HUBioDataLab/GLaDiGAtor.",
      "authors": [
        "Osman Onur Kuzucu",
        "Tunca Doğan"
      ],
      "url": "https://arxiv.org/abs/2602.18769",
      "published": "2026-02-21T09:26:44+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18767",
      "title": "Nazrin: Atomic Tactics for Graph Neural Networks for Theorem Proving in Lean 4",
      "abstract": "In Machine-Assisted Theorem Proving, a theorem proving agent searches for a sequence of expressions and tactics that can prove a conjecture in a proof assistant.   In this work, we introduce several novel concepts and capabilities to address obstacles faced by machine-assisted theorem proving. We first present a set of \\textbf{atomic tactics}, a small finite set of tactics capable of proving any provable statement in Lean. We then introduce a \\textbf{transposing atomization} algorithm which turns arbitrary proof expressions into a series of atomic tactics. We next introduce the \\textbf{ExprGraph} data structure, which provides a succinct representation for Lean expressions. Finally, we present the \\textbf{Nazrin Prover}, a graph neural network-based theorem proving agent using atomic tactics and ExprGraph. Nazrin circumvents many challenges faced by existing proving agents by exclusively dispatching atomic tactics, and it is robust enough to both train and evaluate on consumer-grade hardware. We demonstrate the potential of tools like Nazrin using theorems from Lean's standard library and from Mathlib.",
      "authors": [
        "Leni Aniva",
        "Iori Oikawa",
        "David Dill",
        "Clark Barrett"
      ],
      "url": "https://arxiv.org/abs/2602.18767",
      "published": "2026-02-21T09:12:51+00:00",
      "categories": [
        "cs.LO",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18764",
      "title": "The Convergence of Schema-Guided Dialogue Systems and the Model Context Protocol",
      "abstract": "This paper establishes a fundamental convergence: Schema-Guided Dialogue (SGD) and the Model Context Protocol (MCP) represent two manifestations of a unified paradigm for deterministic, auditable LLM-agent interaction. SGD, designed for dialogue-based API discovery (2019), and MCP, now the de facto standard for LLM-tool integration, share the same core insight -- that schemas can encode not just tool signatures but operational constraints and reasoning guidance. By analyzing this convergence, we extract five foundational principles for schema design: (1) Semantic Completeness over Syntactic Precision, (2) Explicit Action Boundaries, (3) Failure Mode Documentation, (4) Progressive Disclosure Compatibility, and (5) Inter-Tool Relationship Declaration. These principles reveal three novel insights: first, SGD's original design was fundamentally sound and should be inherited by MCP; second, both frameworks leave failure modes and inter-tool relationships unexploited -- gaps we identify and resolve; third, progressive disclosure emerges as a critical production-scaling insight under real-world token constraints. We provide concrete design patterns for each principle. These principles position schema-driven governance as a scalable mechanism for AI system oversight without requiring proprietary system inspection -- central to Software 3.0.",
      "authors": [
        "Andreas Schlapbach"
      ],
      "url": "https://arxiv.org/abs/2602.18764",
      "published": "2026-02-21T09:02:35+00:00",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "id": "2602.18763",
      "title": "TAG: Thinking with Action Unit Grounding for Facial Expression Recognition",
      "abstract": "Facial Expression Recognition (FER) is a fine-grained visual understanding task where reliable predictions require reasoning over localized and meaningful facial cues. Recent vision--language models (VLMs) enable natural language explanations for FER, but their reasoning is often ungrounded, producing fluent yet unverifiable rationales that are weakly tied to visual evidence and prone to hallucination, leading to poor robustness across different datasets. We propose TAG (Thinking with Action Unit Grounding), a vision--language framework that explicitly constrains multimodal reasoning to be supported by facial Action Units (AUs). TAG requires intermediate reasoning steps to be grounded in AU-related facial regions, yielding predictions accompanied by verifiable visual evidence. The model is trained via supervised fine-tuning on AU-grounded reasoning traces followed by reinforcement learning with an AU-aware reward that aligns predicted regions with external AU detectors. Evaluated on RAF-DB, FERPlus, and AffectNet, TAG consistently outperforms strong open-source and closed-source VLM baselines while simultaneously improving visual faithfulness. Ablation and preference studies further show that AU-grounded rewards stabilize reasoning and mitigate hallucination, demonstrating the importance of structured grounded intermediate representations for trustworthy multimodal reasoning in FER. The code will be available at https://github.com/would1920/FER_TAG .",
      "authors": [
        "Haobo Lin",
        "Tianyi Bai",
        "Jiajun Zhang",
        "Xuanhao Chang",
        "Sheng Lu",
        "Fangming Gu",
        "Zengjie Hu",
        "Wentao Zhang"
      ],
      "url": "https://arxiv.org/abs/2602.18763",
      "published": "2026-02-21T09:00:52+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18762",
      "title": "Bounds and Identification of Joint Probabilities of Potential Outcomes and Observed Variables under Monotonicity Assumptions",
      "abstract": "Evaluating joint probabilities of potential outcomes and observed variables, and their linear combinations, is a fundamental challenge in causal inference. This paper addresses the bounding and identification of these probabilities in settings with discrete treatment and discrete ordinal outcome. We propose new families of monotonicity assumptions and formulate the bounding problem as a linear programming problem. We further introduce a new monotonicity assumption specifically to achieve identification. Finally, we present numerical experiments to validate our methods and demonstrate their application using real-world datasets.",
      "authors": [
        "Naoya Hashimoto",
        "Yuta Kawakami",
        "Jin Tian"
      ],
      "url": "https://arxiv.org/abs/2602.18762",
      "published": "2026-02-21T09:00:18+00:00",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18759",
      "title": "Towards Reliable Negative Sampling for Recommendation with Implicit Feedback via In-Community Popularity",
      "abstract": "Learning from implicit feedback is a fundamental problem in modern recommender systems, where only positive interactions are observed and explicit negative signals are unavailable. In such settings, negative sampling plays a critical role in model training by constructing negative items that enable effective preference learning and ranking optimization. However, designing reliable negative sampling strategies remains challenging, as they must simultaneously ensure realness, hardness, and interpretability. To this end, we propose \\textbf{ICPNS (In-Community Popularity Negative Sampling)}, a novel framework that leverages user community structure to identify reliable and informative negative samples. Our approach is grounded in the insight that item exposure is driven by latent user communities. By identifying these communities and utilizing in-community popularity, ICPNS effectively approximates the probability of item exposure. Consequently, items that are popular within a user's community but remain unclicked are identified as more reliable true negatives. Extensive experiments on four benchmark datasets demonstrate that ICPNS yields consistent improvements on graph-based recommenders and competitive performance on MF-based models, outperforming representative negative sampling strategies under a unified evaluation protocol.",
      "authors": [
        "Chen Chen",
        "Haobo Lin",
        "Yuanbo Xu"
      ],
      "url": "https://arxiv.org/abs/2602.18759",
      "published": "2026-02-21T08:53:10+00:00",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18758",
      "title": "UFO: Unlocking Ultra-Efficient Quantized Private Inference with Protocol and Algorithm Co-Optimization",
      "abstract": "Private convolutional neural network (CNN) inference based on secure two-party computation (2PC) suffers from high communication and latency overhead, especially from convolution layers. In this paper, we propose UFO, a quantized 2PC inference framework that jointly optimizes the 2PC protocols and quantization algorithm. UFO features a novel 2PC protocol that systematically combines the efficient Winograd convolution algorithm with quantization to improve inference efficiency. However, we observe that naively combining quantization and Winograd convolution faces the following challenges: 1) From the inference perspective, Winograd transformations introduce extensive additions and require frequent bit width conversions to avoid inference overflow, leading to non-negligible communication overhead; 2) From the training perspective, Winograd transformations introduce weight outliers that make quantization-aware training (QAT) difficult, resulting in inferior model accuracy. To address these challenges, we co-optimize both protocol and algorithm. 1) At the protocol level, we propose a series of graph-level optimizations for 2PC inference to minimize the communication. 2) At the algorithm level, we develop a mixed-precision QAT algorithm based on layer sensitivity to optimize model accuracy given communication constraints. To accommodate the outliers, we further introduce a 2PC-friendly bit re-weighting algorithm to increase the representation range without explicitly increasing bit widths. With extensive experiments, UFO demonstrates 11.7x, 3.6x, and 6.3x communication reduction with 1.29%, 1.16%, and 1.29% higher accuracy compared to state-of-the-art frameworks SiRNN, COINN, and CoPriv, respectively.",
      "authors": [
        "Wenxuan Zeng",
        "Chao Yang",
        "Tianshi Xu",
        "Bo Zhang",
        "Changrui Ren",
        "Jin Dong",
        "Meng Li"
      ],
      "url": "https://arxiv.org/abs/2602.18758",
      "published": "2026-02-21T08:45:05+00:00",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18749",
      "title": "Federated Reasoning Distillation Framework with Model Learnability-Aware Data Allocation",
      "abstract": "Data allocation plays a critical role in federated large language model (LLM) and small language models (SLMs) reasoning collaboration. Nevertheless, existing data allocation methods fail to address an under-explored challenge in collaboration: bidirectional model learnability gap, where client-side SLMs cannot identify high-reward samples matching their learnability constraints for effective knowledge transfer from LLMs, while LLMs struggle to select samples contributing novel knowledge beyond their existing data. Furthermore, these collaboration frameworks face another key challenge: domain-agnostic reasoning transfer, where existing reasoning transfer methods fail to flexibly adapt to the local domain data, preventing SLMs from effectively acquiring step-by-step reasoning abilities within from general LLM. To address these challenges, we propose LaDa, a federated reasoning distillation framework with model learnability-aware data allocation. It introduces a model learnability-aware data filter that adaptively allocates high-reward samples based on the learnability gap between each SLM and LLM pair, effectively facilitating bidirectional knowledge transfer. We further design a domain adaptive reasoning distillation method that aligns joint probabilities of reasoning paths on filtered high-reward samples through contrastive distillation learning between SLM and LLM, enabling SLM to capture underlying reasoning patterns under local data distribution. LaDa operates as a plug-in module for existing collaboration frameworks, adapting knowledge transfer based on model learnability gaps.",
      "authors": [
        "Wei Guo",
        "Siyuan Lu",
        "Xiangdong Ran",
        "Yiqi Tong",
        "Yikun Ban",
        "Zelong Xu",
        "Jing Fan",
        "Zixuan Huang",
        "Xiao Zhang",
        "Zhaojun Hu",
        "Fuzhen Zhuang"
      ],
      "url": "https://arxiv.org/abs/2602.18749",
      "published": "2026-02-21T08:18:39+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.18745",
      "title": "Synthesizing Multimodal Geometry Datasets from Scratch and Enabling Visual Alignment via Plotting Code",
      "abstract": "Multimodal geometry reasoning requires models to jointly understand visual diagrams and perform structured symbolic inference, yet current vision--language models struggle with complex geometric constructions due to limited training data and weak visual--symbolic alignment. We propose a pipeline for synthesizing complex multimodal geometry problems from scratch and construct a dataset named \\textbf{GeoCode}, which decouples problem generation into symbolic seed construction, grounded instantiation with verification, and code-based diagram rendering, ensuring consistency across structure, text, reasoning, and images. Leveraging the plotting code provided in GeoCode, we further introduce code prediction as an explicit alignment objective, transforming visual understanding into a supervised structured prediction task. GeoCode exhibits substantially higher structural complexity and reasoning difficulty than existing benchmarks, while maintaining mathematical correctness through multi-stage validation. Extensive experiments show that models trained on GeoCode achieve consistent improvements on multiple geometry benchmarks, demonstrating both the effectiveness of the dataset and the proposed alignment strategy. The code will be available at https://github.com/would1920/GeoCode.",
      "authors": [
        "Haobo Lin",
        "Tianyi Bai",
        "Chen Chen",
        "Jiajun Zhang",
        "Bohan Zeng",
        "Wentao Zhang",
        "Binhang Yuan"
      ],
      "url": "https://arxiv.org/abs/2602.18745",
      "published": "2026-02-21T07:53:48+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18744",
      "title": "RadioGen3D: 3D Radio Map Generation via Adversarial Learning on Large-Scale Synthetic Data",
      "abstract": "Radio maps are essential for efficient radio resource management in future 6G and low-altitude networks. While deep learning (DL) techniques have emerged as an efficient alternative to conventional ray-tracing for radio map estimation (RME), most existing DL approaches are confined to 2D near-ground scenarios. They often fail to capture essential 3D signal propagation characteristics and antenna polarization effects, primarily due to the scarcity of 3D data and training challenges. To address these limitations, we present the RadioGen3D framework. First, we propose an efficient data synthesis method to generate high-quality 3D radio map data. By establishing a parametric target model that captures 2D ray-tracing and 3D channel fading characteristics, we derive realistic coefficient combinations from minimal real measurements, enabling the construction of a large-scale synthetic dataset, Radio3DMix. Utilizing this dataset, we propose a 3D model training scheme based on a conditional generative adversarial network (cGAN), yielding a 3D U-Net capable of accurate RME under diverse input feature combinations. Experimental results demonstrate that RadioGen3D surpasses all baselines in both estimation accuracy and speed. Furthermore, fine-tuning experiments verify its strong generalization capability via successful knowledge transfer.",
      "authors": [
        "Junshen Chen",
        "Angzi Xu",
        "Zezhong Zhang",
        "Shiyao Zhang",
        "Junting Chen",
        "Shuguang Cui"
      ],
      "url": "https://arxiv.org/abs/2602.18744",
      "published": "2026-02-21T07:50:05+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18742",
      "title": "RoboCurate: Harnessing Diversity with Action-Verified Neural Trajectory for Robot Learning",
      "abstract": "Synthetic data generated by video generative models has shown promise for robot learning as a scalable pipeline, but it often suffers from inconsistent action quality due to imperfectly generated videos. Recently, vision-language models (VLMs) have been leveraged to validate video quality, but they have limitations in distinguishing physically accurate videos and, even then, cannot directly evaluate the generated actions themselves. To tackle this issue, we introduce RoboCurate, a novel synthetic robot data generation framework that evaluates and filters the quality of annotated actions by comparing them with simulation replay. Specifically, RoboCurate replays the predicted actions in a simulator and assesses action quality by measuring the consistency of motion between the simulator rollout and the generated video. In addition, we unlock observation diversity beyond the available dataset via image-to-image editing and apply action-preserving video-to-video transfer to further augment appearance. We observe RoboCurate's generated data yield substantial relative improvements in success rates compared to using real data only, achieving +70.1% on GR-1 Tabletop (300 demos), +16.1% on DexMimicGen in the pre-training setup, and +179.9% in the challenging real-world ALLEX humanoid dexterous manipulation setting.",
      "authors": [
        "Seungku Kim",
        "Suhyeok Jang",
        "Byungjun Yoon",
        "Dongyoung Kim",
        "John Won",
        "Jinwoo Shin"
      ],
      "url": "https://arxiv.org/abs/2602.18742",
      "published": "2026-02-21T07:33:24+00:00",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "id": "2602.18740",
      "title": "HONEST-CAV: Hierarchical Optimization of Network Signals and Trajectories for Connected and Automated Vehicles with Multi-Agent Reinforcement Learning",
      "abstract": "This study presents a hierarchical, network-level traffic flow control framework for mixed traffic consisting of Human-driven Vehicles (HVs), Connected and Automated Vehicles (CAVs). The framework jointly optimizes vehicle-level eco-driving behaviors and intersection-level traffic signal control to enhance overall network efficiency and decrease energy consumption. A decentralized Multi-Agent Reinforcement Learning (MARL) approach by Value Decomposition Network (VDN) manages cycle-based traffic signal control (TSC) at intersections, while an innovative Signal Phase and Timing (SPaT) prediction method integrates a Machine Learning-based Trajectory Planning Algorithm (MLTPA) to guide CAVs in executing Eco-Approach and Departure (EAD) maneuvers. The framework is evaluated across varying CAV proportions and powertrain types to assess its effects on mobility and energy performance. Experimental results conducted in a 4*4 real-world network demonstrate that the MARL-based TSC method outperforms the baseline model (i.e., Webster method) in speed, fuel consumption, and idling time. In addition, with MLTPA, HONEST-CAV benefits the traffic system further in energy consumption and idling time. With a 60% CAV proportion, vehicle average speed, fuel consumption, and idling time can be improved/saved by 7.67%, 10.23%, and 45.83% compared with the baseline. Furthermore, discussions on CAV proportions and powertrain types are conducted to quantify the performance of the proposed method with the impact of automation and electrification.",
      "authors": [
        "Ziyan Zhang",
        "Changxin Wan",
        "Peng Hao",
        "Kanok Boriboonsomsin",
        "Matthew J. Barth",
        "Yongkang Liu",
        "Seyhan Ucar",
        "Guoyuan Wu"
      ],
      "url": "https://arxiv.org/abs/2602.18740",
      "published": "2026-02-21T07:27:45+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ]
    },
    {
      "id": "2602.18739",
      "title": "When World Models Dream Wrong: Physical-Conditioned Adversarial Attacks against World Models",
      "abstract": "Generative world models (WMs) are increasingly used to synthesize controllable, sensor-conditioned driving videos, yet their reliance on physical priors exposes novel attack surfaces. In this paper, we present Physical-Conditioned World Model Attack (PhysCond-WMA), the first white-box world model attack that perturbs physical-condition channels, such as HDMap embeddings and 3D-box features, to induce semantic, logic, or decision-level distortion while preserving perceptual fidelity. PhysCond-WMA is optimized in two stages: (1) a quality-preserving guidance stage that constrains reverse-diffusion loss below a calibrated threshold, and (2) a momentum-guided denoising stage that accumulates target-aligned gradients along the denoising trajectory for stable, temporally coherent semantic shifts. Extensive experimental results demonstrate that our approach remains effective while increasing FID by about 9% on average and FVD by about 3.9% on average. Under the targeted attack setting, the attack success rate (ASR) reaches 0.55. Downstream studies further show tangible risk, which using attacked videos for training decreases 3D detection performance by about 4%, and worsens open-loop planning performance by about 20%. These findings has for the first time revealed and quantified security vulnerabilities in generative world models, driving more comprehensive security checkers.",
      "authors": [
        "Zhixiang Guo",
        "Siyuan Liang",
        "Andras Balogh",
        "Noah Lunberry",
        "Rong-Cheng Tu",
        "Mark Jelasity",
        "Dacheng Tao"
      ],
      "url": "https://arxiv.org/abs/2602.18739",
      "published": "2026-02-21T07:22:37+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18734",
      "title": "Rethinking Retrieval-Augmented Generation as a Cooperative Decision-Making Problem",
      "abstract": "Retrieval-Augmented Generation (RAG) has demonstrated strong effectiveness in knowledge-intensive tasks by grounding language generation in external evidence. Despite its success, many existing RAG systems are built based on a ranking-centric, asymmetric dependency paradigm, where the generation quality of the generator is highly dependent on reranking results of the reranker. To overcome this limitation, we reformulate RAG as a cooperative multi-agent decision-making problem and propose Cooperative Retrieval-Augmented Generation (CoRAG), a framework in which the reranker and the generator act as peer decision-makers rather than being connected through an asymmetric dependency pipeline. By jointly optimizing their behaviors toward a shared task objective, the reranker and generator are encouraged to cooperate, ensuring that document reranking and generation work in concert to improve the final response. Experimental results demonstrate good generalization and improved generation stability of CoRAG, even when the model is trained on only around 10K PopQA samples. Our model released in https://anonymous.4open.science/r/CoRAG-D63F",
      "authors": [
        "Lichang Song",
        "Ting Long",
        "Yi Chang"
      ],
      "url": "https://arxiv.org/abs/2602.18734",
      "published": "2026-02-21T06:32:36+00:00",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18733",
      "title": "Prior Aware Memorization: An Efficient Metric for Distinguishing Memorization from Generalization in Large Language Models",
      "abstract": "Training data leakage from Large Language Models (LLMs) raises serious concerns related to privacy, security, and copyright compliance. A central challenge in assessing this risk is distinguishing genuine memorization of training data from the generation of statistically common sequences. Existing approaches to measuring memorization often conflate these phenomena, labeling outputs as memorized even when they arise from generalization over common patterns. Counterfactual Memorization provides a principled solution by comparing models trained with and without a target sequence, but its reliance on retraining multiple baseline models makes it computationally expensive and impractical at scale.   This work introduces Prior-Aware Memorization, a theoretically grounded, lightweight and training-free criterion for identifying genuine memorization in LLMs. The key idea is to evaluate whether a candidate suffix is strongly associated with its specific training prefix or whether it appears with high probability across many unrelated prompts due to statistical commonality.   We evaluate this metric on text from the training corpora of two pre-trained models, LLaMA and OPT, using both long sequences (to simulate copyright risks) and named entities (to simulate PII leakage). Our results show that between 55% and 90% of sequences previously labeled as memorized are in fact statistically common. Similar findings hold for the SATML training data extraction challenge dataset, where roughly 40% of sequences exhibit common-pattern behavior despite appearing only once in the training data. These results demonstrate that low frequency alone is insufficient evidence of memorization and highlight the importance of accounting for model priors when assessing leakage.",
      "authors": [
        "Trishita Tiwari",
        "Ari Trachtenberg",
        "G. Edward Suh"
      ],
      "url": "https://arxiv.org/abs/2602.18733",
      "published": "2026-02-21T06:31:17+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18731",
      "title": "Beyond Description: A Multimodal Agent Framework for Insightful Chart Summarization",
      "abstract": "Chart summarization is crucial for enhancing data accessibility and the efficient consumption of information. However, existing methods, including those with Multimodal Large Language Models (MLLMs), primarily focus on low-level data descriptions and often fail to capture the deeper insights which are the fundamental purpose of data visualization. To address this challenge, we propose Chart Insight Agent Flow, a plan-and-execute multi-agent framework effectively leveraging the perceptual and reasoning capabilities of MLLMs to uncover profound insights directly from chart images. Furthermore, to overcome the lack of suitable benchmarks, we introduce ChartSummInsights, a new dataset featuring a diverse collection of real-world charts paired with high-quality, insightful summaries authored by human data analysis experts. Experimental results demonstrate that our method significantly improves the performance of MLLMs on the chart summarization task, producing summaries with deep and diverse insights.",
      "authors": [
        "Yuhang Bai",
        "Yujuan Ding",
        "Shanru Lin",
        "Wenqi Fan"
      ],
      "url": "https://arxiv.org/abs/2602.18731",
      "published": "2026-02-21T06:17:37+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.18729",
      "title": "MiSCHiEF: A Benchmark in Minimal-Pairs of Safety and Culture for Holistic Evaluation of Fine-Grained Image-Caption Alignment",
      "abstract": "Fine-grained image-caption alignment is crucial for vision-language models (VLMs), especially in socially critical contexts such as identifying real-world risk scenarios or distinguishing cultural proxies, where correct interpretation hinges on subtle visual or linguistic clues and where minor misinterpretations can lead to significant real-world consequences. We present MiSCHiEF, a set of two benchmarking datasets based on a contrastive pair design in the domains of safety (MiS) and culture (MiC), and evaluate four VLMs on tasks requiring fine-grained differentiation of paired images and captions. In both datasets, each sample contains two minimally differing captions and corresponding minimally differing images. In MiS, the image-caption pairs depict a safe and an unsafe scenario, while in MiC, they depict cultural proxies in two distinct cultural contexts. We find that models generally perform better at confirming the correct image-caption pair than rejecting incorrect ones. Additionally, models achieve higher accuracy when selecting the correct caption from two highly similar captions for a given image, compared to the converse task. The results, overall, highlight persistent modality misalignment challenges in current VLMs, underscoring the difficulty of precise cross-modal grounding required for applications with subtle semantic and visual distinctions.",
      "authors": [
        "Sagarika Banerjee",
        "Tangatar Madi",
        "Advait Swaminathan",
        "Nguyen Dao Minh Anh",
        "Shivank Garg",
        "Kevin Zhu",
        "Vasu Sharma"
      ],
      "url": "https://arxiv.org/abs/2602.18729",
      "published": "2026-02-21T06:06:46+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18728",
      "title": "Phase-Consistent Magnetic Spectral Learning for Multi-View Clustering",
      "abstract": "Unsupervised multi-view clustering (MVC) aims to partition data into meaningful groups by leveraging complementary information from multiple views without labels, yet a central challenge is to obtain a reliable shared structural signal to guide representation learning and cross-view alignment under view discrepancy and noise. Existing approaches often rely on magnitude-only affinities or early pseudo targets, which can be unstable when different views induce relations with comparable strengths but contradictory directional tendencies, thereby distorting the global spectral geometry and degrading clustering. In this paper, we propose \\emph{Phase-Consistent Magnetic Spectral Learning} for MVC: we explicitly model cross-view directional agreement as a phase term and combine it with a nonnegative magnitude backbone to form a complex-valued magnetic affinity, extract a stable shared spectral signal via a Hermitian magnetic Laplacian, and use it as structured self-supervision to guide unsupervised multi-view representation learning and clustering. To obtain robust inputs for spectral extraction at scale, we construct a compact shared structure with anchor-based high-order consensus modeling and apply a lightweight refinement to suppress noisy or inconsistent relations. Extensive experiments on multiple public multi-view benchmarks demonstrate that our method consistently outperforms strong baselines.",
      "authors": [
        "Mingdong Lu",
        "Zhikui Chen",
        "Meng Liu",
        "Shubin Ma",
        "Liang Zhao"
      ],
      "url": "https://arxiv.org/abs/2602.18728",
      "published": "2026-02-21T06:04:57+00:00",
      "categories": [
        "cs.LG",
        "cs.CV"
      ]
    },
    {
      "id": "2602.18726",
      "title": "WiCompass: Oracle-driven Data Scaling for mmWave Human Pose Estimation",
      "abstract": "Millimeter-wave Human Pose Estimation (mmWave HPE) promises privacy but suffers from poor generalization under distribution shifts. We demonstrate that brute-force data scaling is ineffective for out-of-distribution (OOD) robustness; efficiency and coverage are the true bottlenecks. To address this, we introduce WiCompass, a coverage-aware data-collection framework. WiCompass leverages large-scale motion-capture corpora to build a universal pose space ``oracle'' that quantifies dataset redundancy and identifies underrepresented motions. Guided by this oracle, WiCompass employs a closed-loop policy to prioritize collecting informative missing samples. Experiments show that WiCompass consistently improves OOD accuracy at matched budgets and exhibits superior scaling behavior compared to conventional collection strategies. By shifting focus from brute-force scaling to coverage-aware data acquisition, this work offers a practical path toward robust mmWave sensing.",
      "authors": [
        "Bo Liang",
        "Chen Gong",
        "Haobo Wang",
        "Qirui Liu",
        "Rungui Zhou",
        "Fengzhi Shao",
        "Yubo Wang",
        "Wei Gao",
        "Kaichen Zhou",
        "Guolong Cui",
        "Chenren Xu"
      ],
      "url": "https://arxiv.org/abs/2602.18726",
      "published": "2026-02-21T05:50:28+00:00",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18724",
      "title": "Task-Aware Exploration via a Predictive Bisimulation Metric",
      "abstract": "Accelerating exploration in visual reinforcement learning under sparse rewards remains challenging due to the substantial task-irrelevant variations. Despite advances in intrinsic exploration, many methods either assume access to low-dimensional states or lack task-aware exploration strategies, thereby rendering them fragile in visual domains. To bridge this gap, we present TEB, a Task-aware Exploration approach that tightly couples task-relevant representations with exploration through a predictive Bisimulation metric. Specifically, TEB leverages the metric not only to learn behaviorally grounded task representations but also to measure behaviorally intrinsic novelty over the learned latent space. To realize this, we first theoretically mitigate the representation collapse of degenerate bisimulation metrics under sparse rewards by internally introducing a simple but effective predicted reward differential. Building on this robust metric, we design potential-based exploration bonuses, which measure the relative novelty of adjacent observations over the latent space. Extensive experiments on MetaWorld and Maze2D show that TEB achieves superior exploration ability and outperforms recent baselines.",
      "authors": [
        "Dayang Liang",
        "Ruihan Liu",
        "Lipeng Wan",
        "Yunlong Liu",
        "Bo An"
      ],
      "url": "https://arxiv.org/abs/2602.18724",
      "published": "2026-02-21T05:30:34+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.18721",
      "title": "ReHear: Iterative Pseudo-Label Refinement for Semi-Supervised Speech Recognition via Audio Large Language Models",
      "abstract": "Semi-supervised learning in automatic speech recognition (ASR) typically relies on pseudo-labeling, which often suffers from confirmation bias and error accumulation due to noisy supervision. To address this limitation, we propose ReHear, a framework for iterative pseudo-label refinement that integrates an instruction-tuned, audio-aware large language model (LLM) into the self-training loop. Unlike conventional text-based correctors, our approach conditions the LLM on both the ASR hypothesis and the source audio, allowing it to recover phonetically accurate transcripts even from severe recognition errors. These refined pseudo-labels serve as high-fidelity targets for fine-tuning the ASR model in an iterative cycle. Experimental results across diverse benchmarks demonstrate that ReHear effectively mitigates error propagation, consistently outperforming both supervised and pseudo-labeling baselines.",
      "authors": [
        "Zefang Liu",
        "Chenyang Zhu",
        "Sangwoo Cho",
        "Shi-Xiong Zhang"
      ],
      "url": "https://arxiv.org/abs/2602.18721",
      "published": "2026-02-21T05:04:22+00:00",
      "categories": [
        "cs.CL",
        "eess.AS"
      ]
    },
    {
      "id": "2602.18718",
      "title": "Stochastic Gradient Variational Inference with Price's Gradient Estimator from Bures-Wasserstein to Parameter Space",
      "abstract": "For approximating a target distribution given only its unnormalized log-density, stochastic gradient-based variational inference (VI) algorithms are a popular approach. For example, Wasserstein VI (WVI) and black-box VI (BBVI) perform gradient descent in measure space (Bures-Wasserstein space) and parameter space, respectively. Previously, for the Gaussian variational family, convergence guarantees for WVI have shown superiority over existing results for black-box VI with the reparametrization gradient, suggesting the measure space approach might provide some unique benefits. In this work, however, we close this gap by obtaining identical state-of-the-art iteration complexity guarantees for both. In particular, we identify that WVI's superiority stems from the specific gradient estimator it uses, which BBVI can also leverage with minor modifications. The estimator in question is usually associated with Price's theorem and utilizes second-order information (Hessians) of the target log-density. We will refer to this as Price's gradient. On the flip side, WVI can be made more widely applicable by using the reparametrization gradient, which requires only gradients of the log-density. We empirically demonstrate that the use of Price's gradient is the major source of performance improvement.",
      "authors": [
        "Kyurae Kim",
        "Qiang Fu",
        "Yi-An Ma",
        "Jacob R. Gardner",
        "Trevor Campbell"
      ],
      "url": "https://arxiv.org/abs/2602.18718",
      "published": "2026-02-21T04:52:53+00:00",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.OC",
        "stat.CO"
      ]
    },
    {
      "id": "2602.18716",
      "title": "Temporal Action Representation Learning for Tactical Resource Control and Subsequent Maneuver Generation",
      "abstract": "Autonomous robotic systems should reason about resource control and its impact on subsequent maneuvers, especially when operating with limited energy budgets or restricted sensing. Learning-based control is effective in handling complex dynamics and represents the problem as a hybrid action space unifying discrete resource usage and continuous maneuvers. However, prior works on hybrid action space have not sufficiently captured the causal dependencies between resource usage and maneuvers. They have also overlooked the multi-modal nature of tactical decisions, both of which are critical in fast-evolving scenarios. In this paper, we propose TART, a Temporal Action Representation learning framework for Tactical resource control and subsequent maneuver generation. TART leverages contrastive learning based on a mutual information objective, designed to capture inherent temporal dependencies in resource-maneuver interactions. These learned representations are quantized into discrete codebook entries that condition the policy, capturing recurring tactical patterns and enabling multi-modal and temporally coherent behaviors. We evaluate TART in two domains where resource deployment is critical: (i) a maze navigation task where a limited budget of discrete actions provides enhanced mobility, and (ii) a high-fidelity air combat simulator in which an F-16 agent operates weapons and defensive systems in coordination with flight maneuvers. Across both domains, TART consistently outperforms hybrid-action baselines, demonstrating its effectiveness in leveraging limited resources and producing context-aware subsequent maneuvers.",
      "authors": [
        "Hoseong Jung",
        "Sungil Son",
        "Daesol Cho",
        "Jonghae Park",
        "Changhyun Choi",
        "H. Jin Kim"
      ],
      "url": "https://arxiv.org/abs/2602.18716",
      "published": "2026-02-21T04:31:55+00:00",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18715",
      "title": "A Data-Driven Method to Map the Functional Organisation of Human Brain White Matter",
      "abstract": "The white matter of the brain is organised into axonal bundles that support long-range neural communication. Although diffusion MRI (dMRI) enables detailed mapping of these pathways through tractography, how white matter pathways directly facilitate large-scale neural synchronisation remains poorly understood. We developed a data-driven framework that integrates dMRI and functional MRI (fMRI) to model the dynamic coupling supported by white matter tracks. Specifically, we employed track dynamic functional connectivity (Track-DFC) to characterise functional coupling of remote grey matter connected by individual white matter tracks. Using independent component analysis followed by k-medoids clustering, we derived functionally-coherent clusters of white matter tracks from the Human Connectome Project young adult cohort. When applied to the HCP ageing cohort, these clusters exhibited widespread age-related declines in both functional coupling strength and temporal variability. Importantly, specific clusters encompassing pathways linking control, default mode, attention, and visual systems significantly mediated the relationship between age and cognitive performance. Together, these findings depict the functional organisation of white matter tracks and provide a powerful tool to study brain ageing and cognitive decline.",
      "authors": [
        "Yifei Sun",
        "James M. Shine",
        "Robert D. Sanders",
        "Robin F. H. Cash",
        "Sharon L. Naismith",
        "Fernando Calamante",
        "Jinglei Lv"
      ],
      "url": "https://arxiv.org/abs/2602.18715",
      "published": "2026-02-21T04:20:41+00:00",
      "categories": [
        "q-bio.NC",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18710",
      "title": "Many AI Analysts, One Dataset: Navigating the Agentic Data Science Multiverse",
      "abstract": "The conclusions of empirical research depend not only on data but on a sequence of analytic decisions that published results seldom make explicit. Past ``many-analyst\" studies have demonstrated this: independent teams testing the same hypothesis on the same dataset regularly reach conflicting conclusions. But such studies require months of coordination among dozens of research groups and are therefore rarely conducted. In this work, we show that fully autonomous AI analysts built on large language models (LLMs) can reproduce a similar structured analytic diversity cheaply and at scale. We task these AI analysts with testing a pre-specified hypothesis on a fixed dataset, varying the underlying model and prompt framing across replicate runs. Each AI analyst independently constructs and executes a full analysis pipeline; an AI auditor then screens each run for methodological validity. Across three datasets spanning experimental and observational designs, AI analyst-produced analyses display wide dispersion in effect sizes, $p$-values, and binary decisions on supporting the hypothesis or not, frequently reversing whether a hypothesis is judged supported. This dispersion is structured: recognizable analytic choices in preprocessing, model specification, and inference differ systematically across LLM and persona conditions. Critically, the effects are \\emph{steerable}: reassigning the analyst persona or LLM shifts the distribution of outcomes even after excluding methodologically deficient runs.",
      "authors": [
        "Martin Bertran",
        "Riccardo Fogliato",
        "Zhiwei Steven Wu"
      ],
      "url": "https://arxiv.org/abs/2602.18710",
      "published": "2026-02-21T04:10:21+00:00",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18705",
      "title": "EDU-MATRIX: A Society-Centric Generative Cognitive Digital Twin Architecture for Secondary Education",
      "abstract": "Existing multi-agent simulations often suffer from the \"Agent-Centric Paradox\": rules are hard-coded into individual agents, making complex social dynamics rigid and difficult to align with educational values. This paper presents EDU-MATRIX, a society-centric generative cognitive digital twin architecture that shifts the paradigm from simulating \"people\" to simulating a \"social space with a gravitational field.\" We introduce three architectural contributions: (1) An Environment Context Injection Engine (ECIE), which acts as a \"social microkernel,\" dynamically injecting institutional rules (Gravity) into agents based on their spatial-temporal coordinates; (2) A Modular Logic Evolution Protocol (MLEP), where knowledge exists as \"fluid\" capsules that agents synthesize to generate new paradigms, ensuring high dialogue consistency (94.1%); and (3) Endogenous Alignment via Role-Topology, where safety constraints emerge from the agent's position in the social graph rather than external filters. Deployed as a digital twin of a secondary school with 2,400 agents, the system demonstrates how \"social gravity\" (rules) and \"cognitive fluids\" (knowledge) interact to produce emergent, value-aligned behaviors (Social Clustering Coefficient: 0.72).",
      "authors": [
        "Wenjing Zhai",
        "Jianbin Zhang",
        "Tao Liu"
      ],
      "url": "https://arxiv.org/abs/2602.18705",
      "published": "2026-02-21T03:32:56+00:00",
      "categories": [
        "cs.MA",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18702",
      "title": "Think with Grounding: Curriculum Reinforced Reasoning with Video Grounding for Long Video Understanding",
      "abstract": "Long video understanding is challenging due to rich and complicated multimodal clues in long temporal range.Current methods adopt reasoning to improve the model's ability to analyze complex video clues in long videos via text-form reasoning.However,the existing literature suffers from the fact that the text-only reasoning under fixed video context may exacerbate hallucinations since detailed crucial clues are often ignored under limited video context length due to the temporal redundancy of long videos.To address this gap,we propose Video-TwG,a curriculum reinforced framework that employs a novel Think-with-Grounding paradigm,enabling video LLMs to actively decide when to perform on-demand grounding during interleaved text-video reasoning, selectively zooming into question-relevant clips only when necessary.Video-TwG can be trained end-to-end in a straightforward manner, without relying on complex auxiliary modules or heavily annotated reasoning tracesIn detail,we design a Two-stage Reinforced Curriculum Strategy, where the model first learns think-with-grounding behavior on a small short-video GQA dataset with grounding labels,and then scales to diverse general QA data with videos of diverse domains to encourage generalization. Further, to handle complex think-with-grounding reasoning for various kinds of data,we propose TwG-GRPO algorithm which features the fine-grained grounding reward, self-confirmed pseudo reward and accuracy-gated mechanism.Finally,we propose to construct a new TwG-51K dataset that facilitates training. Experiments on Video-MME, LongVideoBench, and MLVU show that Video-TwG consistently outperforms strong LVU baselines.Further ablation validates the necessity of our Two-stage Reinforced Curriculum Strategy and shows our TwG-GRPO better leverages diverse unlabeled data to improve grounding quality and reduce redundant groundings without sacrificing QA performance.",
      "authors": [
        "Houlun Chen",
        "Xin Wang",
        "Guangyao Li",
        "Yuwei Zhou",
        "Yihan Chen",
        "Jia Jia",
        "Wenwu Zhu"
      ],
      "url": "https://arxiv.org/abs/2602.18702",
      "published": "2026-02-21T03:16:23+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18700",
      "title": "Watermarking LLM Agent Trajectories",
      "abstract": "LLM agents rely heavily on high-quality trajectory data to guide their problem-solving behaviors, yet producing such data requires substantial task design, high-capacity model generation, and manual filtering. Despite the high cost of creating these datasets, existing literature has overlooked copyright protection for LLM agent trajectories. This gap leaves creators vulnerable to data theft and makes it difficult to trace misuse or enforce ownership rights. This paper introduces ActHook, the first watermarking method tailored for agent trajectory datasets. Inspired by hook mechanisms in software engineering, ActHook embeds hook actions that are activated by a secret input key and do not alter the original task outcome. Like software execution, LLM agents operate sequentially, allowing hook actions to be inserted at decision points without disrupting task flow. When the activation key is present, an LLM agent trained on watermarked trajectories can produce these hook actions at a significantly higher rate, enabling reliable black-box detection. Experiments on mathematical reasoning, web searching, and software engineering agents show that ActHook achieves an average detection AUC of 94.3 on Qwen-2.5-Coder-7B while incurring negligible performance degradation.",
      "authors": [
        "Wenlong Meng",
        "Chen Gong",
        "Terry Yue Zhuo",
        "Fan Zhang",
        "Kecen Li",
        "Zheng Liu",
        "Zhou Yang",
        "Chengkun Wei",
        "Wenzhi Chen"
      ],
      "url": "https://arxiv.org/abs/2602.18700",
      "published": "2026-02-21T03:12:29+00:00",
      "categories": [
        "cs.CR",
        "cs.CL"
      ]
    },
    {
      "id": "2602.18699",
      "title": "Semantic Substrate Theory: An Operator-Theoretic Framework for Geometric Semantic Drift",
      "abstract": "Most semantic drift studies report multiple signals e.g., embedding displacement, neighbor changes, distributional divergence, and recursive trajectory instability, without a shared explanatory theory that relates them. This paper proposes a formalization of these signals in one time-indexed substrate, $S_t=(X,d_t,P_t)$, combining embedding geometry with local diffusion. Within this substrate, node-level neighborhood drift measures changes in local conditional distributions, coarse Ricci curvature measures local contractivity of semantic diffusion, and recursive drift probes stability of iterated semantic operators. This manuscript specifies the formal model, assumptions, and tests that can refute the model. Herein, the paper introduces bridge mass, a node-level aggregate of incident negative curvature, as a predictor of future neighborhood rewiring. This paper provides the theory and test contracts; empirical performance is deferred to subsequent studies.",
      "authors": [
        "Stephen Russell"
      ],
      "url": "https://arxiv.org/abs/2602.18699",
      "published": "2026-02-21T03:04:21+00:00",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18695",
      "title": "Insertion Based Sequence Generation with Learnable Order Dynamics",
      "abstract": "In many domains generating variable length sequences through insertions provides greater flexibility over autoregressive models. However, the action space of insertion models is much larger than that of autoregressive models (ARMs) making the learning challenging. To address this, we incorporate trainable order dynamics into the target rates for discrete flow matching, and show that with suitable choices of parameterizations, joint training of the target order dynamics and the generator is tractable without the need for numerical simulation. As the generative insertion model, we use a variable length masked diffusion model, which generates by inserting and filling mask tokens. On graph traversal tasks for which a locally optimal insertion order is known, we explore the choices of parameterization empirically and demonstrate the trade-offs between flexibility, training stability and generation quality. On de novo small molecule generation, we find that the learned order dynamics leads to an increase in the number of valid molecules generated and improved quality, when compared to uniform order dynamics.",
      "authors": [
        "Dhruvesh Patel",
        "Benjamin Rozonoyer",
        "Gaurav Pandey",
        "Tahira Naseem",
        "Ramón Fernandez Astudillo",
        "Andrew McCallum"
      ],
      "url": "https://arxiv.org/abs/2602.18695",
      "published": "2026-02-21T02:53:55+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18694",
      "title": "In-Context Planning with Latent Temporal Abstractions",
      "abstract": "Planning-based reinforcement learning for continuous control is bottlenecked by two practical issues: planning at primitive time scales leads to prohibitive branching and long horizons, while real environments are frequently partially observable and exhibit regime shifts that invalidate stationary, fully observed dynamics assumptions. We introduce I-TAP (In-Context Latent Temporal-Abstraction Planner), an offline RL framework that unifies in-context adaptation with online planning in a learned discrete temporal-abstraction space. From offline trajectories, I-TAP learns an observation-conditioned residual-quantization VAE that compresses each observation-macro-action segment into a coarse-to-fine stack of discrete residual tokens, and a temporal Transformer that autoregressively predicts these token stacks from a short recent history. The resulting sequence model acts simultaneously as a context-conditioned prior over abstract actions and a latent dynamics model. At test time, I-TAP performs Monte Carlo Tree Search directly in token space, using short histories for implicit adaptation without gradient update, and decodes selected token stacks into executable actions. Across deterministic MuJoCo, stochastic MuJoCo with per-episode latent dynamics regimes, and high-dimensional Adroit manipulation, including partially observable variants, I-TAP consistently matches or outperforms strong model-free and model-based offline baselines, demonstrating efficient and robust in-context planning under stochastic dynamics and partial observability.",
      "authors": [
        "Baiting Luo",
        "Yunuo Zhang",
        "Nathaniel S. Keplinger",
        "Samir Gupta",
        "Abhishek Dubey",
        "Ayan Mukhopadhyay"
      ],
      "url": "https://arxiv.org/abs/2602.18694",
      "published": "2026-02-21T02:29:19+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18693",
      "title": "Contradiction to Consensus: Dual Perspective, Multi Source Retrieval Based Claim Verification with Source Level Disagreement using LLM",
      "abstract": "The spread of misinformation across digital platforms can pose significant societal risks. Claim verification, a.k.a. fact-checking, systems can help identify potential misinformation. However, their efficacy is limited by the knowledge sources that they rely on. Most automated claim verification systems depend on a single knowledge source and utilize the supporting evidence from that source; they ignore the disagreement of their source with others. This limits their knowledge coverage and transparency. To address these limitations, we present a novel system for open-domain claim verification (ODCV) that leverages large language models (LLMs), multi-perspective evidence retrieval, and cross-source disagreement analysis. Our approach introduces a novel retrieval strategy that collects evidence for both the original and the negated forms of a claim, enabling the system to capture supporting and contradicting information from diverse sources: Wikipedia, PubMed, and Google. These evidence sets are filtered, deduplicated, and aggregated across sources to form a unified and enriched knowledge base that better reflects the complexity of real-world information. This aggregated evidence is then used for claim verification using LLMs. We further enhance interpretability by analyzing model confidence scores to quantify and visualize inter-source disagreement. Through extensive evaluation on four benchmark datasets with five LLMs, we show that knowledge aggregation not only improves claim verification but also reveals differences in source-specific reasoning. Our findings underscore the importance of embracing diversity, contradiction, and aggregation in evidence for building reliable and transparent claim verification systems",
      "authors": [
        "Md Badsha Biswas",
        "Ozlem Uzuner"
      ],
      "url": "https://arxiv.org/abs/2602.18693",
      "published": "2026-02-21T02:21:31+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.18692",
      "title": "From Trial by Fire To Sleep Like a Baby: A Lexicon of Anxiety Associations for 20k English Multiword Expressions",
      "abstract": "Anxiety is the unease about a possible future negative outcome. In recent years, there has been growing interest in understanding how anxiety relates to our health, well-being, body, mind, and behaviour. This includes work on lexical resources for word-anxiety association. However, there is very little anxiety-related work on larger units of text such as multiword expressions (MWE). Here, we introduce the first large-scale lexicon capturing descriptive norms of anxiety associations for more than 20k English MWEs. We show that the anxiety associations are highly reliable. We use the lexicon to study prevalence of different types of anxiety- and calmness-associated MWEs; and how that varies across two-, three-, and four-word sequences. We also study the extent to which the anxiety association of MWEs is compositional (due to its constituent words). The lexicon enables a wide variety of anxiety-related research in psychology, NLP, public health, and social sciences. The lexicon is freely available: https://saifmohammad.com/worrylex.html",
      "authors": [
        "Saif M. Mohammad"
      ],
      "url": "https://arxiv.org/abs/2602.18692",
      "published": "2026-02-21T02:15:04+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.18690",
      "title": "Neural Fields as World Models",
      "abstract": "How does the brain predict physical outcomes while acting in the world? Machine learning world models compress visual input into latent spaces, discarding the spatial structure that characterizes sensory cortex. We propose isomorphic world models: architectures preserving sensory topology so that physics prediction becomes geometric propagation rather than abstract state transition. We implement this using neural fields with motor-gated channels, where activity evolves through local lateral connectivity and motor commands multiplicatively modulate specific populations. Three experiments support this approach: (1) local connectivity is sufficient to learn ballistic physics, with predictions traversing intermediate locations rather than \"teleporting\"; (2) policies trained entirely in imagination transfer to real physics at nearly twice the rate of latent-space alternatives; and (3) motor-gated channels spontaneously develop body-selective encoding through visuomotor prediction alone. These findings suggest intuitive physics and body schema may share a common origin in spatially structured neural dynamics.",
      "authors": [
        "Joshua Nunley"
      ],
      "url": "https://arxiv.org/abs/2602.18690",
      "published": "2026-02-21T01:52:43+00:00",
      "categories": [
        "q-bio.NC",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18679",
      "title": "Transformers for dynamical systems learn transfer operators in-context",
      "abstract": "Large-scale foundation models for scientific machine learning adapt to physical settings unseen during training, such as zero-shot transfer between turbulent scales. This phenomenon, in-context learning, challenges conventional understanding of learning and adaptation in physical systems. Here, we study in-context learning of dynamical systems in a minimal setting: we train a small two-layer, single-head transformer to forecast one dynamical system, and then evaluate its ability to forecast a different dynamical system without retraining. We discover an early tradeoff in training between in-distribution and out-of-distribution performance, which manifests as a secondary double descent phenomenon. We discover that attention-based models apply a transfer-operator forecasting strategy in-context. They (1) lift low-dimensional time series using delay embedding, to detect the system's higher-dimensional dynamical manifold, and (2) identify and forecast long-lived invariant sets that characterize the global flow on this manifold. Our results clarify the mechanism enabling large pretrained models to forecast unseen physical systems at test without retraining, and they illustrate the unique ability of attention-based models to leverage global attractor information in service of short-term forecasts.",
      "authors": [
        "Anthony Bao",
        "Jeffrey Lai",
        "William Gilpin"
      ],
      "url": "https://arxiv.org/abs/2602.18679",
      "published": "2026-02-21T01:03:15+00:00",
      "categories": [
        "cs.LG",
        "nlin.CD"
      ]
    },
    {
      "id": "2602.18678",
      "title": "Heterogeneity-agnostic AI/ML-assisted beam selection for multi-panel arrays",
      "abstract": "AI/ML-based beam selection methods coupled with location information effectively reduce beam training overhead. Unfortunately, heterogeneous antenna hardware with varying dimensions, orientations, codebooks, element patterns, and polarization angles limits their feasibility and generalization. This challenge requires either a heterogeneity-agnostic model functional under these variations, or developing many models for each configuration, which is infeasible and expensive in practice. In this paper, we propose a unifying AI/ML-based beam selection algorithm supporting antenna heterogeneity by predicting wireless propagation characteristics independent of antenna configuration. We derive a reference signal received power (RSRP) model that decouples propagation characteristics from antenna configuration. We propose an optimization framework to extract propagation variables consisting of angle-of-arrival (AoA), angle-of-departure (AoD), and a matrix incorporating path gain and channel depolarization from beamformed RSRP measurements. We develop a three-stage autoregressive network to predict these variables from user location, enabling RSRP calculation and beam selection for arbitrary antenna configurations without retraining or having a separate model for each configuration. Simulation results show our heterogeneity-agnostic method provides spectral efficiency close to that of genie-aided selection both with and without antenna heterogeneity.",
      "authors": [
        "Ibrahim Kilinc",
        "Robert W. Heath"
      ],
      "url": "https://arxiv.org/abs/2602.18678",
      "published": "2026-02-21T01:03:05+00:00",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18674",
      "title": "Robustness of Deep ReLU Networks to Misclassification of High-Dimensional Data",
      "abstract": "We present a theoretical study of the robustness of parameterized networks to random input perturbations. Specifically, we analyze local robustness at a given network input by quantifying the probability that a small additive random perturbation of the input leads to misclassification. For deep networks with rectified linear units, we derive lower bounds on local robustness in terms of the input dimensionality and the total number of network units.",
      "authors": [
        "Věra Kůrková"
      ],
      "url": "https://arxiv.org/abs/2602.18674",
      "published": "2026-02-21T00:55:47+00:00",
      "categories": [
        "cs.LG",
        "cs.NE"
      ]
    },
    {
      "id": "2602.18671",
      "title": "Spilled Energy in Large Language Models",
      "abstract": "We reinterpret the final Large Language Model (LLM) softmax classifier as an Energy-Based Model (EBM), decomposing the sequence-to-sequence probability chain into multiple interacting EBMs at inference. This principled approach allows us to track \"energy spills\" during decoding, which we empirically show correlate with factual errors, biases, and failures. Similar to Orgad et al. (2025), our method localizes the exact answer token and subsequently tests for hallucinations. Crucially, however, we achieve this without requiring trained probe classifiers or activation ablations. Instead, we introduce two completely training-free metrics derived directly from output logits: spilled energy, which captures the discrepancy between energy values across consecutive generation steps that should theoretically match, and marginalized energy, which is measurable at a single step. Evaluated on nine benchmarks across state-of-the-art LLMs (including LLaMA, Mistral, and Gemma) and on synthetic algebraic operations (Qwen3), our approach demonstrates robust, competitive hallucination detection and cross-task generalization. Notably, these results hold for both pretrained and instruction-tuned variants without introducing any training overhead.",
      "authors": [
        "Adrian Robert Minut",
        "Hazem Dewidar",
        "Iacopo Masi"
      ],
      "url": "https://arxiv.org/abs/2602.18671",
      "published": "2026-02-21T00:38:47+00:00",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "id": "2602.18663",
      "title": "Toward AI Autonomous Navigation for Mechanical Thrombectomy using Hierarchical Modular Multi-agent Reinforcement Learning (HM-MARL)",
      "abstract": "Mechanical thrombectomy (MT) is typically the optimal treatment for acute ischemic stroke involving large vessel occlusions, but access is limited due to geographic and logistical barriers. Reinforcement learning (RL) shows promise in autonomous endovascular navigation, but generalization across 'long' navigation tasks remains challenging. We propose a Hierarchical Modular Multi-Agent Reinforcement Learning (HM-MARL) framework for autonomous two-device navigation in vitro, enabling efficient and generalizable navigation. HM-MARL was developed to autonomously navigate a guide catheter and guidewire from the femoral artery to the internal carotid artery (ICA). A modular multi-agent approach was used to decompose the complex navigation task into specialized subtasks, each trained using Soft Actor-Critic RL. The framework was validated in both in silico and in vitro testbeds to assess generalization and real-world feasibility. In silico, a single-vasculature model achieved 92-100% success rates on individual anatomies, while a multi-vasculature model achieved 56-80% across multiple patient anatomies. In vitro, both HM-MARL models successfully navigated 100% of trials from the femoral artery to the right common carotid artery and 80% to the right ICA but failed on the left-side vessel superhuman challenge due to the anatomy and catheter type used in navigation. This study presents the first demonstration of in vitro autonomous navigation in MT vasculature. While HM-MARL enables generalization across anatomies, the simulation-to-real transition introduces challenges. Future work will refine RL strategies using world models and validate performance on unseen in vitro data, advancing autonomous MT towards clinical translation.",
      "authors": [
        "Harry Robertshaw",
        "Nikola Fischer",
        "Lennart Karstensen",
        "Benjamin Jackson",
        "Xingyu Chen",
        "S. M. Hadi Sadati",
        "Christos Bergeles",
        "Alejandro Granados",
        "Thomas C Booth"
      ],
      "url": "https://arxiv.org/abs/2602.18663",
      "published": "2026-02-20T23:50:35+00:00",
      "categories": [
        "cs.RO",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18662",
      "title": "Large Causal Models for Temporal Causal Discovery",
      "abstract": "Causal discovery for both cross-sectional and temporal data has traditionally followed a dataset-specific paradigm, where a new model is fitted for each individual dataset. Such an approach limits the potential of multi-dataset pretraining. The concept of large causal models (LCMs) envisions a class of pre-trained neural architectures specifically designed for temporal causal discovery. Prior approaches are constrained to small variable counts, degrade with larger inputs, and rely heavily on synthetic data, limiting generalization. We propose a principled framework for LCMs, combining diverse synthetic generators with realistic time-series datasets, allowing learning at scale. Extensive experiments on synthetic, semi-synthetic and realistic benchmarks show that LCMs scale effectively to higher variable counts and deeper architectures while maintaining strong performance. Trained models achieve competitive or superior accuracy compared to classical and neural baselines, particularly in out-of-distribution settings, while enabling fast, single-pass inference. Results demonstrate LCMs as a promising foundation-model paradigm for temporal causal discovery. Experiments and model weights are available at https://github.com/kougioulis/LCM-paper/.",
      "authors": [
        "Nikolaos Kougioulis",
        "Nikolaos Gkorgkolis",
        "MingXue Wang",
        "Bora Caglayan",
        "Dario Simionato",
        "Andrea Tonon",
        "Ioannis Tsamardinos"
      ],
      "url": "https://arxiv.org/abs/2602.18662",
      "published": "2026-02-20T23:47:55+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18658",
      "title": "Communication-Efficient Personalized Adaptation via Federated-Local Model Merging",
      "abstract": "Parameter-efficient fine-tuning methods, such as LoRA, offer a practical way to adapt large vision and language models to client tasks. However, this becomes particularly challenging under task-level heterogeneity in federated deployments. In this regime, personalization requires balancing general knowledge with personalized knowledge, yet existing approaches largely rely on heuristic mixing rules and lack theoretical justification. Moreover, prior model merging approaches are also computation and communication intensive, making the process inefficient in federated settings. In this work, we propose Potara, a principled framework for federated personalization that constructs a personalized model for each client by merging two complementary models: (i) a federated model capturing general knowledge, and (ii) a local model capturing personalized knowledge. Through the construct of linear mode connectivity, we show that the expected task loss admits a variance trace upper bound, whose minimization yields closed-form optimal mixing weights that guarantee a tighter bound for the merged model than for either the federated or local model alone. Experiments on vision and language benchmarks show that Potara consistently improves personalization while reducing communication, leading to a strong performance-communication trade-off.",
      "authors": [
        "Yinan Zou",
        "Md Kamran Chowdhury Shisher",
        "Christopher G. Brinton",
        "Vishrant Tripathi"
      ],
      "url": "https://arxiv.org/abs/2602.18658",
      "published": "2026-02-20T23:29:28+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18652",
      "title": "PolyFrame at MWE-2026 AdMIRe 2: When Words Are Not Enough: Multimodal Idiom Disambiguation",
      "abstract": "Multimodal models struggle with idiomatic expressions due to their non-compositional meanings, a challenge amplified in multilingual settings. We introduced PolyFrame, our system for the MWE-2026 AdMIRe2 shared task on multimodal idiom disambiguation, featuring a unified pipeline for both image+text ranking (Subtask A) and text-only caption ranking (Subtask B). All model variants retain frozen CLIP-style vision--language encoders and the multilingual BGE M3 encoder, training only lightweight modules: a logistic regression and LLM-based sentence-type predictor, idiom synonym substitution, distractor-aware scoring, and Borda rank fusion. Starting from a CLIP baseline (26.7% Top-1 on English dev, 6.7% on English test), adding idiom-aware paraphrasing and explicit sentence-type classification increased performance to 60.0% Top-1 on English and 60.0% Top-1 (0.822 NDCG@5) in zero-shot transfer to Portuguese. On the multilingual blind test, our systems achieved average Top-1/NDCG scores of 0.35/0.73 for Subtask A and 0.32/0.71 for Subtask B across 15 languages. Ablation results highlight idiom-aware rewriting as the main contributor to performance, while sentence-type prediction and multimodal fusion enhance robustness. These findings suggest that effective idiom disambiguation is feasible without fine-tuning large multimodal encoders.",
      "authors": [
        "Nina Hosseini-Kivanani"
      ],
      "url": "https://arxiv.org/abs/2602.18652",
      "published": "2026-02-20T23:07:55+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.18650",
      "title": "NutriOrion: A Hierarchical Multi-Agent Framework for Personalized Nutrition Intervention Grounded in Clinical Guidelines",
      "abstract": "Personalized nutrition intervention for patients with multimorbidity is critical for improving health outcomes, yet remains challenging because it requires the simultaneous integration of heterogeneous clinical conditions, medications, and dietary guidelines. Single-agent large language models (LLMs) often suffer from context overload and attention dilution when processing such high-dimensional patient profiles. We introduce NutriOrion, a hierarchical multi-agent framework with a parallel-then-sequential reasoning topology. NutriOrion decomposes nutrition planning into specialized domain agents with isolated contexts to mitigate anchoring bias, followed by a conditional refinement stage. The framework includes a multi-objective prioritization algorithm to resolve conflicting dietary requirements and a safety constraint mechanism that injects pharmacological contraindications as hard negative constraints during synthesis, ensuring clinical validity by construction rather than post-hoc filtering. For clinical interoperability, NutriOrion maps synthesized insights into the ADIME standard and FHIR R4 resources. Evaluated on 330 stroke patients with multimorbidity, NutriOrion outperforms multiple baselines, including GPT-4.1 and alternative multi-agent architectures. It achieves a 12.1 percent drug-food interaction violation rate, demonstrates strong personalization with negative correlations (-0.26 to -0.35) between patient biomarkers and recommended risk nutrients, and yields clinically meaningful dietary improvements, including a 167 percent increase in fiber and a 27 percent increase in potassium, alongside reductions in sodium (9 percent) and sugars (12 percent).",
      "authors": [
        "Junwei Wu",
        "Runze Yan",
        "Hanqi Luo",
        "Darren Liu",
        "Minxiao Wang",
        "Kimberly L. Townsend",
        "Lydia S. Hartwig",
        "Derek Milketinas",
        "Xiao Hu",
        "Carl Yang"
      ],
      "url": "https://arxiv.org/abs/2602.18650",
      "published": "2026-02-20T22:55:29+00:00",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "id": "2602.18649",
      "title": "Global Low-Rank, Local Full-Rank: The Holographic Encoding of Learned Algorithms",
      "abstract": "Grokking -- the abrupt transition from memorization to generalization after extended training -- has been linked to the emergence of low-dimensional structure in learning dynamics. Yet neural network parameters inhabit extremely high-dimensional spaces. How can a low-dimensional learning process produce solutions that resist low-dimensional compression?   We investigate this question in multi-task modular arithmetic, training shared-trunk Transformers with separate heads for addition, multiplication, and a quadratic operation modulo 97. Across three model scales (315K--2.2M parameters) and five weight decay settings, we compare three reconstruction methods: per-matrix SVD, joint cross-matrix SVD, and trajectory PCA.   Across all conditions, grokking trajectories are confined to a 2--6 dimensional global subspace, while individual weight matrices remain effectively full-rank. Reconstruction from 3--5 trajectory PCs recovers over 95\\% of final accuracy, whereas both per-matrix and joint SVD fail at sub-full rank. Even when static decompositions capture most spectral energy, they destroy task-relevant structure.   These results show that learned algorithms are encoded through dynamically coordinated updates spanning all matrices, rather than localized low-rank components. We term this the holographic encoding principle: grokked solutions are globally low-rank in the space of learning directions but locally full-rank in parameter space, with implications for compression, interpretability, and understanding how neural networks encode computation.",
      "authors": [
        "Yongzhong Xu"
      ],
      "url": "https://arxiv.org/abs/2602.18649",
      "published": "2026-02-20T22:53:12+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18647",
      "title": "Information-Guided Noise Allocation for Efficient Diffusion Training",
      "abstract": "Training diffusion models typically relies on manually tuned noise schedules, which can waste computation on weakly informative noise regions and limit transfer across datasets, resolutions, and representations. We revisit noise schedule allocation through an information-theoretic lens and propose the conditional entropy rate of the forward process as a theoretically grounded, data-dependent diagnostic for identifying suboptimal noise-level allocation in existing schedules. Based on these insight, we introduce InfoNoise, a principled data-adaptive training noise schedule that replaces heuristic schedule design with an information-guided noise sampling distribution derived from entropy-reduction rates estimated from denoising losses already computed during training. Across natural-image benchmarks, InfoNoise matches or surpasses tuned EDM-style schedules, in some cases with a substantial training speedup (about $1.4\\times$ on CIFAR-10). On discrete datasets, where standard image-tuned schedules exhibit significant mismatch, it reaches superior quality in up to $3\\times$ fewer training steps. Overall, InfoNoise makes noise scheduling data-adaptive, reducing the need for per-dataset schedule design as diffusion models expand across domains.",
      "authors": [
        "Gabriel Raya",
        "Bac Nguyen",
        "Georgios Batzolis",
        "Yuhta Takida",
        "Dejan Stancevic",
        "Naoki Murata",
        "Chieh-Hsin Lai",
        "Yuki Mitsufuji",
        "Luca Ambrogioni"
      ],
      "url": "https://arxiv.org/abs/2602.18647",
      "published": "2026-02-20T22:45:01+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IT"
      ]
    },
    {
      "id": "2602.18645",
      "title": "Adaptive Time Series Reasoning via Segment Selection",
      "abstract": "Time series reasoning tasks often start with a natural language question and require targeted analysis of a time series. Evidence may span the full series or appear in a few short intervals, so the model must decide what to inspect. Most existing approaches encode the entire time series into a fixed representation before inference, regardless of whether or not the entire sequence is relevant. We introduce ARTIST, which formulates time-series reasoning as a sequential decision problem. ARTIST interleaves reasoning with adaptive temporal segment selection. It adopts a controller-reasoner architecture and uses reinforcement learning to train the controller role to select informative segments and the reasoner role to generate segment-conditioned reasoning traces and final answers. During inference, the model actively acquires task-relevant information instead of relying on a static summary of the full sequence. We use a novel hierarchical policy optimization approach for post-training that allows the model to excel in both segment selection and question-answering behavior. We evaluate ARTIST on six time-series reasoning benchmarks and compare it with large language models, vision-language models, and prior time-series reasoning systems. ARTIST improves average accuracy by 6.46 absolute percentage points over the strongest baseline. The largest gains appear on rare event localization and multi-segment reasoning tasks. Supervised fine-tuning improves performance, and reinforcement learning provides additional gains by optimizing question-adaptive segment selection. These results show that selective data use drives effective time-series reasoning.",
      "authors": [
        "Shvat Messica",
        "Jiawen Zhang",
        "Kevin Li",
        "Theodoros Tsiligkaridis",
        "Marinka Zitnik"
      ],
      "url": "https://arxiv.org/abs/2602.18645",
      "published": "2026-02-20T22:37:36+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18642",
      "title": "Auto Quantum Machine Learning for Multisource Classification",
      "abstract": "With fault-tolerant quantum computing on the horizon, there is growing interest in applying quantum computational methods to data-intensive scientific fields like remote sensing. Quantum machine learning (QML) has already demonstrated potential for such demanding tasks. One area of particular focus is quantum data fusion -- a complex data analysis problem that has attracted significant recent attention. In this work, we introduce an automated QML (AQML) approach for addressing data fusion challenges. We evaluate how AQML-generated quantum circuits perform compared to classical multilayer perceptrons (MLPs) and manually designed QML models when processing multisource inputs. Furthermore, we apply our method to change detection using the multispectral ONERA dataset, achieving improved accuracy over previously reported QML-based change detection results.",
      "authors": [
        "Tomasz Rybotycki",
        "Sebastian Dziura",
        "Piotr Gawron"
      ],
      "url": "https://arxiv.org/abs/2602.18642",
      "published": "2026-02-20T22:31:02+00:00",
      "categories": [
        "quant-ph",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18640",
      "title": "Decoding ML Decision: An Agentic Reasoning Framework for Large-Scale Ranking System",
      "abstract": "Modern large-scale ranking systems operate within a sophisticated landscape of competing objectives, operational constraints, and evolving product requirements. Progress in this domain is increasingly bottlenecked by the engineering context constraint: the arduous process of translating ambiguous product intent into reasonable, executable, verifiable hypotheses, rather than by modeling techniques alone. We present GEARS (Generative Engine for Agentic Ranking Systems), a framework that reframes ranking optimization as an autonomous discovery process within a programmable experimentation environment. Rather than treating optimization as static model selection, GEARS leverages Specialized Agent Skills to encapsulate ranking expert knowledge into reusable reasoning capabilities, enabling operators to steer systems via high-level intent vibe personalization. Furthermore, to ensure production reliability, the framework incorporates validation hooks to enforce statistical robustness and filter out brittle policies that overfit short-term signals. Experimental validation across diverse product surfaces demonstrates that GEARS consistently identifies superior, near-Pareto-efficient policies by synergizing algorithmic signals with deep ranking context while maintaining rigorous deployment stability.",
      "authors": [
        "Longfei Yun",
        "Yihan Wu",
        "Haoran Liu",
        "Xiaoxuan Liu",
        "Ziyun Xu",
        "Yi Wang",
        "Yang Xia",
        "Pengfei Wang",
        "Mingze Gao",
        "Yunxiang Wang",
        "Changfan Chen",
        "Junfeng Pan"
      ],
      "url": "https://arxiv.org/abs/2602.18640",
      "published": "2026-02-20T22:24:01+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.18639",
      "title": "Learning Invariant Visual Representations for Planning with Joint-Embedding Predictive World Models",
      "abstract": "World models learned from high-dimensional visual observations allow agents to make decisions and plan directly in latent space, avoiding pixel-level reconstruction. However, recent latent predictive architectures (JEPAs), including the DINO world model (DINO-WM), display a degradation in test time robustness due to their sensitivity to \"slow features\". These include visual variations such as background changes and distractors that are irrelevant to the task being solved. We address this limitation by augmenting the predictive objective with a bisimulation encoder that enforces control-relevant state equivalence, mapping states with similar transition dynamics to nearby latent states while limiting contributions from slow features. We evaluate our model on a simple navigation task under different test-time background changes and visual distractors. Across all benchmarks, our model consistently improves robustness to slow features while operating in a reduced latent space, up to 10x smaller than that of DINO-WM. Moreover, our model is agnostic to the choice of pretrained visual encoder and maintains robustness when paired with DINOv2, SimDINOv2, and iBOT features.",
      "authors": [
        "Leonardo F. Toso",
        "Davit Shadunts",
        "Yunyang Lu",
        "Nihal Sharma",
        "Donglin Zhan",
        "Nam H. Nguyen",
        "James Anderson"
      ],
      "url": "https://arxiv.org/abs/2602.18639",
      "published": "2026-02-20T22:19:46+00:00",
      "categories": [
        "cs.LG",
        "math.OC"
      ]
    },
    {
      "id": "2602.18637",
      "title": "Online decoding of rat self-paced locomotion speed from EEG using recurrent neural networks",
      "abstract": "$\\textit{Objective.}$ Accurate neural decoding of locomotion holds promise for advancing rehabilitation, prosthetic control, and understanding neural correlates of action. Recent studies have demonstrated decoding of locomotion kinematics across species on motorized treadmills. However, efforts to decode locomotion speed in more natural contexts$-$where pace is self-selected rather than externally imposed$-$are scarce, generally achieve only modest accuracy, and require intracranial implants. Here, we aim to decode self-paced locomotion speed non-invasively and continuously using cortex-wide EEG recordings from rats. $\\textit{Approach.}$ We introduce an asynchronous brain$-$computer interface (BCI) that processes a stream of 32-electrode skull-surface EEG (0.01$-$45 Hz) to decode instantaneous speed from a non-motorized treadmill during self-paced locomotion in head-fixed rats. Using recurrent neural networks and a dataset of over 133 h of recordings, we trained decoders to map ongoing EEG activity to treadmill speed. $\\textit{Main results.}$ Our decoding achieves a correlation of 0.88 ($R^2$ = 0.78) for speed, primarily driven by visual cortex electrodes and low-frequency ($< 8$ Hz) oscillations. Moreover, pre-training on a single session permitted decoding on other sessions from the same rat, suggesting uniform neural signatures that generalize across sessions but fail to transfer across animals. Finally, we found that cortical states not only carry information about current speed, but also about future and past dynamics, extending up to 1000 ms. $\\textit{Significance.}$ These findings demonstrate that self-paced locomotion speed can be decoded accurately and continuously from non-invasive, cortex-wide EEG. Our approach provides a framework for developing high-performing, non-invasive BCI systems and contributes to understanding distributed neural representations of action dynamics.",
      "authors": [
        "Alejandro de Miguel",
        "Nelson Totah",
        "Uri Maoz"
      ],
      "url": "https://arxiv.org/abs/2602.18637",
      "published": "2026-02-20T22:12:11+00:00",
      "categories": [
        "cs.LG",
        "q-bio.NC"
      ]
    },
    {
      "id": "2602.18633",
      "title": "DP-RFT: Learning to Generate Synthetic Text via Differentially Private Reinforcement Fine-Tuning",
      "abstract": "Differentially private (DP) synthetic data generation plays a pivotal role in developing large language models (LLMs) on private data, where data owners cannot provide eyes-on access to individual examples. Generating DP synthetic data typically involves a difficult trade-off. On one hand, DP finetuning methods train an LLM as a synthetic data generator with formal privacy guarantees, yet it still requires the raw content of private examples for model training. However, methods that avoid direct exposure to private data are bounded by an off-the-shelf, un-finetuned model, whose outputs often lack domain fidelity. Can we train an LLM to generate high-quality synthetic text without eyes-on access to individual private examples? In this work, we introduce Differentially Private Reinforcement Fine-Tuning (DP-RFT), an online reinforcement learning algorithm for synthetic data generation with LLMs. DP-RFT leverages DP-protected nearest-neighbor votes from an eyes-off private corpus as a reward signal for on-policy synthetic samples generated by an LLM. The LLM iteratively learns to generate synthetic data to maximize the expected DP votes through Proximal Policy Optimization (PPO). We evaluate DP-RFT for long-form and domain-specific synthetic data generation, such as news articles, meeting transcripts, and medical article abstracts. Our experiments show that DP-RFT closes the gap between private evolution and DP finetuning methods in terms of the fidelity and downstream utility of the generated synthetic data, while respecting the private data boundary.",
      "authors": [
        "Fangyuan Xu",
        "Sihao Chen",
        "Zinan Lin",
        "Taiwei Shi",
        "Sydney Graham",
        "Pei Zhou",
        "Mengting Wan",
        "Alex Stein",
        "Virginia Estellers",
        "Charles Chen",
        "Morris Sharp",
        "Richard Speyer",
        "Tadas Baltrusaitis",
        "Jennifer Neville",
        "Eunsol Choi",
        "Longqi Yang"
      ],
      "url": "https://arxiv.org/abs/2602.18633",
      "published": "2026-02-20T22:03:56+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.18630",
      "title": "Lost in Instructions: Study of Blind Users' Experiences with DIY Manuals and AI-Rewritten Instructions for Assembly, Operation, and Troubleshooting of Tangible Products",
      "abstract": "AI tools like ChatGPT and Be-My-AI are increasingly being used by blind individuals. Although prior work has explored their use in some Do-It-Yourself (DIY) tasks by blind individuals, little is known about how they use these tools and the available product-manual resources to assemble, operate, and troubleshoot physical or tangible products - tasks requiring spatial reasoning, structural understanding, and precise execution. We address this knowledge gap via an interview study and a usability study with blind participants, investigating how they leverage AI tools and product manuals for DIY tasks with physical products. Findings show that manuals are essential resources, but product-manual instructions are often inadequate for blind users. AI tools presently do not adequately address this insufficiency; in fact, we observed that they often exacerbate this issue with incomplete, incoherent, or misleading guidance. Lastly, we suggest improvements to AI tools for generating tailored instructions for blind users' DIY tasks involving tangible products.",
      "authors": [
        "Monalika Padma Reddy",
        "Aruna Balasubramanian",
        "Jiawei Zhou",
        "Xiaojun Bi",
        "IV Ramakrishnan",
        "Vikas Ashok"
      ],
      "url": "https://arxiv.org/abs/2602.18630",
      "published": "2026-02-20T21:45:27+00:00",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18628",
      "title": "Non-Interfering Weight Fields: Treating Model Parameters as a Continuously Extensible Function",
      "abstract": "Large language models store all learned knowledge in a single, fixed weight vector. Teaching a model new capabilities requires modifying those same weights, inevitably degrading previously acquired knowledge. This fundamental limitation, known as catastrophic forgetting, has resisted principled solutions for decades. Existing approaches treat weights as immutable artifacts that must be protected through techniques like regularization heuristics, replay buffers, or isolated adapter modules. The problem is none of these provide a structural guarantee against forgetting. In this work, we propose Non-Interfering Weight Fields (NIWF), a framework that replaces the fixed weight paradigm with a learned function that generates weight configurations on demand from a continuous capability coordinate space. After training on a task, we commit the occupied coordinate region by snapshotting the fields outputs on anchor points to enforce a functional lock during all future training. We validate NIWF on sequential instructionfollowing and code generation tasks using Mistral-7B, demonstrating zero forgetting on committed tasks with competitive perplexity on new tasks. The framework introduces the notion of software-like versioning for neural network intelligence, where capabilities can be committed, extended, composed, and rolled back without retraining.",
      "authors": [
        "Sarim Chaudhry"
      ],
      "url": "https://arxiv.org/abs/2602.18628",
      "published": "2026-02-20T21:43:26+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18627",
      "title": "Federated Learning-Assisted Optimization of Mobile Transmission with Digital Twins",
      "abstract": "A Digital Twin (DT) may protect information that is considered private to its associated physical system. For a mobile device, this may include its mobility profile, recent location(s), and experienced channel conditions. Online schedulers, however, typically use this type of information to perform tasks such as shared bandwidth and channel time slot assignments. In this paper, we consider three transmission scheduling problems with energy constraints, where such information is needed, and yet must remain private: minimizing total transmission time when (i) fixed-power or (ii) fixed-rate time slotting with power control is used, and (iii) maximizing the amount of data uploaded in a fixed time period. Using a real-time federated optimization framework, we show how the scheduler can iteratively interact only with the DTs to produce global fractional solutions to these problems, without the latter revealing their private information. Then dependent rounding is used to round the fractional solution into a channel transmission schedule for the physical systems. Experiments show consistent makespan reductions with near-zero bandwidth/energy violations and millisecond-order end-to-end runtime for typical edge server hardware. To the best of our knowledge, this is the first framework that enables channel sharing across DTs using operations that do not expose private data.",
      "authors": [
        "Mohammad Heydari",
        "Terence D. Todd",
        "Dongmei Zhao",
        "George Karakostas"
      ],
      "url": "https://arxiv.org/abs/2602.18627",
      "published": "2026-02-20T21:33:04+00:00",
      "categories": [
        "cs.NI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18623",
      "title": "Finding the Signal in the Noise: An Exploratory Study on Assessing the Effectiveness of AI and Accessibility Forums for Blind Users' Support Needs",
      "abstract": "Accessibility forums and, more recently, generative AI tools have become vital resources for blind users seeking solutions to computer-interaction issues and learning about new assistive technologies, screen reader features, tutorials, and software updates. Understanding user experiences with these resources is essential for identifying and addressing persistent support gaps. Towards this, we interviewed 14 blind users who regularly engage with forums and GenAI tools. Findings revealed that forums often overwhelm users with multiple overlapping topics, redundant or irrelevant content, and fragmented responses that must be mentally pieced together, increasing cognitive load. GenAI tools, while offering more direct assistance, introduce new barriers by producing unreliable answers, including overly verbose or fragmented guidance, fabricated information, and contradictory suggestions that fail to follow prompts, thereby heightening verification demands. Based on these insights, we outlined design opportunities to improve the reliability of assistive resources, aiming to provide blind users with more trustworthy and cognitively-manageable support.",
      "authors": [
        "Satwik Ram Kodandaram",
        "Jiawei Zhou",
        "Xiaojun Bi",
        "IV Ramakrishnan",
        "Vikas Ashok"
      ],
      "url": "https://arxiv.org/abs/2602.18623",
      "published": "2026-02-20T21:29:18+00:00",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18613",
      "title": "Diagnosing LLM Reranker Behavior Under Fixed Evidence Pools",
      "abstract": "Standard reranking evaluations study how a reranker orders candidates returned by an upstream retriever. This setup couples ranking behavior with retrieval quality, so differences in output cannot be attributed to the ranking policy alone. We introduce a controlled diagnostic that isolates reranking by using Multi-News clusters as fixed evidence pools. We limit each pool to exactly eight documents and pass identical inputs to all rankers. Within this setup, BM25 and MMR serve as interpretable reference points for lexical matching and diversity optimization. Across 345 clusters, we find that redundancy patterns vary by model: one LLM implicitly diversifies at larger selection budgets, while another increases redundancy. In contrast, LLMs underperform on lexical coverage at small selection budgets. As a result, LLM rankings diverge substantially from both baselines rather than consistently approximating either strategy. By eliminating retrieval variance, we can attribute these differences directly to the ranking policy. This diagnostic is model-agnostic and applicable to any ranker, including open source systems and proprietary APIs.",
      "authors": [
        "Baris Arat",
        "Emre Sefer"
      ],
      "url": "https://arxiv.org/abs/2602.18613",
      "published": "2026-02-20T21:07:32+00:00",
      "categories": [
        "cs.LG",
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "id": "2602.18607",
      "title": "Feedback-based Automated Verification in Vibe Coding of CAS Adaptation Built on Constraint Logic",
      "abstract": "In CAS adaptation, a challenge is to define the dynamic architecture of the system and changes in its behavior. Implementation-wise, this is projected into an adaptation mechanism, typically realized as an Adaptation Manager (AM). With the advances of generative LLMs, generating AM code based on system specification and desired AM behavior (partially in natural language) is a tempting opportunity. The recent introduction of vibe coding suggests a way to target the problem of the correctness of generated code by iterative testing and vibe coding feedback loops instead of direct code inspection.   In this paper, we show that generating an AM via vibe coding feedback loops is a viable option when the verification of the generated AM is based on a very precise formulation of the functional requirements. We specify these as constraints in a novel temporal logic FCL that allows us to express the behavior of traces with much finer granularity than classical LTL enables.   Furthermore, we show that by combining the adaptation and vibe coding feedback loops where the FCL constraints are evaluated for the current system state, we achieved good results in the experiments with generating AMs for two example systems from the CAS domain. Typically, just a few feedback loop iterations were necessary, each feeding the LLM with reports describing detailed violations of the constraints. This AM testing was combined with high run path coverage achieved by different initial settings.",
      "authors": [
        "Michal Töpfer",
        "František Plášil",
        "Tomáš Bureš",
        "Petr Hnětynka"
      ],
      "url": "https://arxiv.org/abs/2602.18607",
      "published": "2026-02-20T20:49:12+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.18603",
      "title": "Enhancing Goal Inference via Correction Timing",
      "abstract": "Corrections offer a natural modality for people to provide feedback to a robot, by (i) intervening in the robot's behavior when they believe the robot is failing (or will fail) the task objectives and (ii) modifying the robot's behavior to successfully fulfill the task. Each correction offers information on what the robot should and should not do, where the corrected behavior is more aligned with task objectives than the original behavior. Most prior work on learning from corrections involves interpreting a correction as a new demonstration (consisting of the modified robot behavior), or a preference (for the modified trajectory compared to the robot's original behavior). However, this overlooks one essential element of the correction feedback, which is the human's decision to intervene in the robot's behavior in the first place. This decision can be influenced by multiple factors including the robot's task progress, alignment with human expectations, dynamics, motion legibility, and optimality. In this work, we investigate whether the timing of this decision can offer a useful signal for inferring these task-relevant influences. In particular, we investigate three potential applications for this learning signal: (1) identifying features of a robot's motion that may prompt people to correct it, (2) quickly inferring the final goal of a human's correction based on the timing and initial direction of their correction motion, and (3) learning more precise constraints for task objectives. Our results indicate that correction timing results in improved learning for the first two of these applications. Overall, our work provides new insights on the value of correction timing as a signal for robot learning.",
      "authors": [
        "Anjiabei Wang",
        "Shuangge Wang",
        "Tesca Fitzgerald"
      ],
      "url": "https://arxiv.org/abs/2602.18603",
      "published": "2026-02-20T20:38:47+00:00",
      "categories": [
        "cs.RO",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18600",
      "title": "MapTab: Can MLLMs Master Constrained Route Planning?",
      "abstract": "Systematic evaluation of Multimodal Large Language Models (MLLMs) is crucial for advancing Artificial General Intelligence (AGI). However, existing benchmarks remain insufficient for rigorously assessing their constrained reasoning capabilities. To bridge this gap, we introduce MapTab, a multimodal benchmark specifically designed to evaluate constrained reasoning in MLLMs via route planning tasks. MapTab requires MLLMs to perceive and ground visual cues from map images alongside route attributes (e.g., Time, Price) from structured tabular data. The benchmark encompasses two scenarios: Metromap, covering metro networks in 160 cities across 52 countries, and Travelmap, depicting 168 representative tourist attractions from 19 countries. In total, MapTab comprises 328 images, 196,800 route planning queries, and 3,936 QA queries, all incorporating 4 key constraints: Time, Price, Comfort, and Reliability. Extensive evaluations across 15 representative MLLMs reveal that current models face substantial challenges in constrained multimodal reasoning. Notably, under conditions of limited visual perception, multimodal collaboration often underperforms compared to unimodal approaches. We believe MapTab provides a challenging and realistic testbed to advance the systematic evaluation of MLLMs.",
      "authors": [
        "Ziqiao Shang",
        "Lingyue Ge",
        "Yang Chen",
        "Shi-Yu Tian",
        "Zhenyu Huang",
        "Wenbo Fu",
        "Yu-Feng Li",
        "Lan-Zhe Guo"
      ],
      "url": "https://arxiv.org/abs/2602.18600",
      "published": "2026-02-20T20:22:18+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18591",
      "title": "Ensemble Prediction of Task Affinity for Efficient Multi-Task Learning",
      "abstract": "A fundamental problem in multi-task learning (MTL) is identifying groups of tasks that should be learned together. Since training MTL models for all possible combinations of tasks is prohibitively expensive for large task sets, a crucial component of efficient and effective task grouping is predicting whether a group of tasks would benefit from learning together, measured as per-task performance gain over single-task learning. In this paper, we propose ETAP (Ensemble Task Affinity Predictor), a scalable framework that integrates principled and data-driven estimators to predict MTL performance gains. First, we consider the gradient-based updates of shared parameters in an MTL model to measure the affinity between a pair of tasks as the similarity between the parameter updates based on these tasks. This linear estimator, which we call affinity score, naturally extends to estimating affinity within a group of tasks. Second, to refine these estimates, we train predictors that apply non-linear transformations and correct residual errors, capturing complex and non-linear task relationships. We train these predictors on a limited number of task groups for which we obtain ground-truth gain values via multi-task learning for each group. We demonstrate on benchmark datasets that ETAP improves MTL gain prediction and enables more effective task grouping, outperforming state-of-the-art baselines across diverse application domains.",
      "authors": [
        "Afiya Ayman",
        "Ayan Mukhopadhyay",
        "Aron Laszka"
      ],
      "url": "https://arxiv.org/abs/2602.18591",
      "published": "2026-02-20T19:57:38+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18589",
      "title": "DM4CT: Benchmarking Diffusion Models for Computed Tomography Reconstruction",
      "abstract": "Diffusion models have recently emerged as powerful priors for solving inverse problems. While computed tomography (CT) is theoretically a linear inverse problem, it poses many practical challenges. These include correlated noise, artifact structures, reliance on system geometry, and misaligned value ranges, which make the direct application of diffusion models more difficult than in domains like natural image generation. To systematically evaluate how diffusion models perform in this context and compare them with established reconstruction methods, we introduce DM4CT, a comprehensive benchmark for CT reconstruction. DM4CT includes datasets from both medical and industrial domains with sparse-view and noisy configurations. To explore the challenges of deploying diffusion models in practice, we additionally acquire a high-resolution CT dataset at a high-energy synchrotron facility and evaluate all methods under real experimental conditions. We benchmark ten recent diffusion-based methods alongside seven strong baselines, including model-based, unsupervised, and supervised approaches. Our analysis provides detailed insights into the behavior, strengths, and limitations of diffusion models for CT reconstruction. The real-world dataset is publicly available at zenodo.org/records/15420527, and the codebase is open-sourced at github.com/DM4CT/DM4CT.",
      "authors": [
        "Jiayang Shi",
        "Daniel M. Pelt",
        "K. Joost Batenburg"
      ],
      "url": "https://arxiv.org/abs/2602.18589",
      "published": "2026-02-20T19:54:47+00:00",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "id": "2602.18585",
      "title": "BloomNet: Exploring Single vs. Multiple Object Annotation for Flower Recognition Using YOLO Variants",
      "abstract": "Precise localization and recognition of flowers are crucial for advancing automated agriculture, particularly in plant phenotyping, crop estimation, and yield monitoring. This paper benchmarks several YOLO architectures such as YOLOv5s, YOLOv8n/s/m, and YOLOv12n for flower object detection under two annotation regimes: single-image single-bounding box (SISBB) and single-image multiple-bounding box (SIMBB). The FloralSix dataset, comprising 2,816 high-resolution photos of six different flower species, is also introduced. It is annotated for both dense (clustered) and sparse (isolated) scenarios. The models were evaluated using Precision, Recall, and Mean Average Precision (mAP) at IoU thresholds of 0.5 (mAP@0.5) and 0.5-0.95 (mAP@0.5:0.95). In SISBB, YOLOv8m (SGD) achieved the best results with Precision 0.956, Recall 0.951, mAP@0.5 0.978, and mAP@0.5:0.95 0.865, illustrating strong accuracy in detecting isolated flowers. With mAP@0.5 0.934 and mAP@0.5:0.95 0.752, YOLOv12n (SGD) outperformed the more complicated SIMBB scenario, proving robustness in dense, multi-object detection. Results show how annotation density, IoU thresholds, and model size interact: recall-optimized models perform better in crowded environments, whereas precision-oriented models perform best in sparse scenarios. In both cases, the Stochastic Gradient Descent (SGD) optimizer consistently performed better than alternatives. These density-sensitive sensors are helpful for non-destructive crop analysis, growth tracking, robotic pollination, and stress evaluation.",
      "authors": [
        "Safwat Nusrat",
        "Prithwiraj Bhattacharjee"
      ],
      "url": "https://arxiv.org/abs/2602.18585",
      "published": "2026-02-20T19:47:45+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18584",
      "title": "GIST: Targeted Data Selection for Instruction Tuning via Coupled Optimization Geometry",
      "abstract": "Targeted data selection has emerged as a crucial paradigm for efficient instruction tuning, aiming to identify a small yet influential subset of training examples for a specific target task. In practice, influence is often measured through the effect of an example on parameter updates. To make selection scalable, many approaches leverage optimizer statistics (e.g., Adam states) as an axis-aligned surrogate for update geometry (i.e., diagonal precondition), implicitly treating parameters as coordinate-wise independent. We show that this assumption breaks down in parameter-efficient fine-tuning (PEFT) methods such as LoRA. In this setting, the induced optimization geometry exhibits strong cross-parameter coupling with non-trivial off-diagonal interactions, while the task-relevant update directions are confined to a low-dimensional subspace. Motivated by this mismatch, we propose GIST (Gradient Isometric Subspace Transformation), a simple yet principled alternative that replaces axis-aligned scaling with robust subspace alignment. GIST recovers a task-specific subspace from validation gradients via spectral filtering (SVD), projects training gradients into this coupled subspace, and scores examples by their alignment with target directions.Extensive experiments have demonstrated that GIST matches or outperforms the state-of-the-art baseline with only 0.29% of the storage and 25% of the computational time under the same selection budget.",
      "authors": [
        "Guanghui Min",
        "Tianhao Huang",
        "Ke Wan",
        "Chen Chen"
      ],
      "url": "https://arxiv.org/abs/2602.18584",
      "published": "2026-02-20T19:44:24+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "id": "2602.18583",
      "title": "Luna-2: Scalable Single-Token Evaluation with Small Language Models",
      "abstract": "Real-time guardrails require evaluation that is accurate, cheap, and fast - yet today's default, LLM-as-a-judge (LLMAJ), is slow, expensive, and operationally non-deterministic due to multi-token generation. We present Luna-2, a novel architecture that leverages decoder-only small language models (SLMs) into a deterministic evaluation model to reliably compute complex task-specific LLMAJ metrics (e.g. toxicity, hallucination, tool selection quality, etc.) at an accuracy at par or higher than LLMAJ using frontier LLMs while drastically reducing the cost and latency of computation. Each metric is implemented as a lightweight LoRA/PEFT head on top of a shared SLM backbone, enabling hundreds of specialized metrics to run concurrently on a single GPU, deployable locally next to AI systems in a privacy-preserving and latency optimizing manner. Across content safety and hallucination benchmarks, Luna-2 matches the accuracy of state-of-the-art LLM-based evaluators while reducing inference cost by over 80x and latency by over 20x.   In this paper, we outline the model architecture, training methodology and report real-world empirical results on accuracy, latency, and throughput results. In production, Luna-2 is protecting 100M+ AI sessions and processing over 100B tokens per month for our customers with eval cost savings of over $30M annually.",
      "authors": [
        "Vatsal Goel",
        "Rishon Dsouza",
        "Nikhil Ega",
        "Amey Ramesh Rambatla",
        "Rob Friel",
        "Shuai Shao",
        "Yash Sheth"
      ],
      "url": "https://arxiv.org/abs/2602.18583",
      "published": "2026-02-20T19:43:58+00:00",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18582",
      "title": "Hierarchical Reward Design from Language: Enhancing Alignment of Agent Behavior with Human Specifications",
      "abstract": "When training artificial intelligence (AI) to perform tasks, humans often care not only about whether a task is completed but also how it is performed. As AI agents tackle increasingly complex tasks, aligning their behavior with human-provided specifications becomes critical for responsible AI deployment. Reward design provides a direct channel for such alignment by translating human expectations into reward functions that guide reinforcement learning (RL). However, existing methods are often too limited to capture nuanced human preferences that arise in long-horizon tasks. Hence, we introduce Hierarchical Reward Design from Language (HRDL): a problem formulation that extends classical reward design to encode richer behavioral specifications for hierarchical RL agents. We further propose Language to Hierarchical Rewards (L2HR) as a solution to HRDL. Experiments show that AI agents trained with rewards designed via L2HR not only complete tasks effectively but also better adhere to human specifications. Together, HRDL and L2HR advance the research on human-aligned AI agents.",
      "authors": [
        "Zhiqin Qian",
        "Ryan Diaz",
        "Sangwon Seo",
        "Vaibhav Unhelkar"
      ],
      "url": "https://arxiv.org/abs/2602.18582",
      "published": "2026-02-20T19:41:17+00:00",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18581",
      "title": "Learning Beyond Optimization: Stress-Gated Dynamical Regime Regulation in Autonomous Systems",
      "abstract": "Despite their apparent diversity, modern machine learning methods can be reduced to a remarkably simple core principle: learning is achieved by continuously optimizing parameters to minimize or maximize a scalar objective function. This paradigm has been extraordinarily successful for well-defined tasks where goals are fixed and evaluation criteria are explicit. However, if artificial systems are to move toward true autonomy-operating over long horizons and across evolving contexts-objectives may become ill-defined, shifting, or entirely absent. In such settings, a fundamental question emerges: in the absence of an explicit objective function, how can a system determine whether its ongoing internal dynamics are productive or pathological? And how should it regulate structural change without external supervision? In this work, we propose a dynamical framework for learning without an explicit objective. Instead of minimizing external error signals, the system evaluates the intrinsic health of its own internal dynamics and regulates structural plasticity accordingly. We introduce a two-timescale architecture that separates fast state evolution from slow structural adaptation, coupled through an internally generated stress variable that accumulates evidence of persistent dynamical dysfunction. Structural modification is then triggered not continuously, but as a state-dependent event. Through a minimal toy model, we demonstrate that this stress-regulated mechanism produces temporally segmented, self-organized learning episodes without reliance on externally defined goals. Our results suggest a possible route toward autonomous learning systems capable of self-assessment and internally regulated structural reorganization.",
      "authors": [
        "Sheng Ran"
      ],
      "url": "https://arxiv.org/abs/2602.18581",
      "published": "2026-02-20T19:39:56+00:00",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "physics.soc-ph"
      ]
    },
    {
      "id": "2602.18573",
      "title": "Multiclass Calibration Assessment and Recalibration of Probability Predictions via the Linear Log Odds Calibration Function",
      "abstract": "Machine-generated probability predictions are essential in modern classification tasks such as image classification. A model is well calibrated when its predicted probabilities correspond to observed event frequencies. Despite the need for multicategory recalibration methods, existing methods are limited to (i) comparing calibration between two or more models rather than directly assessing the calibration of a single model, (ii) requiring under-the-hood model access, e.g., accessing logit-scale predictions within the layers of a neural network, and (iii) providing output which is difficult for human analysts to understand. To overcome (i)-(iii), we propose Multicategory Linear Log Odds (MCLLO) recalibration, which (i) includes a likelihood ratio hypothesis test to assess calibration, (ii) does not require under-the-hood access to models and is thus applicable on a wide range of classification problems, and (iii) can be easily interpreted. We demonstrate the effectiveness of the MCLLO method through simulations and three real-world case studies involving image classification via convolutional neural network, obesity analysis via random forest, and ecology via regression modeling. We compare MCLLO to four comparator recalibration techniques utilizing both our hypothesis test and the existing calibration metric Expected Calibration Error to show that our method works well alone and in concert with other methods.",
      "authors": [
        "Amy Vennos",
        "Xin Xing",
        "Christopher T. Franck"
      ],
      "url": "https://arxiv.org/abs/2602.18573",
      "published": "2026-02-20T19:29:07+00:00",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "id": "2602.18572",
      "title": "Sub-City Real Estate Price Index Forecasting at Weekly Horizons Using Satellite Radar and News Sentiment",
      "abstract": "Reliable real estate price indicators are typically published at city level and low frequency, limiting their use for neighborhood-scale monitoring and long-horizon planning. We study whether sub-city price indices can be forecasted at weekly frequency by combining physical development signals from satellite radar with market narratives from news text. Using over 350,000 transactions from Dubai Land Department (2015-2025), we construct weekly price indices for 19 sub-city regions and evaluate forecasts from 2 to 34 weeks ahead. Our framework fuses regional transaction history with Sentinel-1 SAR backscatter, news sentiment combining lexical tone and semantic embeddings, and macroeconomic context. Results are strongly horizon dependent: at horizons up to 10 weeks, price history alone matches multimodal configurations, but beyond 14 weeks sentiment and SAR become critical. At long horizons (26-34 weeks), the full multimodal model reduces mean absolute error from 4.48 to 2.93 (35% reduction), with gains statistically significant across regions. Nonparametric learners consistently outperform deep architectures in this data regime. These findings establish benchmarks for weekly sub-city index forecasting and demonstrate that remote sensing and news sentiment materially improve predictability at strategically relevant horizons.",
      "authors": [
        "Baris Arat",
        "Hasan Fehmi Ates",
        "Emre Sefer"
      ],
      "url": "https://arxiv.org/abs/2602.18572",
      "published": "2026-02-20T19:25:48+00:00",
      "categories": [
        "cs.LG",
        "q-fin.ST"
      ]
    },
    {
      "id": "2602.18571",
      "title": "Debug2Fix: Supercharging Coding Agents with Interactive Debugging Capabilities",
      "abstract": "While significant progress has been made in automating various aspects of software development through coding agents, there is still significant room for improvement in their bug fixing capabilities. Debugging and investigation of runtime behavior remains largely a manual, developer-driven process. Popular coding agents typically rely on either static analysis of the code or iterative test-fix cycles, which is akin to trial and error debugging. We posit that there is a wealth of rich runtime information that developers routinely access while debugging code, which agents are currently deprived of due to design limitations. Despite how prevalent debuggers are in modern IDEs and command-line tools, they have surprisingly not made their way into coding agents. In this work, we introduce Debug2Fix, a novel framework that incorporates interactive debugging as a core component of a software engineering agent via a subagent architecture. We incorporate debuggers for Java and Python into our agent framework and evaluate against GitBug-Java and SWE-Bench-Live and achieve >20% improvement in performance compared to the baseline for certain models. Furthermore, using our framework, we're able to make weaker models like GPT-5 and Claude Haiku 4.5 match or exceed the performances of stronger models like Claude Sonnet 4.5, showing that better tool design is often just as important as switching to a more expensive model. Finally, we conduct systematic ablations demonstrating the importance of both the subagent architecture and debugger integration.",
      "authors": [
        "Spandan Garg",
        "Yufan Huang"
      ],
      "url": "https://arxiv.org/abs/2602.18571",
      "published": "2026-02-20T19:24:16+00:00",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18568",
      "title": "RPU -- A Reasoning Processing Unit",
      "abstract": "Large language model (LLM) inference performance is increasingly bottlenecked by the memory wall. While GPUs continue to scale raw compute throughput, they struggle to deliver scalable performance for memory bandwidth bound workloads. This challenge is amplified by emerging reasoning LLM applications, where long output sequences, low arithmetic intensity, and tight latency constraints demand significantly higher memory bandwidth. As a result, system utilization drops and energy per inference rises, highlighting the need for an optimized system architecture for scalable memory bandwidth.   To address these challenges we present the Reasoning Processing Unit (RPU), a chiplet-based architecture designed to address the challenges of the modern memory wall. RPU introduces: (1) A Capacity-Optimized High-Bandwidth Memory (HBM-CO) that trades capacity for lower energy and cost; (2) a scalable chiplet architecture featuring a bandwidth-first power and area provisioning design; and (3) a decoupled microarchitecture that separates memory, compute, and communication pipelines to sustain high bandwidth utilization. Simulation results show that RPU performs up to 45.3x lower latency and 18.6x higher throughput over an H100 system at ISO-TDP on Llama3-405B.",
      "authors": [
        "Matthew Adiletta",
        "Gu-Yeon Wei",
        "David Brooks"
      ],
      "url": "https://arxiv.org/abs/2602.18568",
      "published": "2026-02-20T19:13:19+00:00",
      "categories": [
        "cs.AR",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18435",
      "title": "Assigning Confidence: K-partition Ensembles",
      "abstract": "Clustering is widely used for unsupervised structure discovery, yet it offers limited insight into how reliable each individual assignment is. Diagnostics, such as convergence behavior or objective values, may reflect global quality, but they do not indicate whether particular instances are assigned confidently, especially for initialization-sensitive algorithms like k-means. This assignment-level instability can undermine both accuracy and robustness. Ensemble approaches improve global consistency by aggregating multiple runs, but they typically lack tools for quantifying pointwise confidence in a way that combines cross-run agreement with geometric support from the learned cluster structure. We introduce CAKE (Confidence in Assignments via K-partition Ensembles), a framework that evaluates each point using two complementary statistics computed over a clustering ensemble: assignment stability and consistency of local geometric fit. These are combined into a single, interpretable score in [0,1]. Our theoretical analysis shows that CAKE remains effective under noise and separates stable from unstable points. Experiments on synthetic and real-world datasets indicate that CAKE effectively highlights ambiguous points and stable core members, providing a confidence ranking that can guide filtering or prioritization to improve clustering quality.",
      "authors": [
        "Aggelos Semoglou",
        "John Pavlopoulos"
      ],
      "url": "https://arxiv.org/abs/2602.18435",
      "published": "2026-02-20T18:59:53+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18551",
      "title": "From Static Spectra to Operando Infrared Dynamics: Physics Informed Flow Modeling and a Benchmark",
      "abstract": "The Solid Electrolyte Interphase (SEI) is critical to the performance of lithium-ion batteries, yet its analysis via Operando Infrared (IR) spectroscopy remains experimentally complex and expensive, which limits its accessibility for standard research facilities. To overcome this bottleneck, we formulate a novel task, Operando IR Prediction, which aims to forecast the time-resolved evolution of spectral ``fingerprints'' from a single static spectrum. To facilitate this, we introduce OpIRSpec-7K, the first large-scale operando dataset comprising 7,118 high-quality samples across 10 distinct battery systems, alongside OpIRBench, a comprehensive evaluation benchmark with carefully designed protocols. Addressing the limitations of standard spectrum, video, and sequence models in capturing voltage-driven chemical dynamics and complex composition, we propose Aligned Bi-stream Chemical Constraint (ABCC), an end-to-end physics-aware framework. It reformulates MeanFlow and introduces a novel Chemical Flow to explicitly model reaction trajectories, employs a two-stream disentanglement mechanism for solvent-SEI separation, and enforces physics and spectrum constraints such as mass conservation and peak shifts. ABCC significantly outperforms state-of-the-art static, sequential, and generative baselines. ABCC even generalizes to unseen systems and enables interpretable downstream recovery of SEI formation pathways, supporting AI-driven electrochemical discovery.",
      "authors": [
        "Shuquan Ye",
        "Ben Fei",
        "Hongbin Xu",
        "Jiaying Lin",
        "Wanli Ouyang"
      ],
      "url": "https://arxiv.org/abs/2602.18551",
      "published": "2026-02-20T18:58:43+00:00",
      "categories": [
        "physics.chem-ph",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18431",
      "title": "SMaRT: Online Reusable Resource Assignment and an Application to Mediation in the Kenyan Judiciary",
      "abstract": "Motivated by the problem of assigning mediators to cases in the Kenyan judicial, we study an online resource allocation problem where incoming tasks (cases) must be immediately assigned to available, capacity-constrained resources (mediators). The resources differ in their quality, which may need to be learned. In addition, resources can only be assigned to a subset of tasks that overlaps to varying degrees with the subset of tasks other resources can be assigned to. The objective is to maximize task completion while satisfying soft capacity constraints across all the resources. The scale of the real-world problem poses substantial challenges, since there are over 2000 mediators and a multitude of combinations of geographic locations (87) and case types (12) that each mediator is qualified to work on. Together, these features, unknown quality of new resources, soft capacity constraints, and a high-dimensional state space, make existing scheduling and resource allocation algorithms either inapplicable or inefficient. We formalize the problem in a tractable manner using a quadratic program formulation for assignment and a multi-agent bandit-style framework for learning. We demonstrate the key properties and advantages of our new algorithm, SMaRT (Selecting Mediators that are Right for the Task), compared with baselines on stylized instances of the mediator allocation problem. We then consider its application to real-world data on cases and mediators from the Kenyan judiciary. SMaRT outperforms baselines and allows control over the tradeoff between the strictness of capacity constraints and overall case resolution rates, both in settings where mediator quality is known beforehand and in bandit-like settings where learning is part of the problem definition. On the strength of these results, we plan to run a randomized controlled trial with SMaRT in the judiciary in the near future.",
      "authors": [
        "Shafkat Farabi",
        "Didac Marti Pinto",
        "Wei Lu",
        "Manuel Ramos-Maqueda",
        "Sanmay Das",
        "Antoine Deeb",
        "Anja Sautmann"
      ],
      "url": "https://arxiv.org/abs/2602.18431",
      "published": "2026-02-20T18:58:05+00:00",
      "categories": [
        "cs.CY",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "id": "2602.18429",
      "title": "VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning",
      "abstract": "Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.",
      "authors": [
        "Harshul Raj Surana",
        "Arijit Maji",
        "Aryan Vats",
        "Akash Ghosh",
        "Sriparna Saha",
        "Amit Sheth"
      ],
      "url": "https://arxiv.org/abs/2602.18429",
      "published": "2026-02-20T18:53:07+00:00",
      "categories": [
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "id": "2602.18428",
      "title": "The Geometry of Noise: Why Diffusion Models Don't Need Noise Conditioning",
      "abstract": "Autonomous (noise-agnostic) generative models, such as Equilibrium Matching and blind diffusion, challenge the standard paradigm by learning a single, time-invariant vector field that operates without explicit noise-level conditioning. While recent work suggests that high-dimensional concentration allows these models to implicitly estimate noise levels from corrupted observations, a fundamental paradox remains: what is the underlying landscape being optimized when the noise level is treated as a random variable, and how can a bounded, noise-agnostic network remain stable near the data manifold where gradients typically diverge? We resolve this paradox by formalizing Marginal Energy, $E_{\\text{marg}}(\\mathbf{u}) = -\\log p(\\mathbf{u})$, where $p(\\mathbf{u}) = \\int p(\\mathbf{u}|t)p(t)dt$ is the marginal density of the noisy data integrated over a prior distribution of unknown noise levels. We prove that generation using autonomous models is not merely blind denoising, but a specific form of Riemannian gradient flow on this Marginal Energy. Through a novel relative energy decomposition, we demonstrate that while the raw Marginal Energy landscape possesses a $1/t^p$ singularity normal to the data manifold, the learned time-invariant field implicitly incorporates a local conformal metric that perfectly counteracts the geometric singularity, converting an infinitely deep potential well into a stable attractor. We also establish the structural stability conditions for sampling with autonomous models. We identify a ``Jensen Gap'' in noise-prediction parameterizations that acts as a high-gain amplifier for estimation errors, explaining the catastrophic failure observed in deterministic blind models. Conversely, we prove that velocity-based parameterizations are inherently stable because they satisfy a bounded-gain condition that absorbs posterior uncertainty into a smooth geometric drift.",
      "authors": [
        "Mojtaba Sahraee-Ardakan",
        "Mauricio Delbracio",
        "Peyman Milanfar"
      ],
      "url": "https://arxiv.org/abs/2602.18428",
      "published": "2026-02-20T18:49:00+00:00",
      "categories": [
        "cs.LG",
        "cs.CV",
        "eess.IV"
      ]
    },
    {
      "id": "2602.18425",
      "title": "RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering",
      "abstract": "Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.",
      "authors": [
        "Deniz Qian",
        "Hung-Ting Chen",
        "Eunsol Choi"
      ],
      "url": "https://arxiv.org/abs/2602.18425",
      "published": "2026-02-20T18:48:05+00:00",
      "categories": [
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "id": "2602.18420",
      "title": "SPQ: An Ensemble Technique for Large Language Model Compression",
      "abstract": "This study presents an ensemble technique, SPQ (SVD-Pruning-Quantization), for large language model (LLM) compression that combines variance-retained singular value decomposition (SVD), activation-based pruning, and post-training linear quantization. Each component targets a different source of inefficiency: i) pruning removes redundant neurons in MLP layers, ii) SVD reduces attention projections into compact low-rank factors, iii) and 8-bit quantization uniformly compresses all linear layers. At matched compression ratios, SPQ outperforms individual methods (SVD-only, pruning-only, or quantization-only) in perplexity, demonstrating the benefit of combining complementary techniques. Applied to LLaMA-2-7B, SPQ achieves up to 75% memory reduction while maintaining or improving perplexity (e.g., WikiText-2 5.47 to 4.91) and preserving accuracy on downstream benchmarks such as C4, TruthfulQA, and GSM8K. Compared to strong baselines like GPTQ and SparseGPT, SPQ offers competitive perplexity and accuracy while using less memory (6.86 GB vs. 7.16 GB for GPTQ). Moreover, SPQ improves inference throughput over GPTQ, achieving up to a 1.9x speedup, which further enhances its practicality for real-world deployment. The effectiveness of SPQ's robust compression through layer-aware and complementary compression techniques may provide practical deployment of LLMs in memory-constrained environments. Code is available at: https://github.com/JiaminYao/SPQ_LLM_Compression/",
      "authors": [
        "Jiamin Yao",
        "Eren Gultepe"
      ],
      "url": "https://arxiv.org/abs/2602.18420",
      "published": "2026-02-20T18:44:16+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.18419",
      "title": "Benchmarking Graph Neural Networks in Solving Hard Constraint Satisfaction Problems",
      "abstract": "Graph neural networks (GNNs) are increasingly applied to hard optimization problems, often claiming superiority over classical heuristics. However, such claims risk being unsolid due to a lack of standard benchmarks on truly hard instances. From a statistical physics perspective, we propose new hard benchmarks based on random problems. We provide these benchmarks, along with performance results from both classical heuristics and GNNs. Our fair comparison shows that classical algorithms still outperform GNNs. We discuss the challenges for neural networks in this domain. Future claims of superiority can be made more robust using our benchmarks, available at https://github.com/ArtLabBocconi/RandCSPBench.",
      "authors": [
        "Geri Skenderi",
        "Lorenzo Buffoni",
        "Francesco D'Amico",
        "David Machado",
        "Raffaele Marino",
        "Matteo Negri",
        "Federico Ricci-Tersenghi",
        "Carlo Lucibello",
        "Maria Chiara Angelini"
      ],
      "url": "https://arxiv.org/abs/2602.18419",
      "published": "2026-02-20T18:41:48+00:00",
      "categories": [
        "cond-mat.dis-nn",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18417",
      "title": "Subgroups of $U(d)$ Induce Natural RNN and Transformer Architectures",
      "abstract": "This paper presents a direct framework for sequence models with hidden states on closed subgroups of U(d). We use a minimal axiomatic setup and derive recurrent and transformer templates from a shared skeleton in which subgroup choice acts as a drop-in replacement for state space, tangent projection, and update map. We then specialize to O(d) and evaluate orthogonal-state RNN and transformer models on Tiny Shakespeare and Penn Treebank under parameter-matched settings. We also report a general linear-mixing extension in tangent space, which applies across subgroup choices and improves finite-budget performance in the current O(d) experiments.",
      "authors": [
        "Joshua Nunley"
      ],
      "url": "https://arxiv.org/abs/2602.18417",
      "published": "2026-02-20T18:35:43+00:00",
      "categories": [
        "cs.LG",
        "cs.CL"
      ]
    },
    {
      "id": "2602.18409",
      "title": "Unifying approach to uniform expressivity of graph neural networks",
      "abstract": "The expressive power of Graph Neural Networks (GNNs) is often analysed via correspondence to the Weisfeiler-Leman (WL) algorithm and fragments of first-order logic. Standard GNNs are limited to performing aggregation over immediate neighbourhoods or over global read-outs. To increase their expressivity, recent attempts have been made to incorporate substructural information (e.g. cycle counts and subgraph properties). In this paper, we formalize this architectural trend by introducing Template GNNs (T-GNNs), a generalized framework where node features are updated by aggregating over valid template embeddings from a specified set of graph templates. We propose a corresponding logic, Graded template modal logic (GML(T)), and generalized notions of template-based bisimulation and WL algorithm. We establish an equivalence between the expressive power of T-GNNs and GML(T), and provide a unifying approach for analysing GNN expressivity: we show how standard AC-GNNs and its recent variants can be interpreted as instantiations of T-GNNs.",
      "authors": [
        "Huan Luo",
        "Jonni Virtema"
      ],
      "url": "https://arxiv.org/abs/2602.18409",
      "published": "2026-02-20T18:18:48+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "id": "2602.18406",
      "title": "Latent Equivariant Operators for Robust Object Recognition: Promise and Challenges",
      "abstract": "Despite the successes of deep learning in computer vision, difficulties persist in recognizing objects that have undergone group-symmetric transformations rarely seen during training$\\unicode{x2013}$for example objects seen in unusual poses, scales, positions, or combinations thereof. Equivariant neural networks are a solution to the problem of generalizing across symmetric transformations, but require knowledge of transformations a priori. An alternative family of architectures proposes to learn equivariant operators in a latent space, from examples of symmetric transformations. Here, using simple datasets of rotated and translated noisy MNIST, we illustrate how such architectures can successfully be harnessed for out-of-distribution classification, thus overcoming the limitations of both traditional and equivariant networks. While conceptually enticing, we discuss challenges ahead on the path of scaling these architectures to more complex datasets.",
      "authors": [
        "Minh Dinh",
        "Stéphane Deny"
      ],
      "url": "https://arxiv.org/abs/2602.18406",
      "published": "2026-02-20T18:14:05+00:00",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18403",
      "title": "Scientific Knowledge-Guided Machine Learning for Vessel Power Prediction: A Comparative Study",
      "abstract": "Accurate prediction of main engine power is essential for vessel performance optimization, fuel efficiency, and compliance with emission regulations. Conventional machine learning approaches, such as Support Vector Machines, variants of Artificial Neural Networks (ANNs), and tree-based methods like Random Forests, Extra Tree Regressors, and XGBoost, can capture nonlinearities but often struggle to respect the fundamental propeller law relationship between power and speed, resulting in poor extrapolation outside the training envelope. This study introduces a hybrid modeling framework that integrates physics-based knowledge from sea trials with data-driven residual learning. The baseline component, derived from calm-water power curves of the form $P = cV^n$, captures the dominant power-speed dependence, while another, nonlinear, regressor is then trained to predict the residual power, representing deviations caused by environmental and operational conditions. By constraining the machine learning task to residual corrections, the hybrid model simplifies learning, improves generalization, and ensures consistency with the underlying physics. In this study, an XGBoost, a simple Neural Network, and a Physics-Informed Neural Network (PINN) coupled with the baseline component were compared to identical models without the baseline component. Validation on in-service data demonstrates that the hybrid model consistently outperformed a pure data-driven baseline in sparse data regions while maintaining similar performance in populated ones. The proposed framework provides a practical and computationally efficient tool for vessel performance monitoring, with applications in weather routing, trim optimization, and energy efficiency planning.",
      "authors": [
        "Orfeas Bourchas",
        "George Papalambrou"
      ],
      "url": "https://arxiv.org/abs/2602.18403",
      "published": "2026-02-20T18:12:14+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18401",
      "title": "Leakage and Second-Order Dynamics Improve Hippocampal RNN Replay",
      "abstract": "Biological neural networks (like the hippocampus) can internally generate \"replay\" resembling stimulus-driven activity. Recent computational models of replay use noisy recurrent neural networks (RNNs) trained to path-integrate. Replay in these networks has been described as Langevin sampling, but new modifiers of noisy RNN replay have surpassed this description. We re-examine noisy RNN replay as sampling to understand or improve it in three ways: (1) Under simple assumptions, we prove that the gradients replay activity should follow are time-varying and difficult to estimate, but readily motivate the use of hidden state leakage in RNNs for replay. (2) We confirm that hidden state adaptation (negative feedback) encourages exploration in replay, but show that it incurs non-Markov sampling that also slows replay. (3) We propose the first model of temporally compressed replay in noisy path-integrating RNNs through hidden state momentum, connect it to underdamped Langevin sampling, and show that, together with adaptation, it counters slowness while maintaining exploration. We verify our findings via path-integration of 2D triangular and T-maze paths and of high-dimensional paths of synthetic rat place cell activity.",
      "authors": [
        "Josue Casco-Rodriguez",
        "Nanda H. Krishna",
        "Richard G. Baraniuk"
      ],
      "url": "https://arxiv.org/abs/2602.18401",
      "published": "2026-02-20T18:07:09+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC",
        "stat.ML"
      ]
    },
    {
      "id": "2602.18396",
      "title": "PRISM-FCP: Byzantine-Resilient Federated Conformal Prediction via Partial Sharing",
      "abstract": "We propose PRISM-FCP (Partial shaRing and robust calIbration with Statistical Margins for Federated Conformal Prediction), a Byzantine-resilient federated conformal prediction framework that utilizes partial model sharing to improve robustness against Byzantine attacks during both model training and conformal calibration. Existing approaches address adversarial behavior only in the calibration stage, leaving the learned model susceptible to poisoned updates. In contrast, PRISM-FCP mitigates attacks end-to-end. During training, clients partially share updates by transmitting only $M$ of $D$ parameters per round. This attenuates the expected energy of an adversary's perturbation in the aggregated update by a factor of $M/D$, yielding lower mean-square error (MSE) and tighter prediction intervals. During calibration, clients convert nonconformity scores into characterization vectors, compute distance-based maliciousness scores, and downweight or filter suspected Byzantine contributions before estimating the conformal quantile. Extensive experiments on both synthetic data and the UCI Superconductivity dataset demonstrate that PRISM-FCP maintains nominal coverage guarantees under Byzantine attacks while avoiding the interval inflation observed in standard FCP with reduced communication, providing a robust and communication-efficient approach to federated uncertainty quantification.",
      "authors": [
        "Ehsan Lari",
        "Reza Arablouei",
        "Stefan Werner"
      ],
      "url": "https://arxiv.org/abs/2602.18396",
      "published": "2026-02-20T18:01:59+00:00",
      "categories": [
        "cs.LG",
        "eess.SP",
        "math.PR",
        "stat.AP",
        "stat.ML"
      ]
    },
    {
      "id": "2602.18386",
      "title": "Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO",
      "abstract": "Pure Pursuit (PP) is widely used in autonomous racing for real-time path tracking due to its efficiency and geometric clarity, yet performance is highly sensitive to how key parameters-lookahead distance and steering gain-are chosen. Standard velocity-based schedules adjust these only approximately and often fail to transfer across tracks and speed profiles. We propose a reinforcement-learning (RL) approach that jointly chooses the lookahead Ld and a steering gain g online using Proximal Policy Optimization (PPO). The policy observes compact state features (speed and curvature taps) and outputs (Ld, g) at each control step. Trained in F1TENTH Gym and deployed in a ROS 2 stack, the policy drives PP directly (with light smoothing) and requires no per-map retuning. Across simulation and real-car tests, the proposed RL-PP controller that jointly selects (Ld, g) consistently outperforms fixed-lookahead PP, velocity-scheduled adaptive PP, and an RL lookahead-only variant, and it also exceeds a kinematic MPC raceline tracker under our evaluated settings in lap time, path-tracking accuracy, and steering smoothness, demonstrating that policy-guided parameter tuning can reliably improve classical geometry-based control.",
      "authors": [
        "Mohamed Elgouhary",
        "Amr S. El-Wakeel"
      ],
      "url": "https://arxiv.org/abs/2602.18386",
      "published": "2026-02-20T17:48:21+00:00",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ]
    },
    {
      "id": "2602.18548",
      "title": "1D-Bench: A Benchmark for Iterative UI Code Generation with Visual Feedback in Real-World",
      "abstract": "Design-to-code translates high-fidelity UI designs into executable front-end implementations, but progress remains hard to compare due to inconsistent datasets, toolchains, and evaluation protocols. We introduce 1D-Bench, a benchmark grounded in real e-commerce workflows, where each instance provides a reference rendering and an exported intermediate representation that may contain extraction errors. 1D is short for one day, representing the efficient completion of design-to-code tasks in less than one day. Models take both as input, using the intermediate representation as structural cues while being evaluated against the reference rendering, which tests robustness to intermediate representation defects rather than literal adherence.   1D-Bench requires generating an executable React codebase under a fixed toolchain with an explicit component hierarchy, and defines a multi-round setting in which models iteratively apply component-level edits using execution feedback. Experiments on commercial and open-weight multimodal models show that iterative editing generally improves final performance by increasing rendering success and often improving visual similarity. We further conduct a pilot study on post-training with synthetic repair trajectories and reinforcement learning based editing, and observe limited and unstable gains that may stem from sparse terminal rewards and high-variance file-level updates.",
      "authors": [
        "Qiao Xu",
        "Yipeng Yu",
        "Chengxiao Feng",
        "Xu Liu"
      ],
      "url": "https://arxiv.org/abs/2602.18548",
      "published": "2026-02-20T17:46:51+00:00",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18384",
      "title": "FedZMG: Efficient Client-Side Optimization in Federated Learning",
      "abstract": "Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the \"intensity\" or \"bias\" shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CIFAR100, and Shakespeare datasets demonstrate that FedZMG achieves better convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, particularly in highly non-IID settings.",
      "authors": [
        "Fotios Zantalis",
        "Evangelos Zervas",
        "Grigorios Koulouras"
      ],
      "url": "https://arxiv.org/abs/2602.18384",
      "published": "2026-02-20T17:45:28+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18377",
      "title": "Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach",
      "abstract": "Quantum reservoir computers (QRCs) have emerged as a promising approach to quantum machine learning, since they utilize the natural dynamics of quantum systems for data processing and are simple to train. Here, we consider n-qubit quantum extreme learning machines (QELMs) with continuous-time reservoir dynamics. QELMs are memoryless QRCs capable of various ML tasks, including image classification and time series forecasting. We apply the Pauli transfer matrix (PTM) formalism to theoretically analyze the influence of encoding, reservoir dynamics, and measurement operations, including temporal multiplexing, on the QELM performance. This formalism makes explicit that the encoding determines the complete set of (nonlinear) features available to the QELM, while the quantum channels linearly transform these features before they are probed by the chosen measurement operators. Optimizing a QELM can therefore be cast as a decoding problem in which one shapes the channel-induced transformations such that task-relevant features become available to the regressor. The PTM formalism allows one to identify the classical representation of a QELM and thereby guide its design towards a given training objective. As a specific application, we focus on learning nonlinear dynamical systems and show that a QELM trained on such trajectories learns a surrogate-approximation to the underlying flow map.",
      "authors": [
        "Markus Gross",
        "Hans-Martin Rieser"
      ],
      "url": "https://arxiv.org/abs/2602.18377",
      "published": "2026-02-20T17:33:27+00:00",
      "categories": [
        "quant-ph",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18374",
      "title": "Zero-shot Interactive Perception",
      "abstract": "Interactive perception (IP) enables robots to extract hidden information in their workspace and execute manipulation plans by physically interacting with objects and altering the state of the environment -- crucial for resolving occlusions and ambiguity in complex, partially observable scenarios. We present Zero-Shot IP (ZS-IP), a novel framework that couples multi-strategy manipulation (pushing and grasping) with a memory-driven Vision Language Model (VLM) to guide robotic interactions and resolve semantic queries. ZS-IP integrates three key components: (1) an Enhanced Observation (EO) module that augments the VLM's visual perception with both conventional keypoints and our proposed pushlines -- a novel 2D visual augmentation tailored to pushing actions, (2) a memory-guided action module that reinforces semantic reasoning through context lookup, and (3) a robotic controller that executes pushing, pulling, or grasping based on VLM output. Unlike grid-based augmentations optimized for pick-and-place, pushlines capture affordances for contact-rich actions, substantially improving pushing performance. We evaluate ZS-IP on a 7-DOF Franka Panda arm across diverse scenes with varying occlusions and task complexities. Our experiments demonstrate that ZS-IP outperforms passive and viewpoint-based perception techniques such as Mark-Based Visual Prompting (MOKA), particularly in pushing tasks, while preserving the integrity of non-target elements.",
      "authors": [
        "Venkatesh Sripada",
        "Frank Guerin",
        "Amir Ghalamzan"
      ],
      "url": "https://arxiv.org/abs/2602.18374",
      "published": "2026-02-20T17:30:25+00:00",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18372",
      "title": "\"How Do I ...?\": Procedural Questions Predominate Student-LLM Chatbot Conversations",
      "abstract": "Providing scaffolding through educational chatbots built on Large Language Models (LLM) has potential risks and benefits that remain an open area of research. When students navigate impasses, they ask for help by formulating impasse-driven questions. Within interactions with LLM chatbots, such questions shape the user prompts and drive the pedagogical effectiveness of the chatbot's response. This paper focuses on such student questions from two datasets of distinct learning contexts: formative self-study, and summative assessed coursework. We analysed 6,113 messages from both learning contexts, using 11 different LLMs and three human raters to classify student questions using four existing schemas. On the feasibility of using LLMs as raters, results showed moderate-to-good inter-rater reliability, with higher consistency than human raters. The data showed that 'procedural' questions predominated in both learning contexts, but more so when students prepare for summative assessment. These results provide a basis on which to use LLMs for classification of student questions. However, we identify clear limitations in both the ability to classify with schemas and the value of doing so: schemas are limited and thus struggle to accommodate the semantic richness of composite prompts, offering only partial understanding the wider risks and benefits of chatbot integration. In the future, we recommend an analysis approach that captures the nuanced, multi-turn nature of conversation, for example, by applying methods from conversation analysis in discursive psychology.",
      "authors": [
        "Alexandra Neagu",
        "Marcus Messer",
        "Peter Johnson",
        "Rhodri Nelson"
      ],
      "url": "https://arxiv.org/abs/2602.18372",
      "published": "2026-02-20T17:27:41+00:00",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18364",
      "title": "Quantum Maximum Likelihood Prediction via Hilbert Space Embeddings",
      "abstract": "Recent works have proposed various explanations for the ability of modern large language models (LLMs) to perform in-context prediction. We propose an alternative conceptual viewpoint from an information-geometric and statistical perspective. Motivated by Bach[2023], we model training as learning an embedding of probability distributions into the space of quantum density operators, and in-context learning as maximum-likelihood prediction over a specified class of quantum models. We provide an interpretation of this predictor in terms of quantum reverse information projection and quantum Pythagorean theorem when the class of quantum models is sufficiently expressive. We further derive non-asymptotic performance guarantees in terms of convergence rates and concentration inequalities, both in trace norm and quantum relative entropy. Our approach provides a unified framework to handle both classical and quantum LLMs.",
      "authors": [
        "Sreejith Sreekumar",
        "Nir Weinberger"
      ],
      "url": "https://arxiv.org/abs/2602.18364",
      "published": "2026-02-20T17:16:38+00:00",
      "categories": [
        "cs.IT",
        "cs.LG",
        "quant-ph",
        "stat.ML"
      ]
    },
    {
      "id": "2602.18351",
      "title": "Validating Political Position Predictions of Arguments",
      "abstract": "Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \\textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $α=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($α=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.",
      "authors": [
        "Jordan Robinson",
        "Angus R. Williams",
        "Katie Atkinson",
        "Anthony G. Cohn"
      ],
      "url": "https://arxiv.org/abs/2602.18351",
      "published": "2026-02-20T17:03:44+00:00",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18350",
      "title": "Quantum-enhanced satellite image classification",
      "abstract": "We demonstrate the application of a quantum feature extraction method to enhance multi-class image classification for space applications. By harnessing the dynamics of many-body spin Hamiltonians, the method generates expressive quantum features that, when combined with classical processing, lead to quantum-enhanced classification accuracy. Using a strong and well-established ResNet50 baseline, we achieved a maximum classical accuracy of 83%, which can be improved to 84% with a transfer learning approach. In contrast, applying our quantum-classical method the performance is increased to 87% accuracy, demonstrating a clear and reproducible improvement over robust classical approaches. Implemented on several of IBM's quantum processors, our hybrid quantum-classical approach delivers consistent gains of 2-3% in absolute accuracy. These results highlight the practical potential of current and near-term quantum processors in high-stakes, data-driven domains such as satellite imaging and remote sensing, while suggesting broader applicability in real-world machine learning tasks.",
      "authors": [
        "Qi Zhang",
        "Anton Simen",
        "Carlos Flores-Garrigós",
        "Gabriel Alvarado Barrios",
        "Paolo A. Erdman",
        "Enrique Solano",
        "Aaron C. Kemp",
        "Vincent Beltrani",
        "Vedangi Pathak",
        "Hamed Mohammadbagherpoor"
      ],
      "url": "https://arxiv.org/abs/2602.18350",
      "published": "2026-02-20T17:02:16+00:00",
      "categories": [
        "quant-ph",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18348",
      "title": "Explaining AutoClustering: Uncovering Meta-Feature Contribution in AutoML for Clustering",
      "abstract": "AutoClustering methods aim to automate unsupervised learning tasks, including algorithm selection (AS), hyperparameter optimization (HPO), and pipeline synthesis (PS), by often leveraging meta-learning over dataset meta-features. While these systems often achieve strong performance, their recommendations are often difficult to justify: the influence of dataset meta-features on algorithm and hyperparameter choices is typically not exposed, limiting reliability, bias diagnostics, and efficient meta-feature engineering. This limits reliability and diagnostic insight for further improvements. In this work, we investigate the explainability of the meta-models in AutoClustering. We first review 22 existing methods and organize their meta-features into a structured taxonomy. We then apply a global explainability technique (i.e., Decision Predicate Graphs) to assess feature importance within meta-models from selected frameworks. Finally, we use local explainability tools such as SHAP (SHapley Additive exPlanations) to analyse specific clustering decisions. Our findings highlight consistent patterns in meta-feature relevance, identify structural weaknesses in current meta-learning strategies that can distort recommendations, and provide actionable guidance for more interpretable Automated Machine Learning (AutoML) design. This study therefore offers a practical foundation for increasing decision transparency in unsupervised learning automation.",
      "authors": [
        "Matheus Camilo da Silva",
        "Leonardo Arrighi",
        "Ana Carolina Lorena",
        "Sylvio Barbon Junior"
      ],
      "url": "https://arxiv.org/abs/2602.18348",
      "published": "2026-02-20T17:01:25+00:00",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "id": "2602.18346",
      "title": "Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System",
      "abstract": "In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.",
      "authors": [
        "Pavithra PM Nair",
        "Preethu Rose Anish"
      ],
      "url": "https://arxiv.org/abs/2602.18346",
      "published": "2026-02-20T16:57:44+00:00",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18333",
      "title": "On the \"Induction Bias\" in Sequence Models",
      "abstract": "Despite the remarkable practical success of transformer-based language models, recent work has raised concerns about their ability to perform state tracking. In particular, a growing body of literature has shown this limitation primarily through failures in out-of-distribution (OOD) generalization, such as length extrapolation. In this work, we shift attention to the in-distribution implications of these limitations. We conduct a large-scale experimental study of the data efficiency of transformers and recurrent neural networks (RNNs) across multiple supervision regimes. We find that the amount of training data required by transformers grows much more rapidly with state-space size and sequence length than for RNNs. Furthermore, we analyze the extent to which learned state-tracking mechanisms are shared across different sequence lengths. We show that transformers exhibit negligible or even detrimental weight sharing across lengths, indicating that they learn length-specific solutions in isolation. In contrast, recurrent models exhibit effective amortized learning by sharing weights across lengths, allowing data from one sequence length to improve performance on others. Together, these results demonstrate that state tracking remains a fundamental challenge for transformers, even when training and evaluation distributions match.",
      "authors": [
        "M. Reza Ebrahimi",
        "Michaël Defferrard",
        "Sunny Panchal",
        "Roland Memisevic"
      ],
      "url": "https://arxiv.org/abs/2602.18333",
      "published": "2026-02-20T16:39:07+00:00",
      "categories": [
        "cs.LG",
        "cs.CL"
      ]
    },
    {
      "id": "2602.18326",
      "title": "Predicting Contextual Informativeness for Vocabulary Learning using Deep Learning",
      "abstract": "We describe a modern deep learning system that automatically identifies informative contextual examples (\\qu{contexts}) for first language vocabulary instruction for high school student. Our paper compares three modeling approaches: (i) an unsupervised similarity-based strategy using MPNet's uniformly contextualized embeddings, (ii) a supervised framework built on instruction-aware, fine-tuned Qwen3 embeddings with a nonlinear regression head and (iii) model (ii) plus handcrafted context features. We introduce a novel metric called the Retention Competency Curve to visualize trade-offs between the discarded proportion of good contexts and the \\qu{good-to-bad} contexts ratio providing a compact, unified lens on model performance. Model (iii) delivers the most dramatic gains with performance of a good-to-bad ratio of 440 all while only throwing out 70\\% of the good contexts. In summary, we demonstrate that a modern embedding model on neural network architecture, when guided by human supervision, results in a low-cost large supply of near-perfect contexts for teaching vocabulary for a variety of target words.",
      "authors": [
        "Tao Wu",
        "Adam Kapelner"
      ],
      "url": "https://arxiv.org/abs/2602.18326",
      "published": "2026-02-20T16:32:14+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.18324",
      "title": "PsihoRo: Depression and Anxiety Romanian Text Corpus",
      "abstract": "Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.",
      "authors": [
        "Alexandra Ciobotaru",
        "Ana-Maria Bucur",
        "Liviu P. Dinu"
      ],
      "url": "https://arxiv.org/abs/2602.18324",
      "published": "2026-02-20T16:24:23+00:00",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "id": "2602.18319",
      "title": "Robo-Saber: Generating and Simulating Virtual Reality Players",
      "abstract": "We present the first motion generation system for playtesting virtual reality (VR) games. Our player model generates VR headset and handheld controller movements from in-game object arrangements, guided by style exemplars and aligned to maximize simulated gameplay score. We train on the large BOXRR-23 dataset and apply our framework on the popular VR game Beat Saber. The resulting model Robo-Saber produces skilled gameplay and captures diverse player behaviors, mirroring the skill levels and movement patterns specified by input style exemplars. Robo-Saber demonstrates promise in synthesizing rich gameplay data for predictive applications and enabling a physics-based whole-body VR playtesting agent.",
      "authors": [
        "Nam Hee Kim",
        "Jingjing May Liu",
        "Jaakko Lehtinen",
        "Perttu Hämäläinen",
        "James F. O'Brien",
        "Xue Bin Peng"
      ],
      "url": "https://arxiv.org/abs/2602.18319",
      "published": "2026-02-20T16:19:19+00:00",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18313",
      "title": "Clapeyron Neural Networks for Single-Species Vapor-Liquid Equilibria",
      "abstract": "Machine learning (ML) approaches have shown promising results for predicting molecular properties relevant for chemical process design. However, they are often limited by scarce experimental property data and lack thermodynamic consistency. As such, thermodynamics-informed ML, i.e., incorporating thermodynamic relations into the loss function as regularization term for training, has been proposed. We herein transfer the concept of thermodynamics-informed graph neural networks (GNNs) from the Gibbs-Duhem to the Clapeyron equation, predicting several pure component properties in a multi-task manner, namely: vapor pressure, liquid molar volume, vapor molar volume and enthalpy of vaporization. We find improved prediction accuracy of the Clapeyron-GNN compared to the single-task learning setting, and improved approximation of the Clapeyron equation compared to the purely data-driven multi-task learning setting. In fact, we observe the largest improvement in prediction accuracy for the properties with the lowest availability of data, making our model promising for practical application in data scarce scenarios of chemical engineering practice.",
      "authors": [
        "Jan Pavšek",
        "Alexander Mitsos",
        "Elvis J. Sim",
        "Jan G. Rittig"
      ],
      "url": "https://arxiv.org/abs/2602.18313",
      "published": "2026-02-20T16:11:42+00:00",
      "categories": [
        "physics.chem-ph",
        "cs.LG"
      ]
    },
    {
      "id": "2602.18308",
      "title": "JPmHC Dynamical Isometry via Orthogonal Hyper-Connections",
      "abstract": "Recent advances in deep learning, exemplified by Hyper-Connections (HC), have expanded the residual connection paradigm by introducing wider residual streams and diverse connectivity patterns. While these innovations yield significant performance gains, they compromise the identity mapping property of residual connections, leading to training instability, limited scalability, and increased memory overhead. To address these challenges, we propose JPmHC (Jacobian-spectrum Preserving manifold-constrained Hyper-Connections), a framework that replaces identity skips with a trainable linear mixer acting on n parallel streams while explicitly controlling gradient conditioning. By constraining the mixer M on operator-norm-bounded manifolds (e.g., bistochastic, Stiefel, Grassmann), JPmHC prevents gradient pathologies and enhances stability. JPmHC introduces three key contributions: (i) a free-probability analysis that predicts Jacobian spectra for structured skips, providing actionable design rules for mixer selection; (ii) memory-efficient implicit differentiation for fixed-point projections, reducing activation memory and synchronization overhead; and (iii) a Stiefel-constrained mixer via Cayley transforms, ensuring orthogonality without post-hoc normalization. Empirical evaluations on ARC-AGI demonstrate that JPmHC achieves faster convergence, higher accuracy, and lower computational cost compared to bistochastic baselines. As a flexible and scalable extension of HC, JPmHC advances spectrum-aware, stable, and efficient deep learning, offering insights into topological architecture design and foundational model evolution.",
      "authors": [
        "Biswa Sengupta",
        "Jinhua Wang",
        "Leo Brunswic"
      ],
      "url": "https://arxiv.org/abs/2602.18308",
      "published": "2026-02-20T16:06:01+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18307",
      "title": "VeriSoftBench: Repository-Scale Formal Verification Benchmarks for Lean",
      "abstract": "Large language models have achieved striking results in interactive theorem proving, particularly in Lean. However, most benchmarks for LLM-based proof automation are drawn from mathematics in the Mathlib ecosystem, whereas proofs in software verification are developed inside definition-rich codebases with substantial project-specific libraries. We introduce VeriSoftBench, a benchmark of 500 Lean 4 proof obligations drawn from open-source formal-methods developments and packaged to preserve realistic repository context and cross-file dependencies. Our evaluation of frontier LLMs and specialized provers yields three observations. First, provers tuned for Mathlib-style mathematics transfer poorly to this repository-centric setting. Second, success is strongly correlated with transitive repository dependence: tasks whose proofs draw on large, multi-hop dependency closures are less likely to be solved. Third, providing curated context restricted to a proof's dependency closure improves performance relative to exposing the full repository, but nevertheless leaves substantial room for improvement. Our benchmark and evaluation suite are released at https://github.com/utopia-group/VeriSoftBench.",
      "authors": [
        "Yutong Xin",
        "Qiaochu Chen",
        "Greg Durrett",
        "Işil Dillig"
      ],
      "url": "https://arxiv.org/abs/2602.18307",
      "published": "2026-02-20T16:05:06+00:00",
      "categories": [
        "cs.SE",
        "cs.CL",
        "cs.LG",
        "cs.PL"
      ]
    },
    {
      "id": "2602.18301",
      "title": "On the Semantic and Syntactic Information Encoded in Proto-Tokens for One-Step Text Reconstruction",
      "abstract": "Autoregressive large language models (LLMs) generate text token-by-token, requiring n forward passes to produce a sequence of length n. Recent work, Exploring the Latent Capacity of LLMs for One-Step Text Reconstruction (Mezentsev and Oseledets), shows that frozen LLMs can reconstruct hundreds of tokens from only two learned proto-tokens in a single forward pass, suggesting a path beyond the autoregressive paradigm. In this paper, we study what information these proto-tokens encode and how they behave under reconstruction and controlled constraints. We perform a series of experiments aimed at disentangling semantic and syntactic content in the two proto-tokens, analyzing stability properties of the e-token, and visualizing attention patterns to the e-token during reconstruction. Finally, we test two regularization schemes for \"imposing\" semantic structure on the e-token using teacher embeddings, including an anchor-based loss and a relational distillation objective. Our results indicate that the m-token tends to capture semantic information more strongly than the e-token under standard optimization; anchor-based constraints trade off sharply with reconstruction accuracy; and relational distillation can transfer batch-level semantic relations into the proto-token space without sacrificing reconstruction quality, supporting the feasibility of future non-autoregressive seq2seq systems that predict proto-tokens as an intermediate representation.",
      "authors": [
        "Ivan Bondarenko",
        "Egor Palkin",
        "Fedor Tikunov"
      ],
      "url": "https://arxiv.org/abs/2602.18301",
      "published": "2026-02-20T15:54:10+00:00",
      "categories": [
        "cs.LG",
        "cs.CL"
      ]
    },
    {
      "id": "2602.18297",
      "title": "Analyzing and Improving Chain-of-Thought Monitorability Through Information Theory",
      "abstract": "Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation. In this paper, we use information-theoretic analysis to show that non-zero mutual information between CoT and output is a necessary but not sufficient condition for CoT monitorability. We identify two sources of approximation error that may undermine the performance of CoT monitors in practice: information gap, which measures the extent to which the monitor can extract the information available in CoT, and elicitation error, which measures the extent to which the monitor approximates the optimal monitoring function. We further demonstrate that CoT monitorability can be systematically improved through targeted training objectives. To this end, we propose two complementary approaches: (a) an oracle-based method that directly rewards the monitored model for producing CoTs that maximize monitor accuracy, and (b) a more practical, label-free approach that maximizes conditional mutual information between outputs and CoTs. Across multiple different environments, we show both methods significantly improve monitor accuracy while preventing CoT degeneration even when training against a monitor, thereby mitigating reward hacking when the task reward is imperfectly specified.",
      "authors": [
        "Usman Anwar",
        "Tim Bakker",
        "Dana Kianfar",
        "Cristina Pinneri",
        "Christos Louizos"
      ],
      "url": "https://arxiv.org/abs/2602.18297",
      "published": "2026-02-20T15:50:30+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IT"
      ]
    },
    {
      "id": "2602.18296",
      "title": "Context-Aware Mapping of 2D Drawing Annotations to 3D CAD Features Using LLM-Assisted Reasoning for Manufacturing Automation",
      "abstract": "Manufacturing automation in process planning, inspection planning, and digital-thread integration depends on a unified specification that binds the geometric features of a 3D CAD model to the geometric dimensioning and tolerancing (GD&T) callouts, datum definitions, and surface requirements carried by the corresponding 2D engineering drawing. Although Model-Based Definition (MBD) allows such specifications to be embedded directly in 3D models, 2D drawings remain the primary carrier of manufacturing intent in automotive, aerospace, shipbuilding, and heavy-machinery industries. Correctly linking drawing annotations to the corresponding 3D features is difficult because of contextual ambiguity, repeated feature patterns, and the need for transparent and traceable decisions. This paper presents a deterministic-first, context-aware framework that maps 2D drawing entities to 3D CAD features to produce a unified manufacturing specification. Drawing callouts are first semantically enriched and then scored against candidate features using an interpretable metric that combines type compatibility, tolerance-aware dimensional agreement, and conservative context consistency, along with engineering-domain heuristics. When deterministic scoring cannot resolve an ambiguity, the system escalates to multimodal and constrained large-language-model reasoning, followed by a single human-in-the-loop (HITL) review step. Experiments on 20 real CAD-drawing pairs achieve a mean precision of 83.67%, recall of 90.46%, and F1 score of 86.29%. An ablation study shows that each pipeline component contributes to overall accuracy, with the full system outperforming all reduced variants. By prioritizing deterministic rules, clear decision tracking, and retaining unresolved cases for human review, the framework provides a practical foundation for downstream manufacturing automation in real-world industrial environments.",
      "authors": [
        "Muhammad Tayyab Khan",
        "Lequn Chen",
        "Wenhe Feng",
        "Seung Ki Moon"
      ],
      "url": "https://arxiv.org/abs/2602.18296",
      "published": "2026-02-20T15:46:57+00:00",
      "categories": [
        "cs.CE",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18292",
      "title": "Decoding as Optimisation on the Probability Simplex: From Top-K to Top-P (Nucleus) to Best-of-K Samplers",
      "abstract": "Decoding sits between a language model and everything we do with it, yet it is still treated as a heuristic knob-tuning exercise. We argue decoding should be understood as a principled optimisation layer: at each token, we solve a regularised problem over the probability simplex that trades off model score against structural preferences and constraints. This single template recovers greedy decoding, Softmax sampling, Top-K, Top-P, and Sparsemax-style sparsity as special cases, and explains their common structure through optimality conditions. More importantly, the framework makes it easy to invent new decoders without folklore. We demonstrate this by designing Best-of-K (BoK), a KL-anchored coverage objective aimed at multi-sample pipelines (self-consistency, reranking, verifier selection). BoK targets the probability of covering good alternatives within a fixed K-sample budget and improves empirical performance. We show that such samples can improve accuracy by, for example, +18.6% for Qwen2.5-Math-7B on MATH500 at high sampling temperatures.",
      "authors": [
        "Xiaotong Ji",
        "Rasul Tutunov",
        "Matthieu Zimmer",
        "Haitham Bou-Ammar"
      ],
      "url": "https://arxiv.org/abs/2602.18292",
      "published": "2026-02-20T15:38:16+00:00",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18291",
      "title": "Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies",
      "abstract": "Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \\underline{O}nline off-policy \\underline{MA}RL framework using \\underline{D}iffusion policies (\\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\\times$ to $5\\times$ improvement in sample efficiency.",
      "authors": [
        "Zhuoran Li",
        "Hai Zhong",
        "Xun Wang",
        "Qingxin Xia",
        "Lihua Zhang",
        "Longbo Huang"
      ],
      "url": "https://arxiv.org/abs/2602.18291",
      "published": "2026-02-20T15:38:02+00:00",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "id": "2602.18540",
      "title": "Rodent-Bench",
      "abstract": "We present Rodent-Bench, a novel benchmark designed to evaluate the ability of Multimodal Large Language Models (MLLMs) to annotate rodent behaviour footage. We evaluate state-of-the-art MLLMs, including Gemini-2.5-Pro, Gemini-2.5-Flash and Qwen-VL-Max, using this benchmark and find that none of these models perform strongly enough to be used as an assistant for this task. Our benchmark encompasses diverse datasets spanning multiple behavioral paradigms including social interactions, grooming, scratching, and freezing behaviors, with videos ranging from 10 minutes to 35 minutes in length. We provide two benchmark versions to accommodate varying model capabilities and establish standardized evaluation metrics including second-wise accuracy, macro F1, mean average precision, mutual information, and Matthew's correlation coefficient. While some models show modest performance on certain datasets (notably grooming detection), overall results reveal significant challenges in temporal segmentation, handling extended video sequences, and distinguishing subtle behavioral states. Our analysis identifies key limitations in current MLLMs for scientific video annotation and provides insights for future model development. Rodent-Bench serves as a foundation for tracking progress toward reliable automated behavioral annotation in neuroscience research.",
      "authors": [
        "Thomas Heap",
        "Laurence Aitchison",
        "Emma Cahill",
        "Adriana Casado Rodriguez"
      ],
      "url": "https://arxiv.org/abs/2602.18540",
      "published": "2026-02-20T15:14:38+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.20028",
      "title": "Descriptor: Dataset of Parasitoid Wasps and Associated Hymenoptera (DAPWH)",
      "abstract": "Accurate taxonomic identification is the cornerstone of biodiversity monitoring and agricultural management, particularly for the hyper-diverse superfamily Ichneumonoidea. Comprising the families Ichneumonidae and Braconidae, these parasitoid wasps are ecologically critical for regulating insect populations, yet they remain one of the most taxonomically challenging groups due to their cryptic morphology and vast number of undescribed species. To address the scarcity of robust digital resources for these key groups, we present a curated image dataset designed to advance automated identification systems. The dataset contains 3,556 high-resolution images, primarily focused on Neotropical Ichneumonidae and Braconidae, while also including supplementary families such as Andrenidae, Apidae, Bethylidae, Chrysididae, Colletidae, Halictidae, Megachilidae, Pompilidae, and Vespidae to improve model robustness. Crucially, a subset of 1,739 images is annotated in COCO format, featuring multi-class bounding boxes for the full insect body, wing venation, and scale bars. This resource provides a foundation for developing computer vision models capable of identifying these families.",
      "authors": [
        "Joao Manoel Herrera Pinheiro",
        "Gabriela Do Nascimento Herrera",
        "Luciana Bueno Dos Reis Fernandes",
        "Alvaro Doria Dos Santos",
        "Ricardo V. Godoy",
        "Eduardo A. B. Almeida",
        "Helena Carolina Onody",
        "Marcelo Andrade Da Costa Vieira",
        "Angelica Maria Penteado-Dias",
        "Marcelo Becker"
      ],
      "url": "https://arxiv.org/abs/2602.20028",
      "published": "2026-02-20T15:13:14+00:00",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18283",
      "title": "HyTRec: A Hybrid Temporal-Aware Attention Architecture for Long Behavior Sequential Recommendation",
      "abstract": "Modeling long sequences of user behaviors has emerged as a critical frontier in generative recommendation. However, existing solutions face a dilemma: linear attention mechanisms achieve efficiency at the cost of retrieval precision due to limited state capacity, while softmax attention suffers from prohibitive computational overhead. To address this challenge, we propose HyTRec, a model featuring a Hybrid Attention architecture that explicitly decouples long-term stable preferences from short-term intent spikes. By assigning massive historical sequences to a linear attention branch and reserving a specialized softmax attention branch for recent interactions, our approach restores precise retrieval capabilities within industrial-scale contexts involving ten thousand interactions. To mitigate the lag in capturing rapid interest drifts within the linear layers, we furthermore design Temporal-Aware Delta Network (TADN) to dynamically upweight fresh behavioral signals while effectively suppressing historical noise. Empirical results on industrial-scale datasets confirm the superiority that our model maintains linear inference speed and outperforms strong baselines, notably delivering over 8% improvement in Hit Rate for users with ultra-long sequences with great efficiency.",
      "authors": [
        "Lei Xin",
        "Yuhao Zheng",
        "Ke Cheng",
        "Changjiang Jiang",
        "Zifan Zhang",
        "Fanhu Zeng"
      ],
      "url": "https://arxiv.org/abs/2602.18283",
      "published": "2026-02-20T15:11:40+00:00",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "id": "2602.18277",
      "title": "PRISM: Parallel Reward Integration with Symmetry for MORL",
      "abstract": "This work studies heterogeneous Multi-Objective Reinforcement Learning (MORL), where objectives can differ sharply in temporal frequency. Such heterogeneity allows dense objectives to dominate learning, while sparse long-horizon rewards receive weak credit assignment, leading to poor sample efficiency. We propose a Parallel Reward Integration with Symmetry (PRISM) algorithm that enforces reflectional symmetry as an inductive bias in aligning reward channels. PRISM introduces ReSymNet, a theory-motivated model that reconciles temporal-frequency mismatches across objectives, using residual blocks to learn a scaled opportunity value that accelerates exploration while preserving the optimal policy. We also propose SymReg, a reflectional equivariance regulariser that enforces agent mirroring and constrains policy search to a reflection-equivariant subspace. This restriction provably reduces hypothesis complexity and improves generalisation. Across MuJoCo benchmarks, PRISM consistently outperforms both a sparse-reward baseline and an oracle trained with full dense rewards, improving Pareto coverage and distributional balance: it achieves hypervolume gains exceeding 100\\% over the baseline and up to 32\\% over the oracle. The code is at \\href{https://github.com/EVIEHub/PRISM}{https://github.com/EVIEHub/PRISM}.",
      "authors": [
        "Finn van der Knaap",
        "Kejiang Qian",
        "Zheng Xu",
        "Fengxiang He"
      ],
      "url": "https://arxiv.org/abs/2602.18277",
      "published": "2026-02-20T15:02:42+00:00",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    }
  ]
}